@INCOLLECTION{Abreu2010,
  author = {Abreu, Rui and Gonz\'alez, Alberto and Zoeteweij, Peter and Gemund,
	Arjan J. C.},
  title = {Using Fault Screeners for Software Error Detection},
  booktitle = {Evaluation of Novel Approaches to Software Engineering},
  publisher = {Springer Berlin Heidelberg},
  year = {2010},
  editor = {Maciaszek, Leszek A. and Gonz\'alez-P\'erez, C\'esar and Jablonski,
	Stefan},
  volume = {69},
  series = {Communications in Computer and Information Science},
  pages = {60-74},
  note = {10.1007/978-3-642-14819-4\_5},
  abstract = {Fault screeners are simple software (or hardware) constructs that
	detect variable value errors based on unary invariant checking. In
	this paper we evaluate and compare the performance of three low-cost
	screeners (Bloom filter, bitmask, and range screener) that can be
	automatically integrated within a program, and trained during the
	testing phase. While the Bloom filter has the capacity of retaining
	virtually all variable values associated with proper program execution,
	this property comes with a much higher false positive rate per unit
	of training effort, compared to the more simple range and bitmask
	screeners, that compresses all value information in terms of a single
	lower and upper bound or a bitmask, respectively. We present a novel
	analytic model that predicts the false positive and false negative
	rate for ideal (i.e., screeners that store each individual value
	during training) and simple (e.g., range and bitmask) screeners.
	We show that the model agrees with our empirical findings. Furthermore,
	we describe an application of all screeners, where the screener's
	error detection output is used as input to a fault localization process
	that provides automatic feedback on the location of residual program
	defects during deployment in the field.},
  affiliation = {Software Engineering Research Group, Delft University of Technology,
	P.O. Box 5031, NL-2600 GA Delft, The Netherlands},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {S},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-3-642-14819-4},
  justificativa = {Este artigo avalia e compara tr\^es diferentes screeners (detectores
	de erros) quanto ao seu desempenho na detec{\c c}\~ao de erros e
	a utiliza{\c c}\~ao das informa{\c c}\~oes de erros para a localiza{\c
	c}\~ao de defeitos. Embora esteja dentro dos objetivos da revis\~ao,
	o texto integral n\~ao est\'a dispon\'ivel.},
  keyword = {Computer Science},
  nroartigo = {5},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-14819-4\_5}
}

@INPROCEEDINGS{Abreu2008b,
  author = {Abreu, Rui and Gonz\'alez, Alberto and Zoeteweij, Peter and van Gemund,
	Arjan J. C.},
  title = {Automatic software fault localization using generic program invariants},
  booktitle = {Proceedings of the 2008 ACM symposium on Applied computing},
  year = {2008b},
  series = {SAC '08},
  pages = {712--717},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma nova abordagem para localiza{\c c}\~ao de
	defeitos baseado em espectro utilizando informa{\c c}\~oes de "screeners"
	(detectores de erro gen\'ericos) ou invariante. Um invariante \'e
	uma proposi{\c c}\~ao ou fato sobre dados. O artigo atende aos crit\'erios
	de inclus\~ao.},
  abstract = {Despite extensive testing in the development phase, residual defects
	can be a great threat to dependability in the operational phase.
	This paper studies the utility of low-cost, generic invariants ("screeners")
	in their capacity of error detectors within a spectrum-based fault
	localization (SFL) approach aimed to diagnose program defects in
	the operational phase. The screeners considered are simple bit-mask
	and range invariants that screen every load/store and function argument/return
	program point. Their generic nature allows them to be automatically
	instrumented without any programmer-effort, while training is straightforward
	given the test cases available in the development phase. Experiments
	based on the Siemens program set demonstrate diagnostic performance
	that is similar to the traditional, development-time application
	of SFL based on the program pass/fail information known before-hand.
	This diagnostic performance is currently attained at an average 14%
	screener execution time overhead, but this overhead can be reduced
	at limited performance penalty.},
  acmid = {1363855},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1363686.1363855},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p712-abreu.pdf:PDF},
  isbn = {978-1-59593-753-7},
  keywords = {black box diagnosis, error detection, fault localization, program
	invariants, program spectra},
  location = {Fortaleza, Ceara, Brazil},
  nroartigo = {50},
  numpages = {6},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1363686.1363855}
}

@INPROCEEDINGS{Abreu2008,
  author = {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan J. C.},
  title = {An observation-based model for fault localization},
  booktitle = {Proceedings of the 2008 international workshop on dynamic analysis:
	held in conjunction with the ACM SIGSOFT International Symposium
	on Software Testing and Analysis (ISSTA 2008)},
  year = {2008a},
  series = {WODA '08},
  pages = {64--70},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	baseada em racioc\'inio l\'ogico sobre informa{\c c}\~oes de execu{\c
	c}\~ao de programas, aplic\'avel a programas com defeitos simples.
	Inclu\'ido por fazer parte dos objetivos da revis\~ao.},
  abstract = {Automatic techniques for helping developers in finding the root causes
	of software failures are extremely important in the development cycle
	of software. In this paper we study a dynamic modeling approach to
	fault localization, which is based on logic reasoning over program
	traces. We present a simple diagnostic performance model to assess
	the influence of various parameters, such as test set size and coverage,
	on the debugging effort required to find the root causes of software
	failures. The model shows that our approach unambiguously reveals
	the actual faults, provided that sufficient test cases are available.
	This optimal diagnostic performance is confirmed by numerical experiments.
	Furthermore, we present preliminary experiments on the diagnostic
	capabilities of this approach using the single-fault Siemens benchmark
	set. We show that, for the Siemens set, the approach presented in
	this paper yields a better diagnostic ranking than other well-known
	techniques.},
  acmid = {1401841},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1401827.1401841},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p64-abreu.pdf:PDF},
  isbn = {978-1-60558-054-8},
  keywords = {model-based diagnosis, program spectra, software fault diagnosis,
	test data analysis},
  location = {Seattle, Washington},
  nroartigo = {34},
  numpages = {7},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1401827.1401841}
}

@INPROCEEDINGS{Abreu2009,
  author = {Abreu, R. and Zoeteweij, P. and van Gemund, Arjan J. C.},
  title = {Localizing Software Faults Simultaneously},
  booktitle = {Quality Software, 2009. QSIC '09. 9th International Conference on},
  year = {2009},
  pages = {367 -376},
  month = {aug.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo apresenta uma t\'ecnica para localiza{\c c}\~ao de defeitos
	m\'ultiplos baseada em um modelo de racioc\'inio l\'ogico e uma t\'ecnica
	semelhante para defeitos simples. O artigo est\'a dentro dos crit\'erios
	de inclus\~ao da revis\~ao.},
  abstract = {Current automatic diagnosis techniques are predominantly of a statistical
	nature and, despite typical defect densities, do not explicitly consider
	multiple faults, as also demonstrated by the popularity of the single-fault
	Siemens set. We present a logic reasoning approach, called Zoltar-M(ultiple
	fault), that yields multiple-fault diagnoses, ranked in order of
	their probability. Although application of Zoltar-M to programs with
	many faults requires further research into heuristics to reduce computational
	complexity, theory as well as experiments on synthetic program models
	and two multiple-fault program versions from the Siemens set show
	that for multiple-fault programs this approach can outperform statistical
	techniques, notably spectrum-based fault localization (SFL). As a
	side-effect of this research, we present a new SFL variant, called
	Zoltar-S(ingle fault), that is provably optimal for single-fault
	programs, outperforming all other variants known to date.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {S},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2009.55},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05381406.pdf:PDF},
  issn = {1550-6002},
  keywords = {Siemens;Zoltar-multiple fault;Zoltar-single fault;computational complexity;logic
	reasoning approach;multiple-fault program versions;probability;single-fault
	programs;software fault diagnosis;spectrum-based fault localization;synthetic
	program models;computational complexity;probability;program diagnostics;software
	fault tolerance;},
  nroartigo = {27},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5381406}
}


@ARTICLE{Porter2009,
  author = {Porter Adam and Yilmaz Cemal and Memon M. and Schmidt C. and Natarajan
	Bala},
  title = {Skoll: A Process and Infrastructure for Distributed Continuous Quality
	Assurance},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2009},
  volume = {PP},
  pages = {1},
  number = {99},
  month = { },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma nova abordagem para processos de garantia
	de qualidade de software, adequados a ambientes de desenvolvimento
	distribu\'idos e continuos. Prop\~oe tamb\'em novos processos de
	garantia de qualidade necess\'arios para essa proposta e uma ferramenta
	para permitir a utiliza{\c c}\~ao de processos de garantia de qualidade
	distribu\'idas e cont\'inuas. Trabalho id\^entico a outro j\'a visto
	na mesma biblioteca (IEEE Xplore). Fora do escopo desta revis\~ao.},
  abstract = {Software engineers increasingly emphasize agility and flexibility
	in their designs and development approaches. They increasingly use
	distributed development teams, rely on component assembly and deployment
	rather than green field code writing, rapidly evolve the system through
	incremental development and frequent updating, and use flexible product
	designs supporting extensive end-user customization. While agility
	and flexibility have many benefits, they also create an enormous
	number of potential system configurations built from rapidly changing
	component implementations. Since today's quality assurance (QA) techniques
	do not scale to handle highly configurable systems, we are developing
	and validating novel software QA processes and tools that leverage
	the extensive computing resources of user and developer communities
	in a distributed, continuous manner to improve software quality significantly.
	This paper provides several contributions to the study of distributed,
	continuous QA (DCQA). First, it shows the structure and functionality
	of Skoll, which is an environment that defines a generic around-the-world,
	around-the-clock QA process and several sophisticated tools that
	support this process. Second, it describes several novel QA processes
	built using the Skoll environment. Third, it presents two studies
	using Skoll: one involving user testing of the Mozilla browser and
	another involving continuous build, integration, and testing of the
	ACE+TAO communication software package. The results of our studies
	suggest that the Skoll environment can manage and control distributed
	continuous QA processes more effectively than conventional QA processes.
	For example, our DCQA processes rapidly identified problems that
	had taken the ACE+TAO developers much longer to find and several
	of which they had not found. Moreover, the automatic analysis of
	QA results provided developers information that enabled them to quickly
	find the root cause of problems.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2007.1013},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04359961.pdf:PDF},
  issn = {0098-5589},
  nroartigo = {61},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4359961}
}

@INPROCEEDINGS{Ali2009,
  author = {Ali, Shaimaa and Andrews, James H. and Dhandapani, Tamilselvi and
	Wang, Wantao},
  title = {Evaluating the Accuracy of Fault Localization Techniques},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2009},
  editor = {25},
  series = {ASE '09},
  pages = {76--87},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este trabalho faz uma compara{\c c}\~ao entre algumas t\'ecnicas de
	localiza{\c c}\~ao de defeitos existentes para avaliar a acur\'acia
	dessas t\'ecnicas. Prop\~oe uma nova medida de avalia{\c c}\~ao para
	averiguar essa acur\'acia das t\'ecnicas, que, segundo os autores,
	\'e uma medida justa e n\~ao enviesada. Avalia tamb\'em o uso de
	muta{\c c}\~ao e t\'ecnicas de data mining para localiza{\c c}\~ao
	de defeitos. Este trabalho est\'a dentro do escopo desta revis\~ao,
	j\'a que apresenta uma compara{\c c}\~ao entre t\'ecnicas de localiza{\c
	c}\~ao de defeitos existentes propondo uma nova m\'etrica para compar\'a-las.},
  abstract = {We investigate claims and assumptions made in several recent papers
	about fault localization (FL) techniques. Most of these claims have
	to do with evaluating FL accuracy. Our investigation centers on a
	new subject program having properties useful for FL experiments.
	We find that Tarantula (Jones et al.) works well on the program,
	and we show weak support for the assertion that coverage-based test
	suites help Tarantula to localize faults. Baudry et al. used automatically-generated
	mutants to evaluate the accuracy of an FL technique that generates
	many distinct scores for program locations. We find no evidence to
	suggest that the use of mutants for this purpose is invalid. However,
	we find evidence that the standard method for evaluating FL accuracy
	is unfairly biased toward techniques that generate many distinct
	scores, and we propose a fairer method of accuracy evaluation. Finally,
	Denmat et al. suggest that data mining techniques may apply to FL.
	We investigate this suggestion with the data mining tool Weka, using
	standard techniques for evaluating the accuracy of data mining classifiers.
	We find that standard classifiers suffer from the class imbalance
	problem. However, we find that adding cost information improves accuracy.},
  acmid = {1747510},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {S},
  ci5 = {S},
  doi = {http://dx.doi.org/10.1109/ASE.2009.89},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/3891a076.pdf:PDF},
  isbn = {978-0-7695-3891-4},
  keywords = {Fault localization, mutation analysis, data mining},
  nroartigo = {11},
  numpages = {12},
  owner = {higoramario},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1109/ASE.2009.89}
}

@ARTICLE{Artho2011,
  author = {Artho, Cyrille},
  title = {Iterative delta debugging},
  journal = {International Journal on Software Tools for Technology Transfer (STTT)},
  year = {2011},
  volume = {13},
  pages = {223-246},
  note = {10.1007/s10009-010-0139-9},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SpringerLink},
  incluido = {S},
  justificativa = {O artigo prop\~oe uma t\'ecnica que minimiza a diferen{\c c}a entre
	duas entradas, uma que executa com sucesso e outra com falha para
	realizar a localiza{\c c}\~ao de defeitos. Segundo o autor, a t\'ecnica
	pode ser aplicada a programas reais. Atende aos crit\'erios de inclus\~ao.},
  abstract = {Automated debugging attempts to locate the reason for a failure. Delta
	debugging minimizes the difference between two inputs, where one
	input is processed correctly while the other input causes a failure,
	using a series of test runs to determine the outcome of applied changes.
	Delta debugging is applicable to inputs or to the program itself,
	as long as a correct version of the program exists. However, complex
	errors are often masked by other program defects, making it impossible
	to obtain a correct version of the program through delta debugging
	in such cases. Iterative delta debugging extends delta debugging
	and removes a series of defects step by step, until the originally
	unresolved defect is isolated. The method is automated and managed
	to localize a bug in some real-life examples.},
  affiliation = {Research Center for Information Security (RCIS), AIST, Tokyo, Japan},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {S},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Artho\_2008.pdf:PDF},
  issn = {1433-2779},
  issue = {3},
  keyword = {Computer Science},
  nroartigo = {4},
  owner = {higoramario},
  publisher = {Springer Berlin / Heidelberg},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/s10009-010-0139-9}
}

@INPROCEEDINGS{Artzi2011,
  author = {Artzi, Shay and Dolby, Julian and Jensen, Simon Holm and M{\o}ller,
	Anders and Tip, Frank},
  title = {A framework for automated testing of javascript web applications},
  booktitle = {Proceeding of the 33rd international conference on Software engineering},
  year = {2011},
  series = {ICSE '11},
  pages = {571--580},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta um framework para gera{\c c}\~ao autom\'atica
	de teste com feedback imediato para Javascript, que coleta as informa{\c
	c}\~oes dos testes gerados para indicar poss\'iveis erros em p\'aginas
	web. Fora do escopo da revis\~ao.},
  abstract = {Current practice in testing JavaScript web applications requires manual
	construction of test cases, which is difficult and tedious. We present
	a framework for feedback-directed automated test generation for JavaScript
	in which execution is monitored to collect information that directs
	the test generator towards inputs that yield increased coverage.
	We implemented several instantiations of the framework, corresponding
	to variations on feedback-directed random testing, in a tool called
	Artemis. Experiments on a suite of JavaScript applications demonstrate
	that a simple instantiation of the framework that uses event handler
	registrations as feedback information produces surprisingly good
	coverage if enough tests are generated. By also using coverage information
	and read-write sets as feedback information, a slightly better level
	of coverage can be achieved, and sometimes with many fewer tests.
	The generated tests can be used for detecting HTML validity problems
	and other programming errors.},
  acmid = {1985871},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1985793.1985871},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p571-artzi.pdf:PDF},
  isbn = {978-1-4503-0445-0},
  keywords = {ajax, automated testing, debugging, event driven, javascript, random
	testing, web applications},
  location = {Waikiki, Honolulu, HI, USA},
  nroartigo = {40},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1985793.1985871}
}

@ARTICLE{Artzi2011a,
  author = {Artzi, S. and Dolby, J. and Tip, F. and Pistoia, M.},
  title = {Fault Localization for Dynamic Web Applications},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2011},
  volume = {PP},
  pages = {1},
  number = {99},
  month = { },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O presente artigo mostra como utilizar tais t\'ecnicas de localiza{\c
	c}\~ao de defeitos com chamadas de fun{\c c}\~oes, o que pode ser
	utilizado para teste de integra{\c c}\~ao. Embora o artigo seja voltado
	para aplica{\c c}\~oes web e n\~ao apresente nenhuma nova t\'ecnica
	para depura{\c c}\~ao automatizada, pode ser lido posteriormente.
	Dessa forma, n\~ao atende os crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {In recent years, there has been significant interest in fault-localization
	techniques that are based on statistical analysis of program constructs
	executed by passing and failing executions. This paper shows how
	the Tarantula, Ochiai, and Jaccard fault-localization algorithms
	can be enhanced to localize faults effectively in Web applications
	written in PHP, by using an extended domain for conditional and function-call
	statements, and by using a source mapping. We also propose several
	novel test-generation strategies that are geared towards producing
	test suites that have maximal fault-localization effectiveness. We
	implemented various fault-localization techniques and test-generation
	strategies in Apollo, and evaluated them on several open-source PHP
	applications. Our results indicate that a variant of the Ochiai algorithm
	that includes all our enhancements localizes 87.8% of all faults
	to within 1% of all executed statements, compared to only 37.4% for
	the unenhanced Ochiai algorithm. We also found that all the test-generation
	strategies that we considered are capable of generating test suites
	with maximal fault-localization effectiveness, when given an infinite
	time budget for test generation. However, on average, a directed
	strategy based on path-constraint similarity achieves this maximal
	effectiveness after generating only 6.5 tests, compared to 46.8 tests
	for an undirected test-generation strategy.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2011.76},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05975173.pdf:PDF},
  issn = {0098-5589},
  nroartigo = {4},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5975173}
}

@INPROCEEDINGS{Artzi2010,
  author = {Artzi, Shay and Dolby, Julian and Tip, Frank and Pistoia, Marco},
  title = {Directed test generation for effective fault localization},
  booktitle = {Proceedings of the 19th international symposium on Software testing
	and analysis},
  year = {2010},
  series = {ISSTA '10},
  pages = {49--60},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma nova t\'ecnica de gera{\c c}\~ao autom\'atica
	de casos de teste utilizando a t\'ecnica de localiza{\c c}\~ao de
	defeitos Ochiai para avaliar o desempenho em compara{\c c}\~ao com
	t\'ecnicas de gera{\c c}\~ao de casos de teste existentes como concolic
	(simb\'olica e concreta). Fora dos objetivos da revis\~ao.},
  abstract = {Fault-localization techniques that apply statistical analyses to execution
	data gathered from multiple tests are quite effective when a large
	test suite is available. However, if no test suite is available,
	what is the best approach to generate one? This paper investigates
	the fault-localization effectiveness of test suites generated according
	to several test-generation techniques based on combined concrete
	and symbolic (concolic) execution. We evaluate these techniques by
	applying the Ochiai fault-localization technique to generated test
	suites in order to localize 35 faults in four PHP Web applications.
	Our results show that the test-generation techniques under consideration
	produce test suites with similar high fault-localization effectiveness,
	when given a large time budget. However, a new, "directed" test-generation
	technique, which aims to maximize the similarity between the path
	constraints of the generated tests and those of faulty executions,
	reaches this level of effectiveness with much smaller test suites.
	On average, when compared to test generation based on standard concolic
	execution techniques that aims to maximize code coverage, the new
	directed technique preserves fault-localization effectiveness while
	reducing test-suite size by 86.1% and test-suite generation time
	by 88.6%.},
  acmid = {1831715},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1831708.1831715},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p49-artzi.pdf:PDF},
  isbn = {978-1-60558-823-0},
  keywords = {automated testing, concolic testing, testing web applications},
  location = {Trento, Italy},
  nroartigo = {44},
  numpages = {12},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1831708.1831715}
}

@ARTICLE{Artzi2010a,
  author = {Artzi, S. and Kiezun, A. and Dolby, J. and Tip, F. and Dig, D. and
	Paradkar, A. and Ernst, M.D.},
  title = {Finding Bugs in Web Applications Using Dynamic Test Generation and
	Explicit-State Model Checking},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2010},
  volume = {36},
  pages = {474 -494},
  number = {4},
  month = {july-aug. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica para gera{\c c}\~ao autom\'atica
	de casos de teste para aplica{\c c}\~oes Web, combinando execu{\c
	c}\~ao simb\'olica e concreta, executando os testes gerados eidentifica
	falhas nas p\'aginas geradas automaticamente. Experimentos foram
	realizados utilizando 6 aplica{\c c}\~oes PHP. Fora do escopo desta
	revis\~ao.},
  abstract = {Web script crashes and malformed dynamically generated webpages are
	common errors, and they seriously impact the usability of Web applications.
	Current tools for webpage validation cannot handle the dynamically
	generated pages that are ubiquitous on today's Internet. We present
	a dynamic test generation technique for the domain of dynamic Web
	applications. The technique utilizes both combined concrete and symbolic
	execution and explicit-state model checking. The technique generates
	tests automatically, runs the tests capturing logical constraints
	on inputs, and minimizes the conditions on the inputs to failing
	tests so that the resulting bug reports are small and useful in finding
	and fixing the underlying faults. Our tool Apollo implements the
	technique for the PHP programming language. Apollo generates test
	inputs for a Web application, monitors the application for crashes,
	and validates that the output conforms to the HTML specification.
	This paper presents Apollo's algorithms and implementation, and an
	experimental evaluation that revealed 673 faults in six PHP Web applications.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2010.31},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05416728.pdf:PDF},
  issn = {0098-5589},
  keywords = {Apollo tool;HTML specification;Internet;PHP Web applications;PHP programming
	language;Web pages;Web script;bugs;dynamic test generation;explicit
	state model checking;program debugging;program testing;program verification;software
	tools;},
  nroartigo = {44},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5416728}
}

@INPROCEEDINGS{Artzi2008,
  author = {Artzi, Shay and Kiezun, Adam and Dolby, Julian and Tip, Frank and
	Dig, Danny and Paradkar, Amit and Ernst, Michael D.},
  title = {Finding bugs in dynamic web applications},
  booktitle = {Proceedings of the 2008 international symposium on Software testing
	and analysis},
  year = {2008},
  series = {ISSTA '08},
  pages = {261--272},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica chamada Apollo para realizar testes
	automatizados em p\'aginas web geradas dinamicamente em PHP, atrav\'es
	da compara{\c c}\~ao dos resultados com especifica{\c c}\~oes HTML
	(or\'aculos). A Apollo tamb\'em gera os casos de teste e gera os
	relat\'orios de falhas. Portanto, n\~ao se aplica aos crit\'erios
	de inclus\~ao desta revis\~ao.},
  abstract = {Web script crashes and malformed dynamically-generated Web pages are
	common errors, and they seriously impact usability of Web applications.
	Current tools for Web-page validation cannot handle the dynamically-generated
	pages that are ubiquitous on today's Internet. In this work, we apply
	a dynamic test generation technique, based on combined concrete and
	symbolic execution, to the domain of dynamic Web applications. The
	technique generates tests automatically, uses the tests to detect
	failures, and minimizes the conditions on the inputs exposing each
	failure, so that the resulting bug reports are small and useful in
	finding and fixing the underlying faults. Our tool Apollo implements
	the technique for PHP. Apollo generates test inputs for the Web application,
	monitors the application for crashes, and validates that the output
	conforms to the HTML specification. This paper presents Apollo's
	algorithms and implementation, and an experimental evaluation that
	revealed 214 faults in 4 PHP Web applications.},
  acmid = {1390662},
  ce1 = {N},
  ce2 = {S},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1390630.1390662},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p261-artzi.pdf:PDF},
  isbn = {978-1-60558-050-0},
  keywords = {dynamic analysis, php, software testing, web applications},
  location = {Seattle, WA, USA},
  nroartigo = {5},
  numpages = {12},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://doi.acm.org/10.1145/1390630.1390662}
}

@INPROCEEDINGS{Baudry2006,
  author = {Baudry, Benoit and Fleurey, Franck and Le Traon, Yves},
  title = {Improving test suites for efficient fault localization},
  booktitle = {Proceedings of the 28th international conference on Software engineering},
  year = {2006},
  series = {ICSE '06},
  pages = {82--91},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo prop\~oe uma estrat\'egia para gera{\c c}\~ao de casos de
	teste para melhorar a depura{\c c}\~ao, mas n\~ao prop\~oe nenhuma
	nova t\'ecnica ou abordagem para depura{\c c}\~ao. Fora do objetivo
	da revis\~ao.},
  abstract = {The need for testing-for-diagnosis strategies has been identified
	for a long time, but the explicit link from testing to diagnosis
	(fault localization) is rare. Analyzing the type of information needed
	for efficient fault localization, we identify the attribute (called
	Dynamic Basic Block) that restricts the accuracy of a diagnosis algorithm.
	Based on this attribute, a test-for-diagnosis criterion is proposed
	and validated through rigorous case studies: it shows that a test
	suite can be improved to reach a high level of diagnosis accuracy.
	So, the dilemma between a reduced testing effort (with as few test
	cases as possible) and the diagnosis accuracy (that needs as much
	test cases as possible to get more information) is partly solved
	by selecting test cases that are dedicated to diagnosis.},
  acmid = {1134299},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1134285.1134299},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p82-baudry.pdf:PDF},
  isbn = {1-59593-375-1},
  keywords = {diagnosis, mutation analysis, test generation},
  location = {Shanghai, China},
  nroartigo = {19},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1134285.1134299}
}

@INPROCEEDINGS{Beer2007,
  author = {Beer, Armin and Heindl, Matthias},
  title = {Issues in Testing Dependable Event-Based Systems at a Systems Integration
	Company},
  booktitle = {Availability, Reliability and Security, 2007. ARES 2007. The Second
	International Conference on},
  year = {2007},
  pages = {1093 -1100},
  month = {april},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta dois estudos de caso sobre o estado da pr\'atica
	de testes para sistemas baseado em eventos. Fora do escopo da revis\~ao.},
  abstract = {Testing of dependable event-based systems is very important to ensure
	that all requirements (including nonfunctional requirements such
	as reliability, availability, safety and security) are met and the
	relevant standards are considered. Siemens Program and Systems Engineering
	is a company that builds dependable event-based systems in multiple
	domains. A special unit at PSE, the Support Center Test, focuses
	on testing issues. In this paper we provide an overview of the state-of-the-practice
	in testing dependable event-based systems and identify the challenges
	that have to be addressed in the future. We illustrate our findings
	by two case studies, one for a transportation system and one for
	telecommunications. The top three topics for improvement are: testability
	and requirements tracing, generation of test cases, and verification
	and validation},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ARES.2007.103},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04159913.pdf:PDF},
  keywords = {dependable event-based system testing;requirements tracing;system
	availability;system reliability;system safety;system security;system
	validation;system verification;test case generation;program testing;program
	verification;security of data;software reliability;},
  nroartigo = {47},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4159913}
}

@INPROCEEDINGS{Binkley2007,
  author = {Binkley, David},
  title = {Source Code Analysis: A Road Map},
  booktitle = {2007 Future of Software Engineering},
  year = {2007},
  series = {FOSE '07},
  pages = {104--119},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Artigo discutindo os progressos e desafios para a \'area de automa{\c
	c}\~ao de an\'alise de c\'odigo. Fora do escopo da revis\~ao.},
  abstract = {The automated and semi-automated analysis of source code has remained
	a topic of intense research for more than thirty years. During this
	period, algorithms and techniques for source-code analysis have changed,
	sometimes dramatically. The abilities of the tools that implement
	them have also expanded to meet new and diverse challenges. This
	paper surveys current work on source-code analysis. It also provides
	a road map for future work over the next five-year period and speculates
	on the development of source-code analysis applications, techniques,
	and challenges over the next 10, 20, and 50 years.},
  acmid = {1254713},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/FOSE.2007.27},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04221615.pdf:PDF},
  isbn = {0-7695-2829-5},
  nroartigo = {32},
  numpages = {16},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dx.doi.org/10.1109/FOSE.2007.27}
}

@INPROCEEDINGS{Briand2008,
  author = {Briand, L.C. and Labiche, Y. and Bawar, Z.},
  title = {Using Machine Learning to Refine Black-Box Test Specifications and
	Test Suites},
  booktitle = {Quality Software, 2008. QSIC '08. The Eighth International Conference
	on},
  year = {2008},
  pages = {135 -144},
  month = {aug.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma t\'ecnica baseada em aprendizado de m\'aquina
	para refinamento de conjuntos de teste de regress\~ao. Fora dos prop\'ositos
	da revis\~ao.},
  abstract = {In the context of open source development or software evolution, developers
	often face test suites which have been developed with no apparent
	rationale and which may need to be augmented or refined to ensure
	sufficient dependability, or even reduced to meet tight deadlines.
	We refer to this process as the re-engineering of test suites. It
	is important to provide both methodological and tool support to help
	people understand the limitations of test suites and their possible
	redundancies, so as to be able to refine them in a cost effective
	manner. To address this problem in the case of black-box testing,
	we propose a methodology based on machine learning that has shown
	promising results on a case study.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2008.5},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04601537.pdf:PDF},
  issn = {1550-6002},
  keywords = {black-box test specification refinement;machine learning;open source
	development;software evolution;test suite reengineering;formal specification;learning
	(artificial intelligence);program testing;public domain software;software
	maintenance;},
  nroartigo = {45},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4601537}
}

@INCOLLECTION{Briand2010,
  author = {Briand, Lionel C.},
  title = {Software Verification - A Scalable, Model-Driven, Empirically Grounded
	Approach},
  booktitle = {Simula Research Laboratory},
  publisher = {Springer Berlin Heidelberg},
  year = {2010},
  editor = {Tveito, Aslak and Bruaset, Are Magnus and Lysne, Olav},
  pages = {415-442},
  note = {10.1007/978-3-642-01156-6\_28},
  abstract = {Software is present in most systems across all industries, including
	energy, automotive, health care, maritime, aerospace, and banking,
	to name just a few. Software systems are increasingly taking on safety-
	and business-critical roles and growing in complexity. One crucial
	aspect of software development is therefore to ensure the dependability
	of such systems, that is, their reliability, safety, and robustness.
	This is achieved by several complementary means of verification,
	ranging from early analysis of system specifications and designs
	to systematic testing of the executable software. Such verification
	activities are, however, difficult and time-consuming. This stems
	in part from the sheer complexity of most software systems and because
	they must accommodate changing requirements from many stakeholders.},
  affiliation = {Simula Research Laboratory, Oslo, Norway},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {S},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-3-642-01156-6},
  justificativa = {O cap\'itulo traz uma vis\~ao geral sobre as atividades de verifica{\c
	c}\~ao de software para garantia de sua confiabilidade, seguran{\c
	c}a e robustez. Fora do escopo da revis\~ao. O texto n\~ao est\'a
	dispon\'ivel integralmente.},
  keyword = {Mathematics},
  nroartigo = {15},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-01156-6\_28}
}

@INPROCEEDINGS{Bryce2007,
  author = {Bryce, Ren\'ee C. and Memon, Atif M.},
  title = {Test suite prioritization by interaction coverage},
  booktitle = {Workshop on Domain specific approaches to software test automation:
	in conjunction with the 6th ESEC/FSE joint meeting},
  year = {2007},
  series = {DOSTA '07},
  pages = {1--7},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo prop\~oe uma t\'ecnica para teste de sistemas dirigidos a
	eventos interativa. Fora do escopo da revis\~ao.},
  abstract = {Event-driven software (EDS) is a widely used class of software that
	takes sequences of events as input, changes state, and outputs new
	event sequences. Managing the size of tests suites for EDS is difficult
	as the number of event combinations and sequences grow exponentially
	with the number of events. We propose a new testing technique that
	extends software interaction testing. Traditional software interaction
	testing systematically examines all t-way interactions of parameters
	for a program. This paper extends the notion to t-way interactions
	over sequences of events. The technique applies to many classes of
	software; we focus on that of EDS. As a proof-of-concept, we prioritize
	existing test suites for four GUI-based programs by t-way interaction
	coverage. We compare the rate of fault detection with that of several
	other prioritization criteria. Results show that prioritization by
	interaction coverage has the fastest rate of fault detection in half
	of our experiments, making the most impact when tests have high interaction
	coverage.},
  acmid = {1294922},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1294921.1294922},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p1-bryce.pdf:PDF},
  isbn = {978-1-59593-726-1},
  keywords = {<i>t</i>-way interaction coverage, combinatorial interaction testing,
	covering arrays, event driven software, test suite prioritization},
  location = {Dubrovnik, Croatia},
  nroartigo = {20},
  numpages = {7},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1294921.1294922}
}

@INPROCEEDINGS{Burger2011,
  author = {Burger, Martin and Zeller, Andreas},
  title = {Minimizing reproduction of software failures},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing
	and Analysis},
  year = {2011},
  series = {ISSTA '11},
  pages = {221--231},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {O artigo apresenta uma t\'ecnica para reduzir o espa{\c c}o de busca
	de fun{\c c}\~oes chamadas quando ocorre uma falha em uma execu{\c
	c}\~ao. Atende aos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {A program fails. What now? Taking a single failing run, we record
	and minimize the interaction between objects to the set of calls
	relevant for the failure. The result is a minimal unit test that
	faithfully reproduces the failure at will: "Out of these 14,628 calls,
	only 2 are required". In a study of 17 real-life bugs, our JINSI
	prototype reduced the search space to 13.7% of the dynamic slice
	or 0.22% of the source code, with only 1--12 calls left to examine.},
  acmid = {2001447},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/2001420.2001447},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p221-burger.pdf:PDF},
  isbn = {978-1-4503-0562-4},
  keywords = {automated debugging, capture/replay},
  location = {Toronto, Ontario, Canada},
  nroartigo = {10},
  numpages = {11},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/2001420.2001447}
}

@CONFERENCE{Cellier2009,
  author = {Cellier, P., Ducass\'e, M., Ferr\'e, S., Ridoux, O.},
  title = {DeLLIS: A data mining process for fault localization},
  year = {2009},
  pages = {432-437},
  note = {cited By (since 1996) 1},
  abstract = {Most dynamic fault localization methods aim at totally ordering program
	elements from highly suspicious to innocent. This ignores the structure
	of the program and creates clusters of program elements where the
	relations between the elements are lost. We propose a data mining
	process that computes program element clusters and that also shows
	dependencies between program elements. Experimentations show that
	our process gives a comparable number of lines to analyze than the
	best related methods while providing a richer environment for the
	analysis. We also show that the method scales up by tuning the statistical
	indicators of the data mining process.},
  affiliation = {University of Rennes 1, INSA of Rennes, IRISA, France},
  base = {SciVerse Scopus},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {S},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  journal = {Proceedings of the 21st International Conference on Software Engineering
	and Knowledge Engineering, SEKE 2009},
  justificativa = {Este trabalho apresenta uma t\'ecnica para localiza{\c c}\~ao de defeitos
	que utiliza data-mining, agrupando comandos por semelhância e mostrando
	as depend\^encias existentes entre eles. Embora o artigo apresenta
	uma nova t\'ecnica para localiza{\c c}\~ao de defeitos, o texto do
	artigo n\~ao est\'a dispon\'ivel, atendendo a um dos crit\'erios
	de exclus\~ao.},
  nroartigo = {18},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149355582\&partnerID=40\&md5=ec8ed0b6329d0741ed77f36d0ad3bde3}
}

@INPROCEEDINGS{Cervnak2010,
  author = {Cer\v{n}ak, Milo\'{y}},
  title = {Diagnostics for debugging speech recognition systems},
  booktitle = {Proceedings of the 13th international conference on Text, speech
	and dialogue},
  year = {2010},
  series = {TSD'10},
  pages = {251--258},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SpringerLink},
  incluido = {N},
  justificativa = {Este artigo trata do uso de t\'ecnica para localiza{\c c}\~ao de defeitos
	especificamente para sistemas de reconhecimento de fala, utilizando
	t\'ecnicas de localiza{\c c}\~ao de defeitos baseada em espectro
	j\'a existentes. Fora dos objetivos dessa revis\~ao.},
  abstract = {Modern speech recognition applications are becoming very complex program
	packages. To understand the error behaviour of the ASR systems, a
	special diagnosis-a procedure or a too--is needed. Many ASR users
	and developers have developed their own expert diagnostic rules that
	can be successfully applied to a system. There are also several explicit
	approaches in the literature for determining the problems related
	to application errors. The approaches are based on error and ablative
	analyses of the ASR components, with a blame assignment to a problematic
	component. The disadvantage of those methods is that they are either
	quite time-consuming to acquire expert diagnostic knowledge, or that
	they offer very coarse-grained localization of a problematic ASR
	part. This paper proposes fine-grained diagnostics for debugging
	ASR by applying a program-spectra based failure localization, and
	it localizes directly a part of ASR implementation. We designed a
	toy experiment with diagnostic database OLLO to show that our method
	is very easy to use and that it provides a good localization accuracy.
	Because it is not able to localize all the errors, an issue that
	we discuss in the discussion, we recommend to use it with other coarse-grained
	localization methods for a complex ASR diagnosis.},
  acmid = {1887211},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/cernak\_10.pdf:PDF},
  isbn = {3-642-15759-9, 978-3-642-15759-2},
  keywords = {automatic speech recognition, fault diagnosis},
  location = {Brno, Czech Republic},
  nroartigo = {11},
  numpages = {8},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dl.acm.org/citation.cfm?id=1887176.1887211}
}

@INPROCEEDINGS{Chen2010,
  author = {Xiang Chen and Qing Gu and Jingxian Qi and Daoxu Chen},
  title = {Applying Particle Swarm Optimization to Pairwise Testing},
  booktitle = {Computer Software and Applications Conference (COMPSAC), 2010 IEEE
	34th Annual},
  year = {2010},
  pages = {107 -116},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo aborda a gera{\c c}\~ao de automatizada de testes combinat\'orios
	utilizando uma meta-heur\'istica de busca chamada de Particle Swarm
	Optimization. Fora do escopo da revis\~ao.},
  abstract = {Combinatorial testing (also called interaction testing) is an effective
	specification-based test input generation technique. By now most
	of research work in combinatorial testing aims to propose novel approaches
	trying to generate test suites with minimum size that still cover
	all the pairwise, triple, or n-way combinations of factors. Since
	the difficulty of solving this problem is demonstrated to be NP-hard,
	existing approaches have been designed to generate optimal or near
	optimal combinatorial test suites in polynomial time. In this paper,
	we try to apply particle swarm optimization (PSO), a kind of meta-heuristic
	search technique, to pairwise testing (i.e. a special case of combinatorial
	testing aiming to cover all the pairwise combinations). To systematically
	build pairwise test suites, we propose two different PSO based algorithms.
	One algorithm is based on one-test-at-a-time strategy and the other
	is based on IPO-like strategy. In these two different algorithms,
	we use PSO to complete the construction of a single test. To successfully
	apply PSO to cover more uncovered pairwise combinations in this construction
	process, we provide a detailed description on how to formulate the
	search space, define the fitness function and set some heuristic
	settings. To verify the effectiveness of our approach, we implement
	these algorithms and choose some typical inputs. In our empirical
	study, we analyze the impact factors of our approach and compare
	our approach to other well-known approaches. Final empirical results
	show the effectiveness and efficiency of our approach.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2010.17},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05676343.pdf:PDF},
  issn = {0730-3157},
  keywords = {NP-hard;combinatorial testing;meta-heuristic search technique;pairwise
	testing;particle swarm optimization;specification based test input
	generation technique;particle swarm optimisation;program debugging;program
	testing;search problems;},
  nroartigo = {50},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5676343}
}

@inproceedings{cheng2009,
 author = {Cheng, Hong and Lo, David and Zhou, Yang and Wang, Xiaoyin and Yan, Xifeng},
 title = {Identifying bug signatures using discriminative graph mining},
 booktitle = {Proceedings of the 2009 International Symposium on Software Testing and Analysis},
 series = {ISSTA '09}, 
 year = {2009},
 pages = {141--152}
 } 

@INPROCEEDINGS{Chittimalli2007,
  author = {Chittimalli, P.K. and Harrold, M.J.},
  title = {Re-computing Coverage Information to Assist Regression Testing},
  booktitle = {Software Maintenance, 2007. ICSM 2007. IEEE International Conference
	on},
  year = {2007},
  pages = {164 -173},
  month = {oct.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para recalcular a cobertura de
	c\'odigo para conjuntos de teste de regress\~ao para n\~ao executar
	casos de teste que n\~ao exercitem as modifica{\c c}\~oes realizadas
	na vers\~ao. Fora do escopo da revis\~ao.},
  abstract = {This paper presents a technique that leverages an existing regression
	test-selection algorithm to compute accurate, updated coverage data
	on a version of the software, Pi+1, without rerunning any test cases
	that do not execute the changes from the previous version of the
	software, Pi, to Pi+1-Users of our technique can avoid the expense
	of rerunning the entire test suite on Pi+1 or the inaccuracy produced
	by previous approaches that estimate coverage data for Pi+1 or reuse
	outdated coverage data from Pi. This paper also presents a tool,
	RECOVER, that implements our technique, along with a set of empirical
	studies. The studies show the inaccuracies that can exist when an
	application-regression-test selection-uses estimated and outdated
	coverage data. The studies also show that the overhead incurred by
	our technique is negligible.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICSM.2007.4362629},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04362629.pdf:PDF},
  issn = {1063-6773},
  keywords = {RECOVER;recomputing coverage information;regression testing;software
	maintenance;program testing;software maintenance;},
  nroartigo = {34},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4362629}
}

@ARTICLE{Chittimalli2009,
  author = {Chittimalli, P.K. and Harrold, M.-J.},
  title = {Recomputing Coverage Information to Assist Regression Testing},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2009},
  volume = {35},
  pages = {452 -469},
  number = {4},
  month = {july-aug. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para recalcular a cobertura de
	c\'odigo para conjuntos de teste de regress\~ao para n\~ao executar
	casos de teste que n\~ao exercitem as modifica{\c c}\~oes realizadas
	na vers\~ao. Um aprimoramento de um outro artigo j\'a proposto pelos
	mesmos autores. Fora do escopo da revis\~ao.},
  abstract = {This paper presents a technique that leverages an existing regression
	test selection algorithm to compute accurate, updated coverage data
	on a version of the software, Pi+1, without rerunning any test cases
	that do not execute the changes from the previous version of the
	software, Pi to Pi+1. The technique also reduces the cost of running
	those test cases that are selected by the regression test selection
	algorithm by performing a selective instrumentation that reduces
	the number of probes required to monitor the coverage data. Users
	of our technique can avoid the expense of rerunning the entire test
	suite on Pi+1 or the inaccuracy produced by previous approaches that
	estimate coverage data for Pi+1 or that reuse outdated coverage data
	from Pi. This paper also presents a tool, RECOVER, that implements
	our technique, along with a set of empirical studies on a set of
	subjects that includes several industrial programs, versions, and
	test cases. The studies show the inaccuracies that can exist when
	an application-regression test selection-uses estimated or outdated
	coverage data. The studies also show that the overhead incurred by
	selective instrumentation used in our technique is negligible and
	overall our technique provides savings over earlier techniques.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2009.4},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04760153.pdf:PDF},
  issn = {0098-5589},
  keywords = {coverage information;industrial programs;regression testing;software
	testing;program testing;regression analysis;},
  nroartigo = {49},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4760153}
}

@INPROCEEDINGS{Chou2011,
  author = {Chou, Hong-Zu and Chang, Kai-Hui and Kuo, Sy-Yen},
  title = {Facilitating unreachable code diagnosis and debugging},
  booktitle = {Proceedings of the 16th Asia and South Pacific Design Automation
	Conference},
  year = {2011},
  series = {ASPDAC '11},
  pages = {485--490},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta um m\'etodo para diagnosticar trechos de c\'odigo
	inalcans\'aveis. Fora do prop\'osito da revis\~ao.},
  abstract = {Code coverage is a popular method to find design bugs and verification
	loopholes. However, once a piece of code is determined to be unreachable,
	diagnosing the cause of the problem can be challenging: since the
	code is unreachable, no counterexample can be returned for debugging.
	Therefore, engineers need to analyze the legality of nonexistent
	execution paths, which can be difficult. To address such a problem,
	we analyzed the cause of unreachability in several industrial designs
	and proposed a diagnosis technique that can explain the cause of
	unreachability. In addition, our method provides suggestions on how
	to solve the un-reachability problem, which can further facilitate
	debugging. Our experimental results show that this technique can
	greatly reduce an engineer's effort in analyzing unreachable code.},
  acmid = {1950915},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p485-chou.pdf:PDF},
  isbn = {978-1-4244-7516-2},
  location = {Yokohama, Japan},
  nroartigo = {1},
  numpages = {6},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://dl.acm.org/citation.cfm?id=1950815.1950915}
}

@INPROCEEDINGS{Choudhary2011,
  author = {Choudhary, Shauvik Roy and Duvall, Jeremy and Jin, Wei and Zhao,
	Dan and Orso, Alessandro},
  title = {Platform support for developing testing and analysis plug-ins},
  booktitle = {Proceeding of the 1st workshop on Developing tools as plug-ins},
  year = {2011},
  series = {TOPI '11},
  pages = {16--19},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo faz uma discuss\~ao sobre caracter\'isticas necess\'arias
	que os Ambientes de Desenvolvimento Integrado (IDE's) devem ter para
	dar suporte a plug-ins de an\'alise de software e t\'ecnicas de teste.
	O trabalho n\~ao prop\~oe nenhuma nova t\'ecnica de an\'alise de
	teste ou cobertura de c\'odigo, n\~ao contribuindo para o objetivo
	dessa revis\~ao.},
  abstract = {Plug-ins have become an important part of today's integrated development
	environments (IDEs). They are useful for extending the functionality
	of these environments and customizing them for different types of
	projects. In this paper, we discuss some features that should be
	provided by IDEs to support the development of a specific kind of
	plug-ins - plug-ins that support program analysis and software testing
	techniques. To guide the discussion, we leverage our experience in
	building a plug-in for two different platforms and generalize from
	that experience.},
  acmid = {1984714},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1984708.1984714},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p16-choudhary.pdf:PDF},
  isbn = {978-1-4503-0599-0},
  keywords = {integrated development environments, plug-ins, program analysis, software
	testing},
  location = {Waikiki, Honolulu, HI, USA},
  nroartigo = {14},
  numpages = {4},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://doi.acm.org/10.1145/1984708.1984714}
}

@INPROCEEDINGS{Chung2008,
  author = {Yu-Min Chung and Chin-Yu Huang and Yu-Chi Huang},
  title = {A Study of Modified Testing-Based Fault Localization Method},
  booktitle = {Dependable Computing, 2008. PRDC '08. 14th IEEE Pacific Rim International
	Symposium on},
  year = {2008},
  pages = {168 -175},
  month = {dec.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	focada em comandos condicionais, utilizando tamb\'em teoria fuzzy
	e c\'alculo matricial no processo de localiza{\c c}\~ao de defeitos.
	A inten{\c c}\~ao \'e determinar importância de cada condicional
	para analizar a localiza{\c c}\~ao de defeitos. Os resultados obtidos
	s\~ao comparados com 2 t\'ecnicas de localiza{\c c}\~ao de defeitos
	existentes. Adequado aos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {In software development and maintenance, locating faults is generally
	a complex and time-consuming process. In order to effectively identify
	the locations of program faults, several approaches have been proposed.
	Similarity-aware fault localization (SAFL) is a testing-based fault
	localization method that utilizes testing information to calculate
	the suspicion probability of each statement. Dicing is also another
	method that we have used. In this paper, our proposed method focuses
	on predicates and their influence, instead of on statements in traditional
	SAFL. In our method, fuzzy theory, matrix calculating, and some probability
	are used. Our method detects the importance of each predicate and
	then provides more test data for programmers to analyze the fault
	locations. Furthermore, programmers will also gain some important
	information about the program in order to maintain their program
	accordingly. In order to speed up the efficiency, we also simplified
	the program. We performed an experimental study for several programs,
	together with another two testing-based fault localization (TBFL)
	approaches. These three methods were discussed in terms of different
	criteria such as line of code and suspicious code coverage. The experimental
	results show that the proposed method from our study can decrease
	the number of codes which have more probability of suspicion than
	real bugs.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/PRDC.2008.34},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/04725293.pdf:PDF},
  keywords = {fuzzy theory;matrix calculation;modified testing-based fault localization
	method;probability;similarity-aware fault localization;software development;software
	maintenance;fault diagnosis;fuzzy set theory;matrix algebra;software
	engineering;},
  nroartigo = {17},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4725293}
}

@ARTICLE{Cohen2006,
  author = {Cohen, Myra B. and Snyder, Joshua and Rothermel, Gregg},
  title = {Testing across configurations: implications for combinatorial testing},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2006},
  volume = {31},
  pages = {1--9},
  month = {November},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo realiza um estudo de caso para testes combinat\'orios
	para programas configur\'aveis em tempo de execu{\c c}\~ao, medindo
	a cobertura e efici\^encia na localiza{\c c}\~ao de defeitos. Fora
	dos prop\'ositos desta revis\~ao.},
  abstract = {User configurable software systems allow users to customize functionality
	at run time. In essence, each such system consists of a family of
	potentially thousands or millions of program instantiations. Testing
	methods cannot test all of these configurations, therefore some sampling
	mechanism must be applied. A common approach to providing such a
	mechanism has been to use combinatorial interaction testing. To date,
	however, little work has been done to quantify the effects of different
	configurations on a test suites' operation and effectiveness. In
	this paper we present a case study that investigates the effects
	of changing configurations on two types of test suites. Our results
	show that test coverage and fault detection effectiveness do not
	vary much across configurations for entire test suites; however,
	for individual test cases and certain types of faults, configurations
	matter.},
  acmid = {1218785},
  address = {New York, NY, USA},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1218776.1218785},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p1-cohen.pdf:PDF},
  issn = {0163-5948},
  issue = {6},
  keywords = {code coverage, combinatorial interaction testing, configurable software,
	empirical study},
  nroartigo = {16},
  numpages = {9},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1218776.1218785}
}

@INPROCEEDINGS{Dean2009,
  author = {Dean, Brian C. and Pressly, William B. and Malloy, Brian A. and Whitley,
	Adam A.},
  title = {A Linear Programming Approach for Automated Localization of Multiple
	Faults},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2009},
  series = {ASE '09},
  pages = {640--644},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma nova t\'ecnica para localiza{\c c}\~ao de
	m\'ultiplos defeitos baseada em programa{\c c}\~ao linear.},
  abstract = {In this paper, we address the problem of localizing faults by analyzing
	execution traces of successful and unsuccessful invocations of the
	application when run against a suite of tests. We present a new algorithm,
	based on a linear programming model, which is designed to be particularly
	effective for the case where multiple faults are present in the application
	under investigation.Through an extensive empirical study, we show
	that in the case of both single and multiple faults, our approach
	outperforms a host of prominent fault localization methods from the
	literature.},
  acmid = {1747572},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {S},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/ASE.2009.54},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/3891a640.pdf:PDF},
  isbn = {978-0-7695-3891-4},
  keywords = {fault localization, spectrum-based fault localization},
  nroartigo = {9},
  numpages = {5},
  owner = {higoramario},
  timestamp = {2011.09.15},
  url = {http://dx.doi.org/10.1109/ASE.2009.54}
}

@ARTICLE{Debroy2011a,
  author = {Debroy, V. and Wong, W.E.},
  title = {On the estimation of adequate test set size using fault failure rates},
  journal = {Journal of Systems and Software},
  year = {2011},
  volume = {84},
  pages = {587-602},
  number = {4},
  note = {cited By (since 1996) 0},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {N},
  justificativa = {O artigo mostra um estudo sobre 11 programas escritos em C para verificar
	a influ\^encia do tamanho dos conjuntos de teste para a localiza{\c
	c}\~ao de falhas existentes em programas atrav\'es de uma m\'etrica
	proposta, chamada taxa de falhas, raz\~ao de casos de teste que d\~ao
	origem a falhas. O artigo est\'a fora dos objetivos da revis\~ao.},
  abstract = {Test set size in terms of the number of test cases is an important
	consideration when testing software systems. Using too few test cases
	might result in poor fault detection and using too many might be
	very expensive and suffer from redundancy. We define the failure
	rate of a program as the fraction of test cases in an available test
	pool that result in execution failure on that program. This paper
	investigates the relationship between failure rates and the number
	of test cases required to detect the faults. Our experiments based
	on 11 sets of C programs suggest that an accurate estimation of failure
	rates of potential fault(s) in a program can provide a reliable estimate
	of adequate test set size with respect to fault detection and should
	therefore be one of the factors kept in mind during test set construction.
	Furthermore, the model proposed herein is fairly robust to incorrect
	estimations in failure rates and can still provide good predictive
	quality. Experiments are also performed to observe the relationship
	between multiple faults present in the same program using the concept
	of a failure rate. When predicting the effectiveness against a program
	with multiple faults, results indicate that not knowing the number
	of faults in the program is not a significant concern, as the predictive
	quality is typically not affected adversely. 2010 Elsevier Inc. All
	rights reserved.},
  affiliation = {Department of Computer Science, University of Texas at Dallas, MS
	EC 31, 800 West Campbell Road, Richardson, TX 75080, United States},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Debroy2011a.pdf:PDF},
  nroartigo = {33},
  owner = {higoramario},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79751532149\&partnerID=40\&md5=5dadf22714c58223a0550c150d68d369}
}

@INPROCEEDINGS{Debroy2010,
  author = {Debroy, V. and Wong, W.E.},
  title = {Using Mutation to Automatically Suggest Fixes for Faulty Programs},
  booktitle = {Software Testing, Verification and Validation (ICST), 2010 Third
	International Conference on},
  year = {2010},
  pages = {65 -74},
  month = {april},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica que combina localiza{\c c}\~ao
	de defeitos com muta{\c c}\~ao para automaticamente sugerir corre{\c
	c}\~oes para defeitos identificados durante a depura{\c c}\~ao sem
	interven{\c c}ao humana. Atende aos crit\'erios de inclus\~ao.},
  abstract = {This paper proposes a strategy for automatically fixing faults in
	a program by combining the processes of mutation and fault localization.
	Statements that are ranked in order of their suspiciousness of containing
	faults can then be mutated in the same order to produce possible
	fixes for the faulty program. The proposed strategy is evaluated
	against the seven benchmark programs of the Siemens suite and the
	Ant program. Results indicate that the strategy is effective at automatically
	suggesting fixes for faults without any human intervention.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICST.2010.66},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05477098.pdf:PDF},
  keywords = {Ant program;Siemens suite;fault localization;faulty program;mutation
	process;fault tolerant computing;program debugging;program testing;},
  nroartigo = {19},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5477098}
}

@INPROCEEDINGS{Debroy2010a,
  author = {Debroy, V. and Wong, W.E. and Xiaofeng Xu and Byoungju Choi},
  title = {A Grouping-Based Strategy to Improve the Effectiveness of Fault Localization
	Techniques},
  booktitle = {Quality Software (QSIC), 2010 10th International Conference on},
  year = {2010},
  pages = {13 -22},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este trabalho prop\~oe uma estrat\'egia baseada em agrupamento que
	pode ser utilizada em conjunto com diversas t\'ecnicas de localiza{\c
	c}\~ao automatizada de defeitos para melhorar a efic\'acia de localiza{\c
	c}\~ao sem necessidade de realizar modifica{\c c}\~oes nas t\'ecnicas.
	Atende aos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {Fault localization is one of the most expensive activities of program
	debugging, which is why the recent years have witnessed the development
	of many different fault localization techniques. This paper proposes
	a grouping-based strategy that can be applied to various techniques
	in order to boost their fault localization effectiveness. The applicability
	of the strategy is assessed over - Tarantula and a radial basis function
	neural network-based technique; across three different sets of programs
	(the Siemens suite, grep and gzip). Results are suggestive that the
	grouping-based strategy is capable of significantly improving the
	fault localization effectiveness and is not limited to any particular
	fault localization technique. The proposed strategy does not require
	any additional information than what was already collected as input
	to the fault localization technique, and does not require the technique
	to be modified in any way.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {S},
  ci5 = {S},
  doi = {10.1109/QSIC.2010.80},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05562940.pdf:PDF},
  issn = {1550-6002},
  keywords = {fault localization effectiveness;grouping based strategy;program debugging;radial
	basis function neural network based technique;fault location;program
	debugging;radial basis function networks;},
  nroartigo = {2},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5562940}
}

@INCOLLECTION{Deursen2010,
  author = {van Deursen, Arie and Mesbah, Ali},
  title = {Research Issues in the Automated Testing of Ajax Applications},
  booktitle = {SOFSEM 2010: Theory and Practice of Computer Science},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {van Leeuwen, Jan and Muscholl, Anca and Peleg, David and PokornÃ½,
	Jaroslav and Rumpe, Bernhard},
  volume = {5901},
  series = {Lecture Notes in Computer Science},
  pages = {16-28},
  note = {10.1007/978-3-642-11266-9\_2},
  abstract = {There is a growing trend to move desktop applications towards the
	web. This move is made possible through advances in web technologies
	collectively known as Asynchronous JavaScript and XML ( ajax ). With
	ajax , the classical model of browsing a series of pages is replaced
	by a JavaScript engine (running in the browser) taking control of
	user interaction, exchanging information updates with the web server
	instead of requesting the complete next page. The benefits of this
	move include no installation costs, automated upgrading for all users,
	increased interactivity, reduced user-perceived latency, and universal
	access, to name a few. ajax , however, comes at a price: the asynchronous,
	stateful nature and the use of Javascript make ajax applications
	particularly error-prone, causing serious dependability threats.
	In this paper, we evaluate to what extent automated testing can be
	used to address these ajax dependability problems. Based on an analysis
	of the current challenges in testing ajax , we formulate directions
	for future research.},
  affiliation = {Delft University of Technology},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Deursen\_2010.pdf:PDF},
  incluido = {N},
  isbn = {978-3-642-11265-2},
  justificativa = {Neste artigo s\~ao avaliadas formas de realizar testes automatizados
	para aplica{\c c}\~oes que utilizam AJAX. Fora dos objetivos da revis\~ao.},
  keyword = {Computer Science},
  nroartigo = {16},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-11266-9\_2}
}

@ARTICLE{Dimitrov2009,
  author = {Dimitrov, Martin and Zhou, Huiyang},
  title = {Anomaly-based bug prediction, isolation, and validation: an automated
	approach for software debugging},
  journal = {SIGPLAN Not.},
  year = {2009},
  volume = {44},
  pages = {61--72},
  month = {March},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo apresenta uma t\'ecnica que automaticamente aponta a localiza{\c
	c}\~ao de defeitos em 3 etapas, atrav\'es da predi{\c c}\~ao de defeitos,
	isolamento do defeito baseado em slicing e valida{\c c}\~ao do defeito,
	que anula a influ\^encia das anomalias suspeitas e verifica o resultado
	da execu{\c c}\~ao. Este artigo est\'a dentro dos crit\'erios de
	inclus\~ao da revis\~ao.},
  abstract = {Software defects, commonly known as bugs, present a serious challenge
	for system reliability and dependability. Once a program failure
	is observed, the debugging activities to locate the defects are typically
	nontrivial and time consuming. In this paper, we propose a novel
	automated approach to pin-point the root-causes of software failures.
	
	
	Our proposed approach consists of three steps. The first step is bug
	prediction, which leverages the existing work on anomaly-based bug
	detection as exceptional behavior during program execution has been
	shown to frequently point to the root cause of a software failure.
	The second step is bug isolation, which eliminates false-positive
	bug predictions by checking whether the dynamic forward slices of
	bug predictions lead to the observed program failure. The last step
	is bug validation, in which the isolated anomalies are validated
	by dynamically nullifying their effects and observing if the program
	still fails. The whole bug prediction, isolation and validation process
	is fully automated and can be implemented with efficient architectural
	support. Our experiments with 6 programs and 7 bugs, including a
	real bug in the gcc 2.95.2 compiler, show that our approach is highly
	effective at isolating only the relevant anomalies. Compared to state-of-art
	debugging techniques, our proposed approach pinpoints the defect
	locations more accurately and presents the user with a much smaller
	code set to analyze.},
  acmid = {1508252},
  address = {New York, NY, USA},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1508284.1508252},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p61-dimitrov.pdf:PDF},
  issn = {0362-1340},
  issue = {3},
  keywords = {architectural support, automated debugging},
  nroartigo = {28},
  numpages = {12},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1508284.1508252}
}

@INPROCEEDINGS{Dinh-Trong2008,
  author = {Dinh-Trong, T. and Geppert, B. and Li, J.J. and Roessler, F.},
  title = {Looking for More Confidence in Refactoring? How to Assess Adequacy
	of Your Refactoring Tests},
  booktitle = {Quality Software, 2008. QSIC '08. The Eighth International Conference
	on},
  year = {2008},
  pages = {255 -263},
  month = {aug.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe um novo crit\'erio de testes adequado para teste
	de regress\~ao para refatora{\c c}\~ao de programas. Fora do escopo
	desta revis\~ao.},
  abstract = {Refactoring is an important technique in today's software development
	practice. If applied correctly, it can significantly improve software
	design without altering behavior. During refactoring, developers
	rely on regression testing. However, without further knowledge about
	the test suite, how can we be confident that regression testing will
	detect potential refactoring faults? To get more insight into adequacy
	of refactoring tests, we therefore suggest test coverage of a refactoring's
	scope of impact as a quantitative measure of confidence. This paper
	shows how to identify a refactoring's scope of impact and proposes
	scope-based test coverage criteria. An example is included that illustrates
	how to use the new test coverage criteria for assessing the adequacy
	of refactoring tests.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2008.49},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04601552.pdf:PDF},
  issn = {1550-6002},
  keywords = {refactoring tests;regression testing;software design;software development;program
	testing;software engineering;},
  nroartigo = {20},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4601552}
}

@INPROCEEDINGS{Dobolyi2010,
  author = {Dobolyi, Kinga and Weimer, Westley},
  title = {Modeling consumer-perceived web application fault severities for
	testing},
  booktitle = {Proceedings of the 19th international symposium on Software testing
	and analysis},
  year = {2010},
  series = {ISSTA '10},
  pages = {97--106},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {É proposta uma t\'ecnica que gera um modelo de defeitos perceb\'iveis
	pelo consumidor de aplica{\c c}\~oes web para prioriza{\c c}\~ao
	de corre{\c c}\~ao por parte dos desenvolvedores. Fora do escopo
	doa revis\~ao.},
  abstract = {Despite the growing usage of web applications, extreme resource constraints
	during their development frequently leave them inadequately tested.
	Because testing may be perceived as having a low return on investment
	for web applications, we believe that providing a consumer-perceived
	fault severity model could allow developers to prioritize faults
	according to their likelihood of impacting consumer retention, encouraging
	web application developers to test more effectively. In a study involving
	386 humans and 800 web application faults, we observe that an arbitrary
	human judgment of fault severity is unreliable. We thus present two
	models of fault severity that outperform individual humans in terms
	of correctly predicting the average consumer-perceived severity of
	web application faults. Our first model uses human annotations of
	fault surface features, and is 87% accurate at identifying low-priority,
	non-severe faults. We also present a fully automated conservative
	model that correctly identifies 55% of non-severe faults without
	missing any severe faults. Both models outperform humans at flagging
	severe faults, and can substitute or reinforce humans by prioritizing
	faults encountered in web application development and testing.},
  acmid = {1831720},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1831708.1831720},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p97-dobolyi.pdf:PDF},
  isbn = {978-1-60558-823-0},
  keywords = {fault, severity, web application},
  location = {Trento, Italy},
  nroartigo = {31},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1831708.1831720}
}

@ARTICLE{Fleurey2009,
  author = {Fleurey, Franck and Baudry, Benoit and Muller, Pierre-Alain and Traon,
	Yves},
  title = {Qualifying input test data for model transformations},
  journal = {Software and Systems Modeling},
  year = {2009},
  volume = {8},
  pages = {185-203},
  note = {10.1007/s10270-007-0074-8},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SpringerLink},
  incluido = {N},
  justificativa = {Este artigo prop\~oe um conjunto de regras e um framework para verificar
	a qualidade de modelos de entrada para testar transforma{\c c}\~oes
	em modelos de transforma{\c c}\~oes e engenharia dirigida por modelos.
	Fora do escopo da revis\~ao.},
  abstract = {Model transformation is a core mechanism for model-driven engineering
	(MDE). Writing complex model transformations is error-prone, and
	efficient testing techniques are required as for any complex program
	development. Testing a model transformation is typically performed
	by checking the results of the transformation applied to a set of
	input models. While it is fairly easy to provide some input models,
	it is difficult to qualify the relevance of these models for testing.
	In this paper, we propose a set of rules and a framework to assess
	the quality of given input models for testing a given transformation.
	Furthermore, the framework identifies missing model elements in input
	models and assists the user in improving these models.},
  affiliation = {IRISA Campus Universitaire de Beaulieu 35042 Rennes Cedex France},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Fleurey\_2009.pdf:PDF},
  issn = {1619-1366},
  issue = {2},
  keyword = {Computer Science},
  nroartigo = {17},
  owner = {higoramario},
  publisher = {Springer Berlin / Heidelberg},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/s10270-007-0074-8}
}

@INPROCEEDINGS{Garousi2010,
  author = {Garousi, Vahid and Koochakzadeh, Negar},
  title = {An empirical evaluation to study benefits of visual versus textual
	test coverage information},
  booktitle = {Proceedings of the 5th international academic and industrial conference
	on Testing - practice and research techniques},
  year = {2010},
  series = {TAIC PART'10},
  pages = {189--193},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {N},
  justificativa = {Esse estudo faz uma avalia{\c c}\~ao comparativa entre o uso de ferramentas
	de cobertura de c\'odigo que fornecem apenas informa{\c c}\~oes textuais
	com uma ferramenta de visualiza{\c c}\~ao de cobertura de c\'odigo
	proposta anteriormente pelos autores. Fora do escopo desta revis\~ao.},
  abstract = {The code coverage tools (e.g., CodeCover for Java) and the textual
	coverage information (e.g., only metric values) they produce are
	very useful for testers. However with increasing size and complexity
	of code bases of both systems under test and also their automated
	test suites (e.g., based on JUnit), there is a need for visualization
	techniques to enable testers to analyze code coverage in higher levels
	of abstraction. To address the above need, we recently proposed a
	test coverage visualization tool. To assess the usability, effectiveness
	and usefulness of this tool in unit testing and test maintenance
	tasks, we have conducted a controlled experiment, the results of
	which show that the tool can benefit testers more compared to textual
	coverage information.},
  acmid = {1885955},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/garousi-10.pdf:PDF},
  isbn = {3-642-15584-7, 978-3-642-15584-0},
  location = {Windsor, UK},
  nroartigo = {23},
  numpages = {5},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://dl.acm.org/citation.cfm?id=1885930.1885955}
}

@INPROCEEDINGS{Gonzalez-Sanchez2011,
  author = {Gonzalez-Sanchez, A. and Gross, H.-G. and van Gemund, A.J.C.},
  title = {Modeling the Diagnostic Efficiency of Regression Test Suites},
  booktitle = {Software Testing, Verification and Validation Workshops (ICSTW),
	2011 IEEE Fourth International Conference on},
  year = {2011},
  pages = {634 -643},
  month = {march},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este trabalho apresenta 2 modelos de efici\^encia de diagn\'ostico
	para conjuntos de testes de regress\~ao. Fora do escopo da revis\~ao.},
  abstract = {Diagnostic performance, measured in terms of the manual effort developers
	have to spend after faults are detected, is not the only important
	quality of a diagnosis. Efficiency, i.e., the number of tests and
	the rate of convergence to the final diagnosis is a very important
	quality of a diagnosis as well. In this paper we present an analytical
	model and a simulation model to predict the diagnostic efficiency
	of test suites when prioritized with the information gain algorithm.
	We show that, besides the size of the system itself, an optimal coverage
	density and uniform coverage distribution are needed to achieve an
	efficient diagnosis. Our models allow us to decide whether using
	IG with our current test suite will provide a good diagnostic efficiency,
	and enable us to define criteria for the generation or improvement
	of test suites.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICSTW.2011.22},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05954476.pdf:PDF},
  keywords = {diagnostic efficiency;information gain algorithm;optimal coverage
	density;regression test suites;uniform coverage distribution;program
	testing;regression analysis;},
  nroartigo = {43},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5954476}
}

@INCOLLECTION{Guo2006,
  author = {Guo, Liang and Roychoudhury, Abhik and Wang, Tao},
  title = {Accurately Choosing Execution Runs for Software Fault Localization},
  booktitle = {Compiler Construction},
  publisher = {Springer Berlin / Heidelberg},
  year = {2006},
  editor = {Mycroft, Alan and Zeller, Andreas},
  volume = {3923},
  series = {Lecture Notes in Computer Science},
  pages = {80-95},
  note = {10.1007/11688839\_7},
  abstract = {Software fault localization involves locating the exact cause of error
	for a "failing" execution run - a run which exhibits an unexpected
	behavior. Given such a failing run, fault localization often proceeds
	by comparing the failing run with a "successful" run, that is, a
	run which does not exhibit the unexpected behavior. One important
	issue here is the choice of the successful run for such a comparison.
	In this paper, we propose a control flow based difference metric
	for this purpose. The difference metric takes into account the sequence
	of statement instances (and not just the set of these instances)
	executed in the two runs, by locating branch instances with similar
	contexts but different outcomes in the failing and the successful
	runs. Given a failing run pi f and a pool of successful runs S ,
	we choose the successful run pi s from S whose execution trace is
	closest to pi f in terms of the difference metric. A bug report is
	then generated by returning the difference between pi f and pi s
	. We conduct detailed experiments to compare our approach with previously
	proposed difference metrics. In particular, we evaluate our approach
	in terms of (a) effectiveness of bug report for locating the bug,
	(b) size of bug report and (c) size of successful run pool required
	to make a decent choice of successful run.},
  affiliation = {School of Computing, National University of Singapore, 117543 Singapore},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Guo\_2006.pdf:PDF},
  incluido = {S},
  isbn = {978-3-540-33050-9},
  justificativa = {O artigo apresenta uma t\'ecnica para localiza{\c c}\~ao de defeitos
	baseada em controle de fluxo que compara a sequ\^encia de comandos
	percorridos em uma execu{\c c}\~ao que falha com um grupo de execu{\c
	c}\~oes de sucesso, e seleciona, dentre esse grupo, a execu{\c c}\~ao
	mais semelhante à execu{\c c}\~ao que falhou atrav\'es de uma m\'etrica
	proposta. A t\'ecnica gera ent\~ao um relat\'orio das diferen{\c
	c}as existentes entre as execu{\c c}\~oes comparadas. Atende aos
	crit\'erios de inclus\~ao.},
  keyword = {Computer Science},
  nroartigo = {2},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/11688839\_7}
}

@inproceedings{hsu2008,
 author = {Hwa-You Hsu and Jones, J. A. and Orso, A.},
 title = {Rapid: Identifying Bug Signatures to Support Debugging Activities},
 booktitle = {Proceedings of the 23th International Conference on Automated Software Engineering},
 series = {ASE '08}, 
 year = {2008},
 pages = {439--442}
} 

@ARTICLE{Huang2007,
  author = {Huang, Tai-Yi and Chou, Pin-Chuan and Tsai, Cheng-Han and Chen, Hsin-An},
  title = {Automated fault localization with statistically suspicious program
	states},
  journal = {SIGPLAN Not.},
  year = {2007},
  volume = {42},
  pages = {11--20},
  month = {June},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo apresenta uma t\'ecnica para refinar a cobertura de c\'odigo
	utilizada para fornecer informa{\c c}\~oes para localiza{\c c}\~ao
	de defeitos atrav\'es da inclus\~ao de informa{\c c}\~oes sobre o
	estado das vari\'aveis de cada ramo executado.},
  abstract = {A number of fault localization techniques have been developed to reduce
	the time in manually debugging a faulty program. The technique of
	code coverage \[8\] has been recognized by its effectiveness in identifying
	suspicious statements that may contain the fault. However, a programmer
	still needs to manually examine each variable referenced in a suspicious
	statement and such a process can become extremely time-consuming
	if this suspicious statement is part of a loop. In this paper, we
	propose a novel technique called state coverage to significantly
	reduce the time in examining variables. We first insert a set of
	checkpoints to record the state of each variable referenced in a
	branching statement. We next execute the faulty program by a test
	suite consisting of both passed and failed cases. A state is statistically
	considered to be more suspicious if it appears more in failed cases
	and less in passed cases. We implemented both code coverage and state
	coverage in a debugging tool and used a commonly-used benchmark consisting
	of 58 faulty programs to evaluate their performance. For 34% of these
	programs, their faults are within 20 statement steps of the most
	suspicious statement identified by code coverage. By adding state
	coverage and breaking at the most suspicious state, we increase this
	ratio to 64%, an 88% performance improvement. Finally, we also explain
	a few cases in which both state coverage and code coverage cannot
	perform well.},
  acmid = {1254769},
  address = {New York, NY, USA},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1273444.1254769},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p11-huang.pdf:PDF},
  issn = {0362-1340},
  issue = {7},
  keywords = {automated debugging, fault localization, state coverage},
  nroartigo = {26},
  numpages = {10},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1273444.1254769}
}

@INPROCEEDINGS{Jiang2010,
  author = {Bo Jiang and Chan, W.K.},
  title = {On the Integration of Test Adequacy, Test Case Prioritization, and
	Statistical Fault Localization},
  booktitle = {Quality Software (QSIC), 2010 10th International Conference on},
  year = {2010},
  pages = {377 -384},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma avalia{\c c}\~ao emp\'irica da integra{\c c}\~ao
	entre conjuntos de teste utilizando 16 diferentes estrat\'egias de
	teste em 4 t\'ecnicas de localiza{\c c}\~ao estat\'istica de defeitos,
	de forma semelhante a outro artigo encontrado nesta mesma biblioteca
	(IEEE Xplore) proposto pelos mesmo autores. N\~ao pro\~oe nenhuma
	t\'ecnica nova para localiza{\c c}\~ao de defeitos, estando fora
	dos crit\'erios de inclus\~ao.},
  abstract = {Testing and debugging account for at least 30% of the project effort.
	Scientific advancements in individual activities or their integration
	may bring significant impacts to the practice of software development.
	Fault localization is the foremost debugging sub-activity. Any effective
	integration between testing and debugging should address how well
	testing and fault localization can be worked together productively.
	How likely does a testing technique provide test suites for effective
	fault localization? To what extent may such a test suite be prioritized
	so that the test cases having higher priority can be effectively
	used in a standalone manner to support fault localization? In this
	paper, we empirically study these two research questions in the context
	of test data adequacy, test case prioritization and statistical fault
	localization. Our preliminary postmortem analysis results on 16 test
	case prioritization techniques and four statistical fault localizations
	show that branch-adequate test suites on the Siemens suite are unlikely
	to support effective fault localization. On the other hand, if such
	a test suite is effective, around 60% of the test cases can be further
	prioritized to support effective fault localization, which indicates
	that the potential savings in terms of effort can be significant.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2010.64},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05562990.pdf:PDF},
  issn = {1550-6002},
  keywords = {Siemens suite;branch adequate test suite;continuous integration;software
	debugging;software development;statistical fault localization;test
	adequacy;test case prioritization;continuous improvement;program
	debugging;program testing;software metrics;software quality;statistical
	analysis;},
  nroartigo = {12},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5562990}
}

@INPROCEEDINGS{Jiang2011,
  author = {Jiang, Bo and Chan, W.K. and Tse, T.H.},
  title = {On Practical Adequate Test Suites for Integrated Test Case Prioritization
	and Fault Localization},
  booktitle = {Quality Software (QSIC), 2011 11th International Conference on},
  year = {2011},
  pages = {21 -30},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo faz um estudo para verificar os efeitos de utiliza{\c c}\~ao
	de 16 diferentes crit\'erios de teste em 4 t\'ecnicas de localiza{\c
	c}\~ao estat\'istica de defeitos, verificando a adequa{\c c}\~ao
	para depura{\c c}\~ao. Embora n\~ao apresente nenhuma nova t\'ecnica
	de depura{\c c}\~ao, pode ser lido para auxiliar na defini{\c c}\~ao
	dos crit\'erios de teste de integra{\c c}\~ao a serem utilizados.
	O artigo n\~ao se adequa a esta revis\~ao.},
  abstract = {An effective integration between testing and debugging should address
	how well testing and fault localization can work together productively.
	In this paper, we report an empirical study on the effectiveness
	of using adequate test suites for fault localization. We also investigate
	the integration of test case prioritization and statistical fault
	localization with a postmortem analysis approach. Our results on
	16 test case prioritization techniques and four statistical fault
	localization techniques show that, although much advancement has
	been made in the last decade, test adequacy criteria are still insufficient
	in supporting effective fault localization. We also find that the
	use of branch-adequate test suites is more likely than statement-adequate
	test suites in the effective support of statistical fault localization.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2011.37},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/06004308.pdf:PDF},
  issn = {1550-6002},
  nroartigo = {11},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6004308}
}

@INPROCEEDINGS{Jiang2009,
  author = {Jiang, Bo and Zhang, Zhenyu and Chan, W. K. and Tse, T. H.},
  title = {Adaptive Random Test Case Prioritization},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2009},
  series = {ASE '09},
  pages = {233--244},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para gera{\c c}\~ao de casos de
	teste para realizar teste de regress\~ao, fora dos objetivos desta
	revis\~ao.},
  abstract = {Regression testing assures changed programs against unintended amendments.
	Rearranging the execution order of test cases is a key idea to improve
	their effectiveness. Paradoxically, many test case prioritization
	techniques resolve tie cases using the random selection approach,
	and yet random ordering of test cases has been considered as ineffective.
	Existing unit testing research unveils that adaptive random testing
	(ART) is a promising candidate that may replace random testing (RT).
	In this paper, we not only propose a new family of coverage-based
	ART techniques, but also show empirically that they are statistically
	superior to the RT-based technique in detecting faults. Furthermore,
	one of the ART prioritization techniques is consistently comparable
	to some of the best coverage-based prioritization techniques (namely,
	the "additional" techniques) and yet involves much less time cost.},
  acmid = {1747523},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/ASE.2009.77},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/3891a233.pdf:PDF},
  isbn = {978-0-7695-3891-4},
  keywords = {Adaptive random testing, test case prioritization},
  nroartigo = {13},
  numpages = {12},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dx.doi.org/10.1109/ASE.2009.77}
}

@INPROCEEDINGS{Jiang2009a,
  author = {Bo Jiang and Zhenyu Zhang and Tse, T.H. and Chen, T.Y.},
  title = {How Well Do Test Case Prioritization Techniques Support Statistical
	Fault Localization},
  booktitle = {Computer Software and Applications Conference, 2009. COMPSAC '09.
	33rd Annual IEEE International},
  year = {2009},
  volume = {1},
  pages = {99 -106},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este trabalho faz uma avalia{\c c}\~ao emp\'irica dos efeitos de t\'ecnicas
	de prioriza{\c c}\~ao de casos de teste em t\'ecnicas de localiza{\c
	c}\~ao de defeitos j\'a existentes. Este artigo est\'a entre os crit\'erios
	de exclus\~ao da revis\~ao.},
  abstract = {In continuous integration, a tight integration of test case prioritization
	techniques and fault-localization techniques may both expose failures
	faster and locate faults more effectively. Statistical fault-localization
	techniques use the execution information collected during testing
	to locate faults. Executing a small fraction of a prioritized test
	suite reduces the cost of testing, and yet the subsequent fault localization
	may suffer. This paper presents the first empirical study to examine
	the impact of test case prioritization on the effectiveness of fault
	localization. Among many interesting empirical results, we find that
	coverage-based and random techniques can be more effective than distribution-based
	techniques in supporting statistical fault localization.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2009.23},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05254274.pdf:PDF},
  issn = {0730-3157},
  keywords = {code compilation;continuous integration;coverage-based technique;debugging
	technique;distribution-based technique;empirical study;prioritized
	test suite;random technique;software process integration;statistical
	fault localization technique;test case prioritization technique;testing
	cost reduction;cost reduction;program compilers;program debugging;program
	testing;random processes;software cost estimation;software fault
	tolerance;statistical distributions;},
  nroartigo = {8},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5254274}
}

@ARTICLE{Kanstr\'en2008,
  author = {Kanstr\'en, T.},
  title = {Towards a deeper understanding of test coverage},
  journal = {Journal of Software Maintenance and Evolution},
  year = {2008},
  volume = {20},
  pages = {59-76},
  number = {1},
  note = {cited By (since 1996) 5},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {N},
  justificativa = {O trabalho apresenta uma t\'ecnica que faz a distin{\c c}\~ao da cobertura
	de c\'odigo atingida por conjuntos de testes levando em considera{\c
	c}\~ao as etapas de teste e as diferentes parte de um software. O
	experimento \'e realizado em projeto open source real. Fora do escopo
	da revis\~ao.},
  abstract = {Test coverage is traditionally considered as how much of the code
	is covered by the test suite in whole. However, test suites typically
	contain different types of tests with different roles, such as unit
	tests, integration tests and functional tests. As traditional measures
	of test coverage make no distinction between the different types
	of tests, the overall view of test coverage is limited to what is
	covered by the tests in general. This paper proposes a quantitative
	way to measure the test coverage of the different parts of the software
	at different testing levels. It is also shown how this information
	can be used in software maintenance and development to further evolve
	the test suite and the system under test. The technique is applied
	to an open-source project to show its application in practice. Copyright
	2007 John Wiley \& Sons, Ltd.},
  affiliation = {VTT Technical Research Center of Finland, Kaitov 1, Oulu FI-90571,
	Finland},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Kanstren2008.pdf:PDF},
  nroartigo = {40},
  owner = {higoramario},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-40049103889\&partnerID=40\&md5=e77bcc2381671dbcd91019ea68683e79}
}

@INPROCEEDINGS{Kapfhammer2008,
  author = {Kapfhammer, Gregory M. and Soffa, Mary Lou},
  title = {Database-aware test coverage monitoring},
  booktitle = {Proceedings of the 1st India software engineering conference},
  year = {2008},
  series = {ISEC '08},
  pages = {77--86},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este trabalho apresenta uma t\'ecnica de monitoramento de cobertura
	de testes para aplica{\c c}\~oes centrada em bancos de dados, fazendo
	uso das entidades do banco de dados durante a execu{\c c}\~ao dos
	testes. Fora dos objetivos desta revis\~ao.},
  abstract = {Unlike traditional programs, a database-centric application interacts
	with a database that has a complex state and structure. Even though
	the database is an important component of modern software, there
	are few tools to support the testing of database-centric applications.
	This paper presents a test coverage monitoring technique that tracks
	a program's definition and use of database entities during test suite
	execution. The paper also describes instrumentation probes that construct
	a coverage tree that records how the program and the tests cover
	the database. We conducted experiments to measure the costs that
	are associated with (i) instrumenting the program and the tests and
	(ii) monitoring coverage. For all of the applications, the experiments
	demonstrate that the instrumentation mechanism incurs an acceptable
	time overhead. While the use of statically inserted probes may increase
	the size of an application, this approach enables database-aware
	coverage monitoring that increases testing time from 13% to no more
	than 54%},
  acmid = {1342228},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1342211.1342228},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/kapfhammer-08.pdf:PDF},
  isbn = {978-1-59593-917-3},
  keywords = {database application, test coverage monitoring},
  location = {Hyderabad, India},
  nroartigo = {35},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1342211.1342228}
}

@ARTICLE{Karam2008,
  author = {Karam, Marcel R. and Smedley, Trevor J. and Dascalu, Sergiu M.},
  title = {Unit-level test adequacy criteria for visual dataflow languages and
	a testing methodology},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {2008},
  volume = {18},
  pages = {1:1--1:40},
  month = {October},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma metodologia para realiza{\c c}\~ao de testes
	automatizados para linguagens de visualiza{\c c}\~ao de fluxo de
	dados, propondo um crit\'erio para realiza{\c c}\~ao de testes e
	verificando sua efic\'acia para localiza{\c c}\~ao de defeitos. A
	t\'ecnica utilizada para localiza{\c c}\~ao de defeitos \'e baseada
	em SFL, n\~ao propondo nenhuma inova{\c c}\~ao para depura{\c c}\~ao.
	O trabalho est\'a fora dos objetivos desta revis\~ao.},
  abstract = {Visual dataflow languages (VDFLs), which include commercial and research
	systems, have had a substantial impact on end-user programming. Like
	any other programming languages, whether visual or textual, VDFLs
	often contain faults. A desire to provide programmers of these languages
	with some of the benefits of traditional testing methodologies has
	been the driving force behind our effort in this work. In this article
	we introduce, in the context of prograph, a testing methodology for
	VDFLs based on structural test adequacy criteria and coverage. This
	article also reports on the results of two empirical studies. The
	first study was conducted to obtain meaningful information about,
	in particular, the effectiveness of our all-Dus criteria in detecting
	a reasonable percentage of faults in VDFLs. The second study was
	conducted to evaluate, under the same criterion, the effectiveness
	of our methodology in assisting users to visually localize faults
	by reducing their search space. Both studies were conducted using
	a testing system that we have implemented in Prograph's IDE.},
  acmid = {1391985},
  address = {New York, NY, USA},
  articleno = {1},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1391984.1391985},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/a1-karam.pdf:PDF},
  issn = {1049-331X},
  issue = {1},
  keywords = {Software testing, color, fault detection, fault localization, visual
	dataflow languages},
  nroartigo = {12},
  numpages = {40},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1391984.1391985}
}

@ARTICLE{Kiciman2010,
  author = {Kiciman, Emre and Livshits, Benjamin},
  title = {AjaxScope: A Platform for Remotely Monitoring the Client-Side Behavior
	of Web 2.0 Applications},
  journal = {ACM Trans. Web},
  year = {2010},
  volume = {4},
  pages = {13:1--13:52},
  month = {September},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para realizar instrumenta{\c c}\~ao
	no lado cliente de aplica{\c c}\~oes web 2.0, permitindo capturar
	o comportamento de tais aplica{\c c}\~oes durante o uso. Fora do
	escopo da revis\~ao.},
  abstract = {The rise of the software-as-a-service paradigm has led to the development
	of a new breed of sophisticated, interactive applications often called
	Web 2.0. While Web applications have become larger and more complex,
	Web application developers today have little visibility into the
	end-to-end behavior of their systems. This article presents AjaxScope,
	a dynamic instrumentation platform that enables cross-user monitoring
	and just-in-time control of Web application behavior on end-user
	desktops. AjaxScope is a proxy that performs on-the-fly parsing and
	instrumentation of JavaScript code as it is sent to users’ browsers.
	AjaxScope provides facilities for distributed and adaptive instrumentation
	in order to reduce the client-side overhead, while giving fine-grained
	visibility into the code-level behavior of Web applications. We present
	a variety of policies demonstrating the power of AjaxScope, ranging
	from simple error reporting and performance profiling to more complex
	memory leak detection and optimization analyses. We also apply our
	prototype to analyze the behavior of over 90 Web 2.0 applications
	and sites that use significant amounts of JavaScript.},
  acmid = {1841910},
  address = {New York, NY, USA},
  articleno = {13},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1841909.1841910},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/a13-kiciman.pdf:PDF},
  issn = {1559-1131},
  issue = {4},
  keywords = {Applications, software instrumentation, software monitoring},
  nroartigo = {18},
  numpages = {52},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1841909.1841910}
}

@INPROCEEDINGS{Kim2010,
  author = {Kim, Sejun and Baik, Jongmoon},
  title = {An effective fault aware test case prioritization by incorporating
	a fault localization technique},
  booktitle = {Proceedings of the 2010 ACM-IEEE International Symposium on Empirical
	Software Engineering and Measurement},
  year = {2010},
  series = {ESEM '10},
  pages = {5:1--5:10},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para prioriza{\c c}\~ao de casos
	de teste que utiliza informa{\c c}\~oes do hist\'orico de defeitos
	encontrados para realizar essa prioriza{\c c}\~ao. Fora do escopo
	da revis\~ao.},
  abstract = {Prior coverage-based test case prioritization techniques aim to increase
	fault detection rates by ordering the test cases according to some
	coverage criteria. However, in practice, since detected faults are
	typically removed, test cases that already covered the previously
	executed areas might not perform well as expected, irrespective of
	their coverage. In this case, the ordering of test cases based on
	coverage information might not be effective. In this paper, we introduce
	a new test case prioritization technique that considers both coverage
	and historical fault information by incorporating fault localization
	technique. Using the historical fault detection information of test
	cases, our approach adjusts the priorities of fault-found test cases
	while maintaining test cases with high coverage in high priority.
	Our approach can reduce the total cost of executing entire test suite(s)
	and enables to detect faults earlier in a testing process by improving
	the testing effectiveness compared to the prior coverage-based techniques.},
  acmid = {1852793},
  articleno = {5},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1852786.1852793},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/a5-kim.pdf:PDF},
  isbn = {978-1-4503-0039-1},
  keywords = {fault localization, regression testing, test case prioritization},
  location = {Bolzano-Bozen, Italy},
  nroartigo = {17},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1852786.1852793}
}

@ARTICLE{Ko2011,
  author = {Ko, Andrew J. and Abraham, Robin and Beckwith, Laura and Blackwell,
	Alan and Burnett, Margaret and Erwig, Martin and Scaffidi, Chris
	and Lawrance, Joseph and Lieberman, Henry and Myers, Brad and Rosson,
	Mary Beth and Rothermel, Gregg and Shaw, Mary and Wiedenbeck, Susan},
  title = {The state of the art in end-user software engineering},
  journal = {ACM Comput. Surv.},
  year = {2011},
  volume = {43},
  pages = {21:1--21:44},
  month = {April},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo discute o que se tem feito em pesquisa na \'area de engenharia
	de software voltada para usu\'arios finais. Fora do escopo da revis\~ao.},
  acmid = {1922658},
  address = {New York, NY, USA},
  articleno = {21},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1922649.1922658},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/a21-ko.pdf:PDF},
  issn = {0360-0300},
  issue = {3},
  keywords = {End-user software engineering, end-user development, end-user programming,
	human-computer interaction, visual programming},
  nroartigo = {46},
  numpages = {44},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1922649.1922658}
}

@INCOLLECTION{Koochakzadeh2010,
  author = {Koochakzadeh, Negar and Garousi, Vahid},
  title = {TeCReVis: A Tool for Test Coverage and Test Redundancy Visualization},
  booktitle = {Testing - Practice and Research Techniques},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Bottaci, Leonardo and Fraser, Gordon},
  volume = {6303},
  series = {Lecture Notes in Computer Science},
  pages = {129-136},
  note = {10.1007/978-3-642-15585-7\_12},
  abstract = {This tool paper presents the feature set, graphical user interface
	and also the implementation details of a test coverage and test redundancy
	visualization tool, called TeCReVis . The tool is an Eclipse plug-in
	and supports JUnit test suites helping testers in analyzing the coverage
	information more effectively in a visual way compared to traditional
	text-based coverage tools.},
  affiliation = {Software Quality Engineering Research Group (SoftQual), Department
	of Electrical and Computer Eng., University of Calgary, Alberta,
	Canada},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Koochakzadeh\_2010.pdf:PDF},
  incluido = {N},
  isbn = {978-3-642-15584-0},
  justificativa = {Este artigo apresenta uma ferramenta de visualiza{\c c}\~ao de cobertura
	de c\'odigo e redundância de teste desenvolvida como plug-in para
	o Eclipse. Fora do escopo da revis\~ao.},
  keyword = {Computer Science},
  nroartigo = {14},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-15585-7\_12}
}

@INPROCEEDINGS{LeGoues2010,
  author = {Le Goues, Claire and Forrest, Stephanie and Weimer, Westley},
  title = {The case for software evolution},
  booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering
	research},
  year = {2010},
  series = {FoSER '10},
  pages = {205--210},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma abordagem te\'orica sobre a evolu{\c c}\~ao da
	complexidade dos sistemas computacionais existentes, tra{\c c}ando
	um paralelo com a evolu{\c c}\~ao biol\'ogica. O objetivo \'e propor
	id\'eias para os pesquisadores da \'area de engenharia de software
	pensem em solu{\c c}\~oes que possam ser inspiradas nos ecossistemas
	biol\'ogicos. Fora do escopo desta revis\~ao.},
  abstract = {Many software systems exceed our human ability to comprehend and manage,
	and they continue to contain unacceptable errors. This is an unintended
	consequence of Moore's Law, which has led to increases in system
	size, complexity, and interconnectedness. Yet, software is still
	primarily created, modified, and maintained by humans. The interactions
	among heterogeneous programs, machines and human operators has reached
	a level of complexity rivaling that of some biological ecosystems.
	By viewing software as an evolving complex system, researchers could
	incorporate biologically inspired mechanisms and employ the quantitative
	analysis methods of evolutionary biology. This approach could improve
	our understanding and analysis of software; it could lead to robust
	methods for automatically writing, debugging and improving code;
	and it could improve predictions about functional and structural
	transitions as scale increases. In the short term, an evolutionary
	perspective challenges several research assumptions, enabling advances
	in error detection, correction, and prevention.},
  acmid = {1882406},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1882362.1882406},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p205-legoues.pdf:PDF},
  isbn = {978-1-4503-0427-6},
  keywords = {evolutionary computation, genetic programming, program repair, software
	engineering},
  location = {Santa Fe, New Mexico, USA},
  nroartigo = {8},
  numpages = {6},
  owner = {higoramario},
  timestamp = {2011.09.15},
  url = {http://doi.acm.org/10.1145/1882362.1882406}
}

@INPROCEEDINGS{Lee2010,
  author = {Hua Jie Lee and Naish, L. and Ramamohanarao, K.},
  title = {Effective Software Bug Localization Using Spectral Frequency Weighting
	Function},
  booktitle = {Computer Software and Applications Conference (COMPSAC), 2010 IEEE
	34th Annual},
  year = {2010},
  pages = {218 -227},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica que utiliza uma fun{\c c}\~ao que
	leva em considera{\c c}\~ao a frequ\^encia em que cada comando foi
	executado durante os testes realizados. Atende aos crit\'erios de
	inclus\~ao da revis\~ao.},
  abstract = {This paper presents an approach of bug localization using a frequency
	weighting function. In an existing approach, only binary information
	of execution count from test executions is used. Information of each
	program statement being executed and not executed by a particular
	test is used; indicated by 1 and 0 respectively. In our proposed
	approach, frequency execution count of each program statement executed
	by a respective test is used. We evaluate several well-known spectra
	metrics using our proposed approach and the existing approach (using
	binary information of execution count) on two test suites; Siemens
	Test Suite and Unix datasets. We show that the bug localization performance
	is improved by using our proposed approach. We conduct statistical
	test and show that the improved bug localization performance using
	our approach (using frequency execution count) is statistically significant
	than using the existing approach (using binary information of execution
	count).},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2010.26},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05676260.pdf:PDF},
  issn = {0730-3157},
  keywords = {Siemens test suite;Unix datasets;software bug localization;spectra
	metrics;spectral frequency weighting function;statistical test;program
	debugging;software metrics;statistical testing;},
  nroartigo = {53},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5676260}
}


@INPROCEEDINGS{Lee2009a,
  author = {Hua Jie Lee and Naish, L. and Ramamohanarao, K.},
  title = {The effectiveness of using non redundant test cases with program
	spectra for bug localization},
  booktitle = {Computer Science and Information Technology, 2009. ICCSIT 2009. 2nd
	IEEE International Conference on},
  year = {2009},
  pages = {127 -134},
  month = {aug.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo aborda o uso de testes n\~ao redundantes para localiza{\c
	c}\~ao de defeitos usando uma t\'ecnica de SFL existente. Est\'a
	fora dos intuitos da revis\~ao por se tratar dos dados utilizados
	em t\'ecnica j\'a existente. No entanto, merece ser lido para averiguar
	os resultados obtidos.},
  abstract = {In this paper, we present our approach of using non redundant test
	cases with program spectra (one of the automated bug localization
	techniques) to locate software bugs in a program. We evaluate several
	spectra metrics (functions mapped from program spectra) using the
	non redundant test cases. Extensive evaluation on Siemens Test Suite
	and subset of Unix datasets shows the effectiveness of locating bug
	using non redundant test cases with program spectra. In this paper,
	we also show that by adding duplicates of non redundant test cases,
	the stability and performance of spectra metrics are affected.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICCSIT.2009.5234587},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05234587.pdf:PDF},
  keywords = {Siemens Test Suite;Unix datasets;automated bug localization techniques;bug
	localization;functions mapping;nonredundant test cases;program spectra;software
	bugs;spectra metrics;program debugging;program testing;software maintenance;software
	metrics;},
  nroartigo = {56},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5234587}
}

@ARTICLE{Liu2008,
  author = {Chao Liu and Xiangyu Zhang and Jiawei Han},
  title = {A Systematic Study of Failure Proximity},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2008},
  volume = {34},
  pages = {826 -843},
  number = {6},
  month = {nov.-dec. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo prop\~oe uma t\'ecnica para avaliar sistematicamente a proximidade
	entre falhas ocorridas em programa usando uma escala de proximidade.
	trabalho n\~ao atende aos crit\'erios de inclus\~ao desta evis\~ao,
	mas pode ser \'util no desenvolvimento de uma t\'ecnica que leve
	em cnsidera{\c c}\~ao a exist\^encia de m\'ultiplos defeitos. Ser\'a
	lido posteriormente.},
  abstract = {Software end-users are the best testers, who keep revealing bugs in
	software that has undergone rigorous in-house testing. In order to
	leverage their testing efforts, failure reporting components have
	been widely deployed in released software. Many utilities of the
	collected failure data depend on an effective failure indexing technique,
	which, at the optimal case, would index all failures due to the same
	bug together. Unfortunately, the problem of failure proximity, which
	underpins the effectiveness of an indexing technique, has not been
	systematically studied. This article presents the first systematic
	study of failure proximity. A failure proximity consists of two components:
	a fingerprinting function that extracts signatures from failures,
	and a distance function that calculates the likelihood of two failures
	being due to the same bug. By considering different instantiations
	of the two functions, we study an array of six failure proximities
	(two of them are new) in this article. These proximities range from
	the simplest approach that checks failure points to the most sophisticated
	approach that utilizes fault localization algorithms to extract failure
	signatures. Besides presenting technical details of each proximity,
	we also study the properties of each proximity and tradeoffs between
	proximities. These altogether deliver a systematic view of failure
	proximity.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2008.66},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04589219.pdf:PDF},
  issn = {0098-5589},
  keywords = {debugging aids;failure indexing technique;failure proximity;in-house
	testing;signature extraction;software end-users;software maintenance;program
	debugging;program testing;software fault tolerance;software maintenance;},
  nroartigo = {32},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4589219}
}

@INPROCEEDINGS{Liu2010,
  author = {Xuemei Liu and Yongpo Liu and Ji Wu and Xiaoxia Jia},
  title = {Finding suspicious patterns of object-oriented programs based on
	variance analysis},
  booktitle = {Fuzzy Systems and Knowledge Discovery (FSKD), 2010 Seventh International
	Conference on},
  year = {2010},
  volume = {6},
  pages = {2815 -2820},
  month = {aug.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {O artigo prop\~oe uma abordagem para localiza{\c c}\~ao de defeitos
	em programas orientados a objetos baseados no comportamento de modelos
	dos objetos utilizando an\'alise de variância. A t\'ecnica procura
	por comportamentos suspeitos de objetos para indicar os poss\'iveis
	defeitos.},
  abstract = {Several variance analysis methods that are used in fault localization
	based on program behaviors were analyzed and compared. None of these
	methods takes into account the features of object-oriented programs,
	thus, could not be used accurately in fault localization in object-oriented
	programs. The present study proposed that when doing variance analysis,
	object behaviors could be described by using the object life behavior
	model; then a behavior model of the object-oriented program was constructed
	based on the model; the similarity of program behaviors was described
	by using the sequence pattern. Based on the variance analysis of
	program behaviors, the method of finding suspicious patterns of object-oriented
	programs was proposed. The model of finding suspicious patterns was
	also constructed. This model consisted of preparing data, extracting
	patterns, and finding suspicious patterns. The standard for pattern
	extracting was defined and the mining algorithms of finding patterns
	were also described. At last, the method of finding suspicious patterns
	based on variance analysis and its implementation procedure were
	depicted in detail. This method has been used in the research of
	fault localization and has been very effective. This work is supported
	by the National Natural Science Foundation of China under grant No.
	60603039.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/FSKD.2010.5569241},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05569241.pdf:PDF},
  keywords = {fault localization;object life behavior model;object-oriented program;pattern
	extraction;pattern mining algorithm;program behavior;sequence pattern;software
	debugging;suspicious pattern;variance analysis;data mining;object-oriented
	programming;program debugging;software fault tolerance;},
  nroartigo = {25},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5569241}
}

@INPROCEEDINGS{Lopez2011,
  author = {Lopez, Nicolas and van der Hoek, Andr\'e},
  title = {The code orb: supporting contextualized coding via at-a-glance views
	(NIER track)},
  booktitle = {Proceeding of the 33rd international conference on Software engineering},
  year = {2011},
  series = {ICSE '11},
  pages = {824--827},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica para contextualiza{\c c}\~ao de
	c\'odigo chamada Code Orb, que visa fornecer informa{\c c}\~oes ao
	programa sobre trechos do c\'odigo existente devem receber maior
	aten{\c c}\~ao, feito atrav\'es de t\'ecnicas de an\'alise de c\'odigo
	existentes. O artigo est\'a fora do escopo desta revis\~ao.},
  abstract = {While code is typically presented as a flat file to a developer who
	must change it, this flat file exists within a context that can drastically
	influence how a developer approaches changing it. While the developer
	clearly must be careful changing any code, they probably should be
	yet more careful in changing code that recently saw major changes,
	is barely covered by test cases, and was the source of a number of
	bugs. Contextualized coding refers to the ability of the developer
	to effectively use such contextual information while they work on
	some changes. In this paper, we introduce the Code Orb, a contextualized
	coding tool that builds upon existing mining and analysis techniques
	to warn developers on a line-by-line basis of the volatility of the
	code they are working on. The key insight underneath the Code Orb
	is that it is neither desired nor possible to always present a code's
	context in its entirety; instead, it is necessary to provide an abstracted
	view of the context that informs the developer of which parts of
	the code they need to pay more attention to. This paper discusses
	the principles of and rationale behind contextualized coding, introduces
	the Code Orb, and illustrates its function with example code and
	context drawn from the Mylyn \[11\] project.},
  acmid = {1985914},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1985793.1985914},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p824-lopez.pdf:PDF},
  isbn = {978-1-4503-0445-0},
  keywords = {code orb, contextualized coding, recommendation systems, software
	visualization},
  location = {Waikiki, Honolulu, HI, USA},
  nroartigo = {43},
  numpages = {4},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://doi.acm.org/10.1145/1985793.1985914}
}

@INCOLLECTION{Madeyski2007,
  author = {Madeyski, Lech},
  title = {On the Effects of Pair Programming on Thoroughness and Fault-Finding
	Effectiveness of Unit Tests},
  booktitle = {Product-Focused Software Process Improvement},
  publisher = {Springer Berlin / Heidelberg},
  year = {2007},
  editor = {MÃ¼nch, JÃ¼rgen and Abrahamsson, Pekka},
  volume = {4589},
  series = {Lecture Notes in Computer Science},
  pages = {207-221},
  note = {10.1007/978-3-540-73460-4\_20},
  abstract = {Code coverage and mutation score measure how thoroughly tests exercise
	programs and how effective they are, respectively. The objective
	is to provide empirical evidence on the impact of pair programming
	on both, thoroughness and effectiveness of test suites, as pair programming
	is considered one of the practices that can make testing more rigorous,
	thorough and effective. A large experiment with MSc students working
	solo and in pairs was conducted. The subjects were asked to write
	unit tests using JUnit, and to follow test-driven development approach,
	as suggested by eXtreme Programming methodology. It appeared that
	branch coverage, as well as mutation score indicator (the lower bound
	on mutation score), was not significantly affected by using pair
	programming, instead of solo programming. However, slight but insignificant
	positive impact of pair programming on mutations score indicator
	was noticeable. The results do not support the positive impact of
	pair programming on testing to make it more effective and thorough.
	The generalization of the results is limited due to the fact that
	MSc students participated in the study. It is possible that the benefits
	of pair programming will exceed the results obtained in this experiment
	for larger, more complex and longer projects.},
  affiliation = {Institute of Applied Informatics, Wroclaw University of Technology,
	Wyb.Wyspianskiego 27, 50370 Wroclaw Poland},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Madeyski\_2007.pdf:PDF},
  incluido = {N},
  isbn = {978-3-540-73459-8},
  justificativa = {O artigo busca avaliar o impacto do uso de programa{\c c}\~ao em pares
	e test-driven development atrav\'es das medidas de cobertura de c\'odigo
	e mutation score para os casos de teste gerados. Fora do escopo da
	revis\~ao.},
  keyword = {Computer Science},
  nroartigo = {8},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-540-73460-4\_20}
}

@INCOLLECTION{Madeyski2010,
  author = {Madeyski, Lech and Madeyski, Lech},
  title = {Research Goals, Conceptual Model and Variables Selection},
  booktitle = {Test-Driven Development},
  publisher = {Springer Berlin Heidelberg},
  year = {2010},
  pages = {25-37},
  note = {10.1007/978-3-642-04288-1\_3},
  abstract = {This chapter presents research goals and the high level conceptual
	model used to guide the research along with the independent, the
	dependent and possible confounding variables.},
  affiliation = {Software Engineering Department, Wroclaw University of Technology,
	Institute of Informatics (I-32), Wybrzeze Wyspianskiego 27, 50-370
	Wroclaw, Poland},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {S},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-3-642-04288-1},
  justificativa = {Este cap\'itulo do livro trata de objetivos de pesquisa e conceitos
	de alto n\'ivel relacionados com test-driven development. Fora do
	escopo da revis\~ao. O texto integral n\~ao est\'a dispon\'ivel.},
  keyword = {Computer Science},
  nroartigo = {10},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-04288-1\_3}
}


@INPROCEEDINGS{Masri2009,
  author = {Masri, Wes and Abou-Assi, Rawad and El-Ghali, Marwa and Al-Fatairi,
	Nour},
  title = {An empirical study of the factors that reduce the effectiveness of
	coverage-based fault localization},
  booktitle = {Proceedings of the 2nd International Workshop on Defects in Large
	Software Systems: Held in conjunction with the ACM SIGSOFT International
	Symposium on Software Testing and Analysis (ISSTA 2009)},
  year = {2009},
  series = {DEFECTS '09},
  pages = {1--5},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo aborda fatores que podem prejudicar o desempenho de t\'ecnicas
	de localiza{\c c}\~ao de defeitos existentes atrav\'es de experimentos
	realizados em 4 diferentes cen\'arios propostos. O trabalho atende
	aos crit\'erios de inclus\~ao.},
  abstract = {Coverage-based fault localization techniques typically assign a suspiciousness
	rank to the statements in a program following an analysis of the
	coverage of certain types of program elements by the failing and
	passing runs. The effectiveness of existing techniques has been limited
	despite the fact that researchers have explored various suspiciousness
	metrics, ranking strategies, and types of program elements. This
	work aims at identifying the factors that impair coverage-based fault
	localization. Specifically, we conducted an empirical study in which
	we assessed the prevalence of the following scenarios: 1) the condition
	for failure is met but the program does not fail; 2) the faulty statement
	is executed but the program does not fail; 3) the failure is correlated
	with a combination of more than one program element possibly of different
	types; 4) a large number of program elements occurred in all failing
	runs but in no passing runs.
	
	
	The study was conducted using 148 seeded versions of ten Java programs
	which included three releases of NanoXML, and seven programs from
	the Siemens test suite that were converted to Java. The results showed
	that most of the above scenarios occur frequently.},
  acmid = {1555862},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {S},
  ci5 = {S},
  doi = {http://doi.acm.org/10.1145/1555860.1555862},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p1-masri.pdf:PDF},
  isbn = {978-1-60558-654-0},
  keywords = {Siemens test suite for Java, coincidental correctness, combinations
	of program elements, coverage-based fault localization, genetic algorithm},
  location = {Chicago, Illinois},
  nroartigo = {41},
  numpages = {5},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1555860.1555862}
}

@INPROCEEDINGS{Masri2010a,
  author = {Masri, W. and Assi, R.A.},
  title = {Cleansing Test Suites from Coincidental Correctness to Enhance Fault-Localization},
  booktitle = {Software Testing, Verification and Validation (ICST), 2010 Third
	International Conference on},
  year = {2010},
  pages = {165 -174},
  month = {april},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este trabalho apresenta uma t\'ecnica que tem como objetivo identificar
	casos de teste executados com sucesso mas que possuem c\'odigo defeituoso,
	chamados de coincidentemente corretos. Com isso, pretende-se melhorar
	os resultados para localiza{\c c}\~ao de defeitos. Um trabalho interessante
	para leitura, pois trata dos casos de falsos negativos, que muitas
	vezes necessitam ser tratados pelas t\'ecnicas de depura{\c c}\~ao
	autom\'atica para melhorar a efici\^encia dos resultados. Fora do
	escopo da revis\~ao.},
  abstract = {Researchers have argued that for failure to be observed the following
	three conditions must be met: 1) the defect is executed, 2) the program
	has transitioned into an infectious state, and 3) the infection has
	propagated to the output. Coincidental correctness arises when the
	program produces the correct output, while conditions 1) and 2) are
	met but not 3). In previous work, we showed that coincidental correctness
	is prevalent and demonstrated that it is a safety reducing factor
	for coverage-based fault localization. This work aims at cleansing
	test suites from coincidental correctness to enhance fault localization.
	Specifically, given a test suite in which each test has been classified
	as failing or passing, we present three variations of a technique
	that identify the subset of passing tests that are likely to be coincidentally
	correct. We evaluated the effectiveness of our techniques by empirically
	quantifying the following: 1) how accurately did they identify the
	coincidentally correct tests, 2) how much did they improve the effectiveness
	of coverage-based fault localization, and 3) how much did coverage
	decrease as a result of applying them. Using our better performing
	technique and configuration, the safety and precision of fault-localization
	was improved for 88% and 61% of the programs, respectively.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICST.2010.22},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05477086.pdf:PDF},
  keywords = {cleansing test suites;coincidental correctness;fault localization
	enhancement;infectious state;fault location;program testing;},
  nroartigo = {14},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5477086}
}

@INPROCEEDINGS{Murtaza2008,
  author = {Murtaza, S.S. and Gittens, M. and Madhavji, N.},
  title = {Discovering the Fault Origin from Field Traces},
  booktitle = {Software Reliability Engineering, 2008. ISSRE 2008. 19th International
	Symposium on},
  year = {2008},
  pages = {295 -296},
  month = {nov.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	que se baseia em field traces (chamadas de fun{\c c}\~oes) para depura{\c
	c}\~ao autom\'atica, identificando padr\~oes entre as execu{\c c}\~oes
	destas chamadas para indicar o local do defeito. Atende aos requisitos
	desta revis\~ao.},
  abstract = {This paper proposes an automatic technique to reduce the time spent
	in detection of the fault origin from field traces, by discovering
	hidden patterns in the traces.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ISSRE.2008.57},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/04700343.pdf:PDF},
  issn = {1071-9458},
  keywords = {fault origin;field traces;trace hidden patterns;program debugging;software
	fault tolerance;software maintenance;},
  nroartigo = {22},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4700343}
}

@INPROCEEDINGS{Murtaza2010,
  author = {Murtaza, Syed Shariyar and Gittens, Mechelle and Li, Zude and Madhavji,
	Nazim H.},
  title = {F007: finding rediscovered faults from the field using function-level
	failed traces of software in the field},
  booktitle = {Proceedings of the 2010 Conference of the Center for Advanced Studies
	on Collaborative Research},
  year = {2010},
  series = {CASCON '10},
  pages = {57--71},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo aborda a redescoberta de defeitos no n\'ivel de fun{\c
	c}\~oes. prop\~oe uma t\'ecnica identificar fun{\c c}\~oes defeituosas
	utilizando informa{\c c}\~oes de execu{\c c}\~ao de c\'odigo. Para
	uma fun{\c c}\~ao, pode ser considerada como um teste funcional.
	Tal abordagem pode ser interessante para fazer uso de integra{\c
	c}\~ao, mas n\~ao se adequa aos prop\'ositos dessa revis\~ao.},
  abstract = {Studies show that approximately 50% to 90% of the failures reported
	from the field are rediscoveries of previous faults. Also, approximately
	80% of the failures originate from approximately 20% of the code.
	Despite this identification of the origin of the failures in system
	code remains an arduous activity, and consumes substantial resources.
	Prior fault discovery techniques for field traces either require
	many pass-fail traces, discover only crashing failures, or identify
	faulty coarse grain code such as files as the source of the fault.
	This paper describes a new method (F007) that focuses on identifying
	finer grain faulty code (faulty functions) from only failed traces
	of deployed software. F007 extracts patterns of function-calls from
	a historical collection of only function-level failed traces, and
	then trains decision trees on the extracted function-call patterns
	for each known faulty function. A ranked list of faulty functions
	is then predicted by F007 for a new failure trace based on the probability
	of fault proneness obtained via decision trees. Our case study on
	the Siemens suite shows that F007: (a) can identify rediscovered
	faulty functions (with new or old faults) with 60--86% accuracy,
	(b) needs to examine approximately 5--10% of the code for the Siemens
	suite, and (c) can discover the faulty functions in every new failed
	trace by using a small collection of previous failed traces. Thus,
	F007 can correctly identify the faulty functions for the majority
	(80%-90%) of (field) failures with the knowledge of a fault in a
	small percentage (20%) of functions.},
  acmid = {1923954},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1923947.1923954},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p57-murtaza.pdf:PDF},
  location = {Toronto, Ontario, Canada},
  nroartigo = {22},
  numpages = {15},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1923947.1923954}
}

@book{Myers2004,
  author = {Myers, G. J. and Sandler, Corey and Badgett, Tom and Thomas, Todd M.},
  title = {The Art of Software Testing},
  edition = {2},
  publisher = {John Wiley \& Sons},
  year = 2004
}


@ARTICLE{Naish2011,
  author = {Naish, Lee and Lee, Hua Jie and Ramamohanarao, Kotagiri},
  title = {A model for spectra-based software diagnosis},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year = {2011},
  volume = {20},
  pages = {11:1--11:32},
  month = {August},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma tecnica para a localiza{\c c}\~ao de defeitos
	em software utilizando um modelo simplificado. Dentro dos crit\'erios
	de inclus\~ao.},
  abstract = {This article presents an improved approach to assist diagnosis of
	failures in software (fault localisation) by ranking program statements
	or blocks in accordance with to how likely they are to be buggy.
	We present a very simple single-bug program to model the problem.
	By examining different possible execution paths through this model
	program over a number of test cases, the effectiveness of different
	proposed spectral ranking methods can be evaluated in idealised conditions.
	The results are remarkably consistent to those arrived at empirically
	using the Siemens test suite and Space benchmarks. The model also
	helps identify groups of metrics that are equivalent for ranking.
	Due to the simplicity of the model, an optimal ranking method can
	be devised. This new method out-performs previously proposed methods
	for the model program, the Siemens test suite and Space. It also
	helps provide insight into other ranking methods.},
  acmid = {2000795},
  address = {New York, NY, USA},
  articleno = {11},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/2000791.2000795},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/a11-naish.pdf:PDF},
  issn = {1049-331X},
  issue = {3},
  keywords = {Fault localization, program spectra, statistical debugging},
  nroartigo = {37},
  numpages = {32},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/2000791.2000795}
}

@INPROCEEDINGS{Namin2011,
  author = {Namin, Akbar Siami and Kakarla, Sahitya},
  title = {The use of mutation in testing experiments and its sensitivity to
	external threats},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing
	and Analysis},
  year = {2011},
  series = {ISSTA '11},
  pages = {342--352},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma an\'alise comparativa da utiliza{\c c}\~ao de
	muta{\c c}\~ao com defeitos existentes em programas reais para avaliar
	sua efic\'acia para valida{\c c}\~ao de t\'ecnicas de teste e suas
	limita{\c c}\~oes. Fora do escopo desta revis\~ao.},
  abstract = {Mutation analysts has emerged as a standard approach for empirical
	assessment of testing techniques. The test practitioners decide about
	cost-effectiveness of testing strategies based on the number of mutants
	the testing techniques detect. Though fundamental rigor to empirical
	software testing, the use of mutants in the absence of real-world
	faults has raised the concern of whether mutants and real faults
	exhibit similar properties. This paper revisits this important concern
	and disseminates interesting findings regarding mutants and whether
	these synthetic faults can predict fault detection ability of test
	suites. The results of controlled experiments conducted in this paper
	show that mutation when used in testing experiments is highly sensitive
	to external threats caused by some influential factors including
	mutation operators, test suite size, and programming languages. This
	paper raises the awareness message of the use of mutation in testing
	experiment and suggests that any interpretation or generalization
	of experimental findings based on mutation should be justified according
	to the influential factors involved.},
  acmid = {2001461},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/2001420.2001461},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p342-namin.pdf:PDF},
  isbn = {978-1-4503-0562-4},
  keywords = {experimental design, hand-seeded faults, mutants, mutation testing,
	real faults, statistical analysis},
  location = {Toronto, Ontario, Canada},
  nroartigo = {23},
  numpages = {11},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/2001420.2001461}
}

@INPROCEEDINGS{Nguyen2007,
  author = {Nguyen, Nguyet T. M. and Soffa, Mary Lou},
  title = {Program representations for testing wireless sensor network applications},
  booktitle = {Workshop on Domain specific approaches to software test automation:
	in conjunction with the 6th ESEC/FSE joint meeting},
  year = {2007},
  series = {DOSTA '07},
  pages = {20--26},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma representa{\c c}\~ao de execu{\c c}\~ao
	baseada em grafos para aplica{\c c}\~oes para redes de sensores wireless
	que pode ser usada para desenvolver ferramentes de testes para este
	tipo de aplica{\c c}\~ao.},
  abstract = {Because of the growing complexity of wireless sensor network applications
	(WSNs), traditional software development tools are being developed
	that are specifically designed for their special characteristics.
	However, testing tools have yet to be proposed. One problem in developing
	testing tools is the need for a program representation that expresses
	the execution behavior. Due to characteristics of WSN applications
	that use a concurrent, event-based execution model, a representation
	is challenging to develop. In this paper, we present novel representations
	for WSNs applications that express the execution behavior of event
	and tasks, the major components of a WSN application. Our representations
	include a task posting graph, an event graph and finally an application
	graph that expresses the relationships among events and tasks as
	well as both timing and environmental interrupts. These representations
	are the first step in developing testing tools for WSN applications.
	Based on the graphs, traditional and event-based coverage criteria
	can be evaluated. When combined with individual Control Flow Graphs(CFGs)
	of events and tasks, the graphs' paths can be used as a criterion
	for evaluating the completeness of the test cases.},
  acmid = {1294925},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1294921.1294925},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p20-nguyen.pdf:PDF},
  isbn = {978-1-59593-726-1},
  keywords = {program representation, test criteria, wireless sensor networks},
  location = {Dubrovnik, Croatia},
  nroartigo = {27},
  numpages = {7},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1294921.1294925}
}

@INPROCEEDINGS{Nica2011,
  author = {Nica, S.},
  title = {On the Improvement of the Mutation Score Using Distinguishing Test
	Cases},
  booktitle = {Software Testing, Verification and Validation (ICST), 2011 IEEE Fourth
	International Conference on},
  year = {2011},
  pages = {423 -426},
  month = {march},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta uma t\'ecnica de teste de muta{\c c}\~ao combinada
	com restri{\c c}\~oes de sistemas para gera{\c c}\~ao de casos de
	teste. Fora do escopo da revis\~ao.},
  abstract = {Software testing, i.e., discovering software failures through test
	case execution, plays a crucial role in the software development
	process. A high quality software must have a strong test suite. Therefore
	it is of high importance for a software to evaluate the test suite
	that is asserting its correctness. Mutation testing is one efficient
	method to evaluate the process of software testing, i.e., the quality
	of the test suite. The current research focuses on mutation testing
	as a metric that can be used not only for establishing a reliable
	testing process, but also for improving the test case generation
	process, when the quality of the test suite is proven to be unsatisfactory.
	More over we aim to come with a solution to the equivalent mutant
	problem, by combing mutation testing and constraint systems.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICST.2011.40},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05770634.pdf:PDF},
  keywords = {constraint system;distinguishing test case;mutation score;mutation
	testing;software development process;software failure;software testing;test
	case execution;test case generation process;test suite;program testing;software
	engineering;},
  nroartigo = {54},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5770634}
}

@ARTICLE{Pandey2011,
  author = {Pandey, Ajeet and Shrivastava, Vivek},
  title = {Early fault detection model using integrated and cost-effective test
	case prioritization},
  journal = {International Journal of Systems Assurance Engineering and Management},
  year = {2011},
  volume = {2},
  pages = {41-47},
  note = {10.1007/s13198-011-0056-7},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SpringerLink},
  incluido = {N},
  justificativa = {O artigo apresenta uma nova t\'ecnica para prioriza{\c c}\~ao de casos
	de teste de regress\~ao. Fora do escopo da revis\~ao.},
  abstract = {Regression testing is one of the important software maintenance activities
	that let the software tester to ensure the quality and reliability
	of modified program. Although the regression testing is expensive,
	it is necessary to validate the software after every modification.
	To reduce the cost of regression testing, software tester may utilize
	test cases prioritization techniques. One potential goal prioritization
	is to increase a test suite's rate of fault detection. An improved
	rate of fault detection can provide earlier feedback on the system,
	enabling earlier debugging. APFD (Average Percentage of Fault Detected)
	metric is used to measure the test suite's fault detection rate.
	This paper presents an integrated test case prioritization approach
	to increase the test suite's fault detection rate. Three important
	factors such as program change level (PCL), test suite change level
	(TCL) and test suite size (TS) are considered to prioritize test
	cases. Proposed approach is applied on different in-house programs
	to validate its accuracy. Model results are found to be promising
	when compared with optimal prioritization techniques which always
	results an upper bound of APFD values.},
  affiliation = {Cognizant Technology Solutions, Hyderabad, India},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/Pandey\_2011.pdf:PDF},
  issn = {0975-6809},
  issue = {1},
  keyword = {Engineering},
  nroartigo = {13},
  owner = {higoramario},
  publisher = {Springer India},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/s13198-011-0056-7}
}

@INPROCEEDINGS{Park2010,
  author = {Park, Sangmin and Vuduc, Richard W. and Harrold, Mary Jean},
  title = {Falcon: fault localization in concurrent programs},
  booktitle = {Proceedings of the 32nd ACM/IEEE International Conference on Software
	Engineering - Volume 1},
  year = {2010},
  series = {ICSE '10},
  pages = {245--254},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo aborda uma nova t\'ecnica de localiza{\c c}\~ao de defeitos
	para programas concorrentes, fazendo uso de padr\~oes de acesso de
	dados compartilhados entre as threads e os resultados de execu{\c
	c}\~ao de testes para indicar os poss\'iveis defeitos. Como a abordagem
	\'e espec\'ifica para compartilhamento de dados entre threads, n\~ao
	traz uma abordagem que possa ser utilizada para os prop\'ositos desta
	revis\~ao.},
  abstract = {Concurrency fault are difficult to find because they usually occur
	under specific thread interleavings. Fault-detection tools in this
	area find data-access patterns among thread interleavings, but they
	report benign patterns as well as actual faulty patterns. Traditional
	fault-localization techniques have been successful in identifying
	faults in sequential, deterministic programs, but they cannot detect
	faulty data-access patterns among threads. This paper presents a
	new dynamic fault-localization technique that can pinpoint faulty
	data-access patterns in multi-threaded concurrent programs. The technique
	monitors memory-access sequences among threads, detects data-access
	patterns associated with a program's pass/fail results, and reports
	dataaccess patterns with suspiciousness scores. The paper also presents
	the description of a prototype implementation of the technique in
	Java, and the results of an empirical study we performed with the
	prototype on several Java benchmarks. The empirical study shows that
	the technique can effectively and efficiently localize the faults
	for our subjects.},
  acmid = {1806838},
  ce1 = {N},
  ce2 = {S},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1806799.1806838},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p245-park.pdf:PDF},
  isbn = {978-1-60558-719-6},
  keywords = {atomicity violation, concurrency, debugging, fault localization, order
	violation},
  location = {Cape Town, South Africa},
  nroartigo = {29},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1806799.1806838}
}


@INPROCEEDINGS{Polikarpova2009,
  author = {Polikarpova, Nadia and Ciupa, Ilinca and Meyer, Bertrand},
  title = {A comparative study of programmer-written and automatically inferred
	contracts},
  booktitle = {Proceedings of the eighteenth international symposium on Software
	testing and analysis},
  year = {2009},
  series = {ISSTA '09},
  pages = {93--104},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma compara{\c c}\~ao entre contratos (elementos de
	especifica{\c c}\~oes presetes no c\'odigo) gerados automaticamente
	e escritos por programadores. N\~ao tem rela{\c c}\~ao com os crit\'erios
	de inclus\~ao},
  abstract = {Where do contracts - specification elements embedded in executable
	code - come from? To produce them, should we rely on the programmers,
	on automatic tools, or some combination?
	
	
	Recent work, in particular the Daikon system, has shown that it is
	possible to infer some contracts automatically from program executions.
	The main incentive has been an assumption that most programmers are
	reluctant to invent the contracts themselves. The experience of contract-supporting
	languages, notably Eiffel, disproves that assumption: programmers
	will include contracts if given the right tools. That experience
	also shows, however, that the resulting contracts are generally partial
	and occasionally incorrect.
	
	
	Contract inference tools provide the opportunity for studying objectively
	the quality of programmer-written contracts, and for assessing the
	respective roles of humans and tools. Working on 25 classes taken
	from different sources such as widely-used standard libraries and
	code written by students, we applied Daikon to infer contracts and
	compared the results (totaling more than 19500 inferred assertion
	clauses) with the already present contracts.
	
	
	We found that a contract inference tool can be used to strengthen
	programmer-written contracts, but cannot infer all contracts that
	humans write. The tool generates around five times as many relevant
	assertion clauses as written by programmers; but it only finds around
	60% of those originally written by programmers. Around a third of
	the generated assertions clauses are either incorrect or irrelevant.
	The study also uncovered interesting correlations between the quality
	of inferred contracts and some code metrics.},
  acmid = {1572284},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1572272.1572284},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p93-polikarpova.pdf:PDF},
  isbn = {978-1-60558-338-9},
  keywords = {dynamic contract inference, eiffel},
  location = {Chicago, IL, USA},
  nroartigo = {39},
  numpages = {12},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1572272.1572284}
}

@ARTICLE{Porter2007,
  author = {Porter, A. and Yilmaz, C. and Memon, A.M. and Schmidt, D.C. and Natarajan,
	B.},
  title = {Skoll: A Process and Infrastructure for Distributed Continuous Quality
	Assurance},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2007},
  volume = {33},
  pages = {510 -525},
  number = {8},
  month = {aug. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma nova abordagem para processos de garantia
	de qualidade de software, adequados a ambientes de desenvolvimento
	distribu\'idos e continuos. Prop\~oe tamb\'em novos processos de
	garantia de qualidade necess\'arios para essa proposta e uma ferramenta
	para permitir a utiliza{\c c}\~ao de processos de garantia de qualidade
	distribu\'idas e cont\'inuas. Fora do escopo desta revis\~ao.},
  abstract = {Software engineers increasingly emphasize agility and flexibility
	in their designs and development approaches. They increasingly use
	distributed development teams, rely on component assembly and deployment
	rather than green field code writing, rapidly evolve the system through
	incremental development and frequent updating, and use flexible product
	designs supporting extensive end-user customization. While agility
	and flexibility have many benefits, they also create an enormous
	number of potential system configurations built from rapidly changing
	component implementations. Since today's quality assurance (QA) techniques
	do not scale to handle highly configurable systems, we are developing
	and validating novel software QA processes and tools that leverage
	the extensive computing resources of user and developer communities
	in a distributed, continuous manner to improve software quality significantly.
	This paper provides several contributions to the study of distributed,
	continuous QA (DCQA). First, it shows the structure and functionality
	of Skoll, which is an environment that defines a generic around-the-world,
	around-the-clock QA process and several sophisticated tools that
	support this process. Second, it describes several novel QA processes
	built using the Skoll environment. Third, it presents two studies
	using Skoll: one involving user testing of the Mozilla browser and
	another involving continuous build, integration, and testing of the
	ACE+TAO communication software package. The results of our studies
	suggest that the Skoll environment can manage and control distributed
	continuous QA processes more effectively than conventional QA processes.
	For example, our DCQA processes rapidly identified problems that
	had taken the ACE+TAO developers much longer to find and several
	of which they had not found. Moreover, the automatic analysis of
	QA results provided developers information that enabled them to quickly
	find the root causes of problems},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2007.70719},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04267023.pdf:PDF},
  issn = {0098-5589},
  keywords = {ACE+TAO communication software package;Skoll;component assembly;component
	deployment;distributed continuous quality assurance;distributed development
	teams;end-user customization;flexible product design;incremental
	development;software engineering;software quality;distributed processing;object-oriented
	programming;software quality;systems analysis;},
  nroartigo = {58},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4267023}
}

@INPROCEEDINGS{Qu2007,
  author = {Bo Qu and Changhai Nie and Baowen Xu and Xiao fang Zhang},
  title = {Test Case Prioritization for Black Box Testing},
  booktitle = {Computer Software and Applications Conference, 2007. COMPSAC 2007.
	31st Annual International},
  year = {2007},
  volume = {1},
  pages = {465 -474},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica para prioriza{\c c}\~ao de casos
	de teste de regress\~ao para teste de caiza-preta. Fora dos objetivos
	da revis\~ao.},
  abstract = {Test case prioritization is an effective and practical technique that
	helps to increase the rate of regression fault detection when software
	evolves. Numerous techniques have been reported in the literature
	on prioritizing test cases for regression testing. However, existing
	prioritization techniques implicitly assume that source or binary
	code is available when regression testing is performed, and therefore
	cannot be implemented when there is no program source or binary code
	to be analyzed. In this paper, we presented a new technique for black
	box regression testing, and we performed an experiment to measure
	our technique. Our results show that the new technique is helpful
	to improve the effectiveness of fault detection when performing regression
	test in black box environment.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2007.209},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04291039.pdf:PDF},
  issn = {0730-3157},
  keywords = {black box regression testing;regression fault detection;test case
	prioritization;fault diagnosis;program testing;regression analysis;},
  nroartigo = {42},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4291039}
}

@INPROCEEDINGS{Qu2009,
  author = {Xiao Qu},
  title = {Configuration aware prioritization techniques in regression testing},
  booktitle = {Software Engineering - Companion Volume, 2009. ICSE-Companion 2009.
	31st International Conference on},
  year = {2009},
  pages = {375 -378},
  month = {may},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O presente artigo apresenta um framework para prioriza{\c c}\~ao de
	teste de regress\~ao focado em configura{\c c}\~ao, voltado a sistemas
	parametriz\'aveis. Fora dos objetivos desta revis\~ao.},
  abstract = {Configurable software lets users customize applications in many ways,
	and is becoming increasingly prevalent. Regression testing is an
	important but expensive way to build confidence that software changes
	introduce no new faults as software evolves, resulting in many attempts
	to improve its performance given limited resources. Whereas problems
	such as test selection and prioritization at the test case level
	have been extensively researched in the regression testing literature,
	they have rarely been considered for configurations, though there
	is evidence that we should not ignore the effects of configurations
	on regression testing. This research intends to provide a framework
	for configuration aware prioritization techniques, evaluated through
	empirical studies.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICSE-COMPANION.2009.5071025},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05071025.pdf:PDF},
  keywords = {configurable software;configuration aware prioritization technique;regression
	testing;test selection;program testing;software engineering;},
  nroartigo = {55},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5071025}
}

@INPROCEEDINGS{Riboira2010,
  author = {Riboira, Andr\'e and Abreu, Rui},
  title = {The GZoltar project: a graphical debugger interface},
  booktitle = {Proceedings of the 5th international academic and industrial conference
	on Testing - practice and research techniques},
  year = {2010},
  series = {TAIC PART'10},
  pages = {215--218},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma ferramenta gr\'afica (GZoltar), baseada em
	uma ferramenta de execu{\c c}\~ao de t\'ecnicas de localiza{\c c}\~ao
	de defeitos j\'a existente (Zoltar), para visualizar as informa{\c
	c}\~oes obtidas pela execu{\c c}\~ao de t\'ecnicas de localiza{\c
	c}\~ao de defeitos. O trabalho n\~ao apresenta nenhuma nova t\'ecnica,
	estando fora dos objetivos desta revis\~ao. No entanto, pode ser
	uma leitura posterior para avaliar a possibilidade de uso dessa ferramenta.},
  abstract = {Software debugging is one of the most time-consuming and expensive
	tasks in software development. There are several tools that contribute
	to this process to become faster and more efficient, but are not
	integrated with each other, nor provide an intuitive interface. These
	tools can be integrated to create an IDE plug-in, which gathers the
	most important debugging information into one place. GZoltar is a
	new project to create that missing plug-in. The main goal of GZoltar
	project is to reduce debugging process time and costs.},
  acmid = {1885961},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/riboira\_abreu\_10.pdf:PDF},
  isbn = {3-642-15584-7, 978-3-642-15584-0},
  keywords = {code dependency graphs, debug, project hierarchy trees, spectrum-based
	fault localization},
  location = {Windsor, UK},
  nroartigo = {27},
  numpages = {4},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://dl.acm.org/citation.cfm?id=1885930.1885961}
}

@INCOLLECTION{Roychowdhury2011,
  author = {Roychowdhury, Shounak and Khurshid, Sarfraz},
  title = {A Novel Framework for Locating Software Faults Using Latent Divergences},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  publisher = {Springer Berlin / Heidelberg},
  year = {2011},
  editor = {Gunopulos, Dimitrios and Hofmann, Thomas and Malerba, Donato and
	Vazirgiannis, Michalis},
  volume = {6913},
  series = {Lecture Notes in Computer Science},
  pages = {49-64},
  note = {10.1007/978-3-642-23808-6\_4},
  abstract = {Fault localization, i.e., identifying erroneous lines of code in a
	buggy program, is a tedious process, which often requires considerable
	manual effort and is costly. Recent years have seen much progress
	in techniques for automated fault localization, specifically using
	program spectra - executions of failed and passed test runs provide
	a basis for isolating the faults. Despite the progress, fault localization
	in large programs remains a challenging problem, because even inspecting
	a small fraction of the lines of code in a large problem can require
	substantial manual effort. This paper presents a novel framework
	for fault localization based on latent divergences - an effective
	method for feature selection in machine learning. Our insight is
	that the problem of fault localization can be reduced to the problem
	of feature selection, where lines of code correspond to features.
	We also present an experimental evaluation of our framework using
	the Siemens suite of subject programs, which are a standard benchmark
	for studying fault localization techniques in software engineering.
	The results show that our framework enables more accurate fault localization
	than existing techniques.},
  affiliation = {Department of Electrical and Computer Engineering, University of Texas,
	Austin, Texas 78712-0240, USA},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Roychowdhury\_2011.pdf:PDF},
  incluido = {S},
  isbn = {978-3-642-23807-9},
  justificativa = {Este artigo prop\~oe uma nova t\'ecnica de localiza{\c c}\~ao de defeitos
	baseada em diverg\^encias latentes, que \'e um m\'etodo de sele{\c
	c}\~ao de caracter\'isticas para aprendizado de m\'aquina. Os comandos
	de um programa s\~ao analisados como caracter\'isticas. Atende aos
	crit\'erios de inclus\~ao.},
  keyword = {Computer Science},
  nroartigo = {9},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-23808-6\_4}
}

@ARTICLE{Schneidewind2010,
  author = {Schneidewind, N. and Montrose, M. and Feinberg, A. and Ghazarian,
	A. and McLinn, J. and Hansen, C. and Laplante, P. and Sinnadurai,
	N. and Zio, E. and Linger, R. and Wong, W. E. and Shieh, S. and Childs,
	J},
  title = {IEEE Reliability Society Technical Operations Annual Technical Report
	for 2010},
  journal = {Reliability, IEEE Transactions on},
  year = {2010},
  volume = {59},
  pages = {449 -482},
  number = {3},
  month = {sept. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Relat\'orio t\'ecnico anual sobre confiabilidade de infraestrutura.
	Fora do escopo da revis\~ao.},
  abstract = {The Annual Technical Report this year is focused on infrastructure
	reliability. Infrastructure constitutes those things that are apparent
	only in their absence. We take the infrastructure for granted, assuming
	it will always be there. We turn on our water facet, and drinkable
	water has always flowed out, for most of us, most of the time. Our
	infrastructure is subject to environment breakages (e.g., earthquakes),
	accidents (e.g., dig ups of cables), sabotage, intrusion, and compromise.
	Also everyday component, software or system failures can bring our
	infrastructure down. Our global connectivity and communications,
	as well as our world wide distributed development and maintenance
	systems, increase our productivity and efficiency, but can also increase
	our vulnerabilities. Our critical infrastructures can be found in
	many places.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TR.2010.2052190},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05510015.pdf:PDF},
  issn = {0018-9529},
  nroartigo = {38},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5510015}
}

@INPROCEEDINGS{Soffa2011,
  author = {Soffa, Mary Lou and Walcott, Kristen R. and Mars, Jason},
  title = {Exploiting hardware advances for software testing and debugging:
	NIER track},
  booktitle = {Proceeding of the 33rd international conference on Software engineering},
  year = {2011},
  series = {ICSE '11},
  pages = {888--891},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo trata das possibilidade de uso dos mecanismos de monitoramento
	de hardware para uso em automatiza{\c c}\~ao de testes e depura{\c
	c}\~ao. Foge aos objetivos da revis\~ao, por\'em pode ser uma boa
	leitura posterior.},
  abstract = {Despite the emerging ubiquity of hardware monitoring mechanisms and
	prior research work in other fields, the applicability and usefulness
	of hardware monitoring mechanisms have not been fully scrutinized
	for software engineering.
	
	
	In this work, we identify several recently developed hardware mechanisms
	that lend themselves well to structural test overage analysis and
	automated fault localization and explore their potential. We discuss
	key factors impacting the applicability of hardware monitoring mechanism
	for these software engineering tasks, present novel online analyses
	leveraging these mechanisms, and provide preliminary results demonstrating
	the promise of this emerging hardware.},
  acmid = {1985935},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1985793.1985935},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p888-soffa.pdf:PDF},
  isbn = {978-1-4503-0445-0},
  keywords = {branch testing, fault localization, performance monitoring},
  location = {Waikiki, Honolulu, HI, USA},
  nroartigo = {52},
  numpages = {4},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1985793.1985935}
}

@INCOLLECTION{Stanley2009,
  author = {Stanley, William and Laski, Janusz and Laski, Janusz and Stanley,
	William},
  title = {Is There a Bug in the Program? Structural Program Testing},
  booktitle = {Software Verification and Analysis},
  publisher = {Springer London},
  year = {2009},
  pages = {173-202},
  note = {10.1007/978-1-84882-240-5\_8},
  abstract = {As Black-Box (BB) testing (see Chap. 4), Structural (White-Box) program
	testing is an experiment with the program, in which the actual program
	results are compared with the expected ones, prescribed by the testing
	"oracle," ideally the program specification. However, in structural
	testing, tests are synthesized on the basis of the code itself, rather
	than its specification. A structural testing strategy is defined
	in terms of Required Elements , i.e, program statements, or combinations
	thereof, that are to be exercised. The best known coverage criteria
	are expressed in terms of simple properties of the flow of control:
	These are statement and branch coverage. Less known, but potentially
	more powerful are data flow coverage criteria: Definition-Use Chains
	(Data Dependency in Chap. 7) and its generalization U(se)-Context
	. All four strategies are supported by STAD. However, due to the
	difficulties of test synthesis structural testing as a stand-alone
	method is currently out of the question. It can only be used as a
	measure of completeness of BB-testing. The main weakness of structural
	testing is the lack of sound theoretical foundations. To remedy this
	situation, an attempt has been made to (1) define formally the notions
	of program faults and errors in terms of the program verification
	schema and (2) formulate testing strategies in terms of program dependencies.
	Also, it has been suggested that besides the standard "main" objective
	of program testing, the detection of the fault, testing also offers
	a measure of fault localization and, for a passing test suite, the
	degree of confidence that the program is indeed correct.},
  affiliation = {Sof Tools, Inc., Rochester Hills, USA},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {S},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-1-84882-240-5},
  justificativa = {Este cap\'itulo do livro fala sobre teste estrutural de software de
	modo geral. N\~ao atende aos crit\'erios de inclus\~ao, al\'em de
	o texto integral n\~ao estar dispon\'ivel.},
  keyword = {Computer Science},
  nroartigo = {7},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-1-84882-240-5\_8}
}

@INPROCEEDINGS{Subrahmaniyan2008,
  author = {Subrahmaniyan, Neeraja and Burnett, Margaret and Bogart, Christopher},
  title = {Software visualization for end-user programmers: trial period obstacles},
  booktitle = {Proceedings of the 4th ACM symposium on Software visualization},
  year = {2008},
  series = {SoftVis '08},
  pages = {135--144},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo traz um estudo de caso que investiga oportunidades para
	melhorias em programas oferecidos para avalia{\c c}\~ao a usu\'arios
	finais. Fora dos objetivos da revis\~ao.},
  abstract = {Software visualization for end-user programmers is a relatively unexplored
	opportunity area. There are advances in software visualization research
	pertinent to this, but the adoption stage has been entirely ignored.
	In this paper, we focus on a popular facilitator of adoption decisions:
	the free trial period. We conducted a case study of an end-user programmer
	(an accountant) in this situation, as she tried out a commercial
	spreadsheet visualization tool to make an adoption decision. The
	results have implications for both theory and design, revealing open
	questions, design opportunities, and strengths and weaknesses of
	theoretical foundations.},
  acmid = {1409742},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1409720.1409742},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p135-subrahmaniyan.pdf:PDF},
  isbn = {978-1-60558-112-5},
  keywords = {end-user software engineering, software adoption, software visualization,
	spreadsheets},
  location = {Ammersee, Germany},
  nroartigo = {6},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1409720.1409742}
}

@ARTICLE{Sumner2011a,
  author = {Sumner, W. and Zheng, Y. and Weeratunge, D. and Zhang, X.},
  title = {Precise Calling Context Encoding},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2011},
  volume = {PP},
  pages = {1},
  number = {99},
  month = { },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo trata de uma t\'ecnica para codificar chamadas de fun{\c
	c}\~oes para facilitar o acesso a tais informa{\c c}\~oes e diminuir
	a sobrecarga e armazenamento. Fora do escopo da revis\~ao.},
  abstract = {Calling contexts are very important for a wide range of applications
	such as profiling, debugging, and event logging. Most applications
	perform expensive stack walking to recover contexts. The resulting
	contexts are often explicitly represented as a sequence of call sites
	and hence bulky. We propose a technique to encode the current calling
	context of any point during an execution. In particular, an acyclic
	call path is encoded into one number through only integer additions.
	Recursive call paths are divided into acyclic subsequences and encoded
	independently. We leverage stack depth in a safe way to optimize
	encoding: if a calling context can be safely and uniquely identified
	by its stack depth, we do not perform encoding. We propose an algorithm
	to seamlessly fuse encoding and stack depth based identification.
	The algorithm is safe because different contexts are guaranteed to
	have different IDs. It also ensures contexts can be faithfully decoded.
	Our experiments show that our technique incurs negligible overhead
	(0%-6.4% on average). For most medium-sized programs, it can encode
	all contexts with just one number. For large programs, we are able
	to encode most calling contexts to a few numbers. We also present
	our experience of applying context encoding to debugging crash based
	failures.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2011.70},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05963696.pdf:PDF},
  issn = {0098-5589},
  nroartigo = {37},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5963696}
}

@INPROCEEDINGS{Sumner2011,
  author = {Sumner, William N. and Bao, Tao and Zhang, Xiangyu},
  title = {Selecting peers for execution comparison},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing
	and Analysis},
  year = {2011},
  editor = {14},
  series = {ISSTA '11},
  pages = {309--319},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo faz uma compara{\c c}\~ao entre 5 t\'ecnicas para selecionar
	pares de execu{\c c}\~ao e prop\~oe uma m\'etrica para compar\'a-las.
	O objetivo desses pares de execu{\c c}\~ao \'e fornecer informa{\c
	c}\~oes para o processo de depura{\c c}\~ao. As t\'ecnicas s\~ao
	avaliadas em tr\^es programas existentes que cont\'em 20 defeitos
	reais. É uma abordagem diferente das verificadas anteriormente para
	acrescentar informa{\c c}\~oes para depura{\c c}\~ao, fazendo parte
	dos crit\'erios de inclus\~ao desta revis\~ao.},
  abstract = {Execution comparison is becoming more common as a means of debugging
	faulty programs or simply explaining program behavior. Often, such
	as when debugging, the goal is to understand particular aspects of
	a single execution, and it is not immediately clear against what
	we should compare this execution. Prior work has led to approaches
	for acquiring a second execution, or peer, with which to compare
	the first. The earliest of these searched test suites for suitable
	candidates. More recent work focuses on synthesizing a new execution,
	either by generating new input for the program or by directly mutating
	the execution itself. In spite of these proposals, it is unclear
	what advantages these different techniques for finding peers might
	have over each other. In this paper, we implement five different
	existing techniques and examine their impact on 20 real bugs. These
	bugs represent the full set of reported bugs for three programs during
	one year. We present a metric to evaluate the quality of the peers.
	It is based on the similarity of the peers to the executions of the
	patched programs. We also discuss in detail the different scenarios
	where these techniques hold advantages.},
  acmid = {2001458},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {S},
  ci4 = {S},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/2001420.2001458},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p309-sumner.pdf:PDF},
  isbn = {978-1-4503-0562-4},
  keywords = {automated debugging, peer selection, trace comparison},
  location = {Toronto, Ontario, Canada},
  nroartigo = {45},
  numpages = {11},
  owner = {higoramario},
  timestamp = {2011.09.15},
  url = {http://doi.acm.org/10.1145/2001420.2001458}
}

@INPROCEEDINGS{Sumner2010,
  author = {Sumner, William N. and Zhang, Xiangyu},
  title = {Memory indexing: canonicalizing addresses across executions},
  booktitle = {Proceedings of the eighteenth ACM SIGSOFT international symposium
	on Foundations of software engineering},
  year = {2010},
  series = {FSE '10},
  pages = {217--226},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este artigo faz uma an\'alise da indexa{\c c}\~ao da mem\'oria entre
	diferentes execu{\c c}\~oes de programas e seus benef\'icios para
	a depura{\c c}\~ao autom\'atica. O artigo traz uma nova abordagem
	de informa{\c c}\~oes para depura{\c c}\~ao autom\'atica, adequando-se
	aos prop\'ositos da revis\~ao.},
  acmid = {1882324},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1882291.1882324},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p217-sumner.pdf:PDF},
  isbn = {978-1-60558-791-2},
  keywords = {aliasing, automated debugging, execution indexing, memory indexing},
  location = {Santa Fe, New Mexico, USA},
  nroartigo = {7},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1882291.1882324}
}

@ARTICLE{Tan2010,
  author = {Tan, D.-G.a b , Chen, L.a b , Wang, Z.-Y.a b , Ding, H.a b , Zhou,
	Y.-M.a b , Xu, B.-W.a b},
  title = {Spectra-based fault localization by increasing marginal weight},
  journal = {Jisuanji Xuebao/Chinese Journal of Computers},
  year = {2010},
  volume = {33},
  pages = {2335-2342},
  number = {12},
  note = {cited By (since 1996) 0},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {N},
  justificativa = {Este artigo apresenta uma abordagem de atribui{\c c}\~ao de ppesos
	para os casos de teste que falham para uso em t\'ecnica de localiza{\c
	c}\~ao de defeitos baseada em espectro. O artigo est\'a em chin\^es,
	por isso ser\'a exclu\'ido.},
  abstract = {Spectra-based fault localization technique uses coverage information
	to calculate every statement's likelihood of having a bug. And then
	rank the likelihood in a decreasing order to find the faulty statement.
	This paper improves the spectra-base fault localization technique
	by increasing the marginal weight of the failed test cases. That
	means that as the number of the failed test case increases, the weight
	of the failed test case also increases. Comparing with reducing or
	sustaining the weight of covered statement's successful/failed test
	case, the experimental result shows that increasing the marginal
	weight of the covered statement's failed test case can promote the
	fault localization efficiency.},
  affiliation = {National Key Laboratory for Novel Software Technology, Nanjing University,
	Nanjing, 210093, China; Department of Computer Science and Technology,
	Nanjing University, Nanjing 210093, China},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Tan2010.pdf:PDF},
  nroartigo = {10},
  owner = {higoramario},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78651430499\&partnerID=40\&md5=58fc019780ac0e4f1875eed82b645486}
}

@INPROCEEDINGS{Tsankov2011,
  author = {Tsankov, P. and Wei Jin and Orso, A. and Sinha, S.},
  title = {Execution Hijacking: Improving Dynamic Analysis by Flying off Course},
  booktitle = {Software Testing, Verification and Validation (ICST), 2011 IEEE Fourth
	International Conference on},
  year = {2011},
  pages = {200 -209},
  month = {march},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma t\'ecnica para for{\c c}ar a execu{\c c}\~ao
	de caminhos durante a execu{\c c}\~ao de um programa, diminuindo
	a necessidade um grande n\'umero de dados de entrada. Esta abordagem
	pode ser utilizada para alguns tipos de an\'alise dinâmica que n\~ao
	necessitem de conhecimento sobre os valores de entrada, como por
	exemplo detec{\c c}\~ao de erros de mem\'oria. Fora do escopo da
	revis\~ao.},
  abstract = {Typically, dynamic-analysis techniques operate on a small subset of
	all possible program behaviors, which limits their effectiveness
	and the representativeness of the computed results. To address this
	issue, a new paradigm is emerging: execution hijacking, consisting
	of techniques that explore a larger set of program behaviors by forcing
	executions along specific paths. Although hijacked executions are
	infeasible for the given inputs, they can still produce feasible
	behaviors that could be observed under other inputs. In such cases,
	execution hijacking can improve the effectiveness of dynamic analysis
	without requiring the (expensive) generation of additional inputs.
	To evaluate the usefulness of execution hijacking, we defined, implemented,
	and evaluated several variants of it. Specifically, we performed
	an empirical study where we assessed whether execution hijacking
	could improve the effectiveness of a common dynamic analysis: memory
	error detection. The results of the study show that execution hijacking,
	if suitably performed, can indeed improve dynamic analysis.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICST.2011.45},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05770609.pdf:PDF},
  keywords = {dynamic analysis;execution hijacking;memory error detection;program
	behavior;program diagnostics;},
  nroartigo = {41},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5770609}
}

@INPROCEEDINGS{Walcott2006,
  author = {Walcott, Kristen R. and Soffa, Mary Lou and Kapfhammer, Gregory M.
	and Roos, Robert S.},
  title = {TimeAware test suite prioritization},
  booktitle = {Proceedings of the 2006 international symposium on Software testing
	and analysis},
  year = {2006},
  series = {ISSTA '06},
  pages = {1--12},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica para prioriza{\c c}\~ao de conjuntos
	de teste de regress\~ao utilizando um algoritmo gen\'etico de acordo
	com as restri{\c c}\~oes de tempo.},
  abstract = {Regression test prioritization is often performed in a time constrained
	execution environment in which testing only occurs for a fixed time
	period. For example, many organizations rely upon nightly building
	and regression testing of their applications every time source code
	changes are committed to a version control repository. This paper
	presents a regression test prioritization technique that uses a genetic
	algorithm to reorder test suites in light of testing time constraints.
	Experiment results indicate that our prioritization approach frequently
	yields higher average percentage of faults detected (APFD) values,
	for two case study applications, when basic block level coverage
	is used instead of method level coverage. The experiments also reveal
	fundamental trade offs in the performance of time-aware prioritization.
	This paper shows that our prioritization technique is appropriate
	for many regression testing environments and explains how the baseline
	approach can be extended to operate in additional time constrained
	testing circumstances.},
  acmid = {1146240},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1146238.1146240},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p1-walcott.pdf:PDF},
  isbn = {1-59593-263-1},
  keywords = {coverage testing, genetic algorithms, test prioritization},
  location = {Portland, Maine, USA},
  nroartigo = {42},
  numpages = {12},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1146238.1146240}
}

@INPROCEEDINGS{Wang2009b,
  author = {Wang, Xinming and Cheung, S. C. and Chan, W. K. and Zhang, Zhenyu},
  title = {Taming coincidental correctness: Coverage refinement with context
	patterns to improve fault localization},
  booktitle = {Proceedings of the 31st International Conference on Software Engineering},
  year = {2009b},
  series = {ICSE '09},
  pages = {45--55},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica para refinamento da cobertura de
	c\'odigo para casos de teste usando padr\~oes de crit\'erios de teste
	propostos para diferentes tipos de defeitos. A inten{\c c}\~ao \'e
	melhorar o conjunto de testes para evitar casos de corre{\c c}\~ao
	coincidente, permitindo uma melhoria de informa{\c c}oes para a localiza{\c
	c}\~ao de defeitos. Este artigo foge dos objetivos desta revis\~ao,
	por\'em deve ser lido para averiguar os tiopos de defeitos propostos.},
  abstract = {Recent techniques for fault localization leverage code coverage to
	address the high cost problem of debugging. These techniques exploit
	the correlations between program failures and the coverage of program
	entities as the clue in locating faults. Experimental evidence shows
	that the effectiveness of these techniques can be affected adversely
	by coincidental correctness, which occurs when a fault is executed
	but no failure is detected. In this paper, we propose an approach
	to address this problem. We refine code coverage of test runs using
	control- and data-flow patterns prescribed by different fault types.
	We conjecture that this extra information, which we call context
	patterns, can strengthen the correlations between program failures
	and the coverage of faulty program entities, making it easier for
	fault localization techniques to locate the faults. To evaluate the
	proposed approach, we have conducted a mutation analysis on three
	real world programs and cross-validated the results with real faults.
	The experimental results consistently show that coverage refinement
	is effective in easing the coincidental correctness problem in fault
	localization techniques.},
  acmid = {1555022},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/ICSE.2009.5070507},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05070507.pdf:PDF},
  isbn = {978-1-4244-3453-4},
  nroartigo = {21},
  numpages = {11},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dx.doi.org/10.1109/ICSE.2009.5070507}
}

@INPROCEEDINGS{Wang2009a,
  author = {Xinping Wang and Qing Gu and Xin Zhang and Xiang Chen and Daoxu Chen},
  title = {Fault Localization Based on Multi-level Similarity of Execution Traces},
  booktitle = {Software Engineering Conference, 2009. APSEC '09. Asia-Pacific},
  year = {2009a},
  pages = {399 -405},
  month = {dec.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {O artigo prop\~oe uma nova t\'ecnica para localiza{\c c}\~ao de defeitos
	baseada em similaridade multi-n\'ivel de execu{\c c}\~oes para calcular
	a suspei{\c c}\~ao de blocos de c\'odigo. Os autores consideram a
	t\'ecnica adequada a software orientado a objetos. Al\'em disso,
	foi desenvolvida uma ferramenta para impelementar a t\'ecnica. Artigo
	adequado aos prop\'ositos desta revis\~ao.},
  abstract = {Since automated fault localization can improve the efficiency of both
	the testing and debugging process, it is an important technique for
	the development of reliable software. This paper proposes a novel
	fault localization approach based on multi-level similarity of execution
	traces, which is suitable for object-oriented software. It selects
	useful test cases at class level and computes code suspiciousness
	at block level. We develop a tool that implements the approach, and
	conduct empirical studies to evaluate its effectiveness. The experimental
	results show that our approach has the potential to be effective
	in localizing faults for object-oriented software.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/APSEC.2009.45},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05358777.pdf:PDF},
  issn = {1530-1362},
  keywords = {automated fault localization;code suspiciousness;debugging process;execution
	traces;multilevel similarity;object-oriented software;reliable software.
	development;testing process;fault location;object-oriented programming;program
	diagnostics;program testing;},
  nroartigo = {1},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5358777}
}

@INPROCEEDINGS{Weiglhofer2009,
  author = {Weiglhofer, Martin and Fraser, Gordon and Wotawa, Franz},
  title = {Using Spectrum-Based Fault Localization for Test Case Grouping},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2009},
  series = {ASE '09},
  pages = {630--634},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {Este trabalho utiliza SFL para agrupar casos de teste de acordo com
	a probabilidade de estarem relacionados a uma mesma falha. Embora
	n\~ao seja proposta uma nova t\'ecnica para localiza{\c c}\~ao de
	defeitos, o agrupamento de testes por similaridade pode ser \'util
	para tratar a abordagem de m\'ultiplos defeitos.},
  abstract = {Model-based test case generation allows one to derive almost arbitrary
	numbers of test cases from models. If resulting test suites are executed
	against real implementations, there are often huge numbers of failed
	test cases. Thus, the analysis of the test execution, i.e. the identification
	of failures for error reporting, becomes a tedious and time consuming
	task. In this paper we investigate a technique for grouping test
	runs that most likely reveal the same failure. This reduces the post
	analysis time and enables the generation of small regression test
	suites. The test case grouping is implemented by means of spectrum-based
	fault localization at the level of the specification. We calculate
	the grouping by relating the spectra of the test cases. Besides a
	brief discussion of our approach we present results of applying our
	approach to the Session Initiation Protocol.},
  acmid = {1747570},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {N},
  ci2 = {S},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/ASE.2009.78},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/3891a630.pdf:PDF},
  isbn = {978-0-7695-3891-4},
  keywords = {model-based testing, test case grouping, spectrum-based fault localization},
  nroartigo = {30},
  numpages = {5},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dx.doi.org/10.1109/ASE.2009.78}
}

@INPROCEEDINGS{Wloka2009,
  author = {Wloka, Jan and Ryder, Barbara G. and Tip, Frank},
  title = {JUnitMX - A change-aware unit testing tool},
  booktitle = {Proceedings of the 31st International Conference on Software Engineering},
  year = {2009},
  series = {ICSE '09},
  pages = {567--570},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma t\'ecnica para gerar casos de testes unit\'arios
	baseado em modifica{\c c}\~oes realizadas em programas. Fora do escopo
	desta revis\~ao.},
  abstract = {Developers use unit testing to improve the quality of software systems.
	Current development tools for unit testing help with automating test
	execution, with reporting results, and with generating test stubs.
	However, they offer no aid for designing tests aimed specifically
	at exercising the effects of changes to a program. This paper describes
	a unit testing tool that leverages a change model to assist developers
	in the creation of new unit tests. The tool provides developers with
	quantitative feedback and detailed information about change effects,
	which not only facilitate the writing of more effective tests, but
	also motivate developers with an achievable coverage goal.},
  acmid = {1555074},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/ICSE.2009.5070557},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05070557.pdf:PDF},
  isbn = {978-1-4244-3453-4},
  nroartigo = {3},
  numpages = {4},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://dx.doi.org/10.1109/ICSE.2009.5070557}
}

@INCOLLECTION{Wolf2009,
  author = {Wolf, Marko and Wolf, Marko},
  title = {Vehicular Security Mechanisms},
  booktitle = {Security Engineering for Vehicular IT Systems},
  publisher = {Vieweg+Teubner},
  year = {2009},
  pages = {121-165},
  note = {10.1007/978-3-8348-9581-3\_8},
  abstract = {This chapter provides an introduction into feasible security mechanisms
	applicable in the automotive domain to fulfill the identified security
	objectives and necessary security requirements. Parts of this chapter
	are based on published research in \[AES + 07, HPWW05, HSW06, PWW04a,
	PWW04c, PWW05, SSS + 06, SSW06, WWW07\].},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {S},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-3-8348-9581-3},
  justificativa = {O cap\'itulo do livro trata dos mecanismos de seguran{\c c}a aplic\'aveis
	ao dom\'inio automotivo. Fora do escopo da revis\~ao. O texto n\~ao
	est\'a dispon\'ivel integralmente.},
  keyword = {Computer Science},
  nroartigo = {12},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-8348-9581-3\_8}
}

@INPROCEEDINGS{Wong2007,
  author = {Wong, W.E. and Yu Qi and Lei Zhao and Kai-Yuan Cai},
  title = {Effective Fault Localization using Code Coverage},
  booktitle = {Computer Software and Applications Conference, 2007. COMPSAC 2007.
	31st Annual International},
  year = {2007},
  volume = {1},
  pages = {449 -456},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {O artigo prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	que possue algumas heur\'isticas para identificar comandos os comandos
	mais susupeitos de conte o defeitos. O artigo tamb\'em discute a
	contribui{\c c}\~ao das informa{\c c}\~oes dos casos de teste executados
	com sucesso para a a identifica{\c c}{\c c}\~ao dos comandos defeituosos,
	al\'em de propor uma ferramenta para exercitar a t\'ecnica proposta.
	O artigo est\'a dentro dos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {Localizing a bug in a program can be a complex and time- consuming
	process. In this paper we propose a code coverage-based fault localization
	method to prioritize suspicious code in terms of its likelihood of
	containing program bugs. Code with a higher risk should be examined
	before that with a lower risk, as the former is more suspicious (i.e.,
	more likely to contain program bugs) than the latter. We also answer
	a very important question: how can each additional test case that
	executes the program successfully help locate program bugs? We propose
	that with respect to a piece of code, the aid introduced by the first
	successful test that executes it in computing its likelihood of containing
	a bug is larger than or equal to that of the second successful test
	that executes it, which is larger than or equal to that of the third
	successful test that executes it, etc. A tool, chiDebug, was implemented
	to automate the computation of the risk of the code and the subsequent
	prioritization of suspicious code for locating program bugs. A case
	study using the Siemens suite was also conducted. Data collected
	from our study support the proposal described above. They also indicate
	that our method (in particular Heuristics III (c), (d), and (e))
	can effectively reduce the search domain for locating program bugs.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2007.109},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/04291037.pdf:PDF},
  issn = {0730-3157},
  keywords = {Siemens suite;code coverage-based fault localization;program bug localization;program
	bug location;search domain;suspicious code;codes;fault tolerant computing;program
	debugging;},
  nroartigo = {3},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4291037}
}

@INPROCEEDINGS{Wong2008b,
  author = {Wong, W.E. and Yan Shi and Yu Qi and Golden, R.},
  title = {Using an RBF Neural Network to Locate Program Bugs},
  booktitle = {Software Reliability Engineering, 2008. ISSRE 2008. 19th International
	Symposium on},
  year = {2008b},
  pages = {27 -36},
  month = {nov.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma nova t\'ecnica de localiza{\c c}\~ao de defeitos
	que utiliza uma rede neural RBF para identificar e classificar comandos
	de um programa de acordo com sua suspei{\c c}\~ao. A t\'ecnica \'e
	avaliada em programas de defeitos simples e 1 programa com m\'ultiplos
	defeitos e comparada com a t\'ecnica Tarantula. O artigo atende aos
	crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {We propose an RBF (radial basis function) neural network-based fault
	localization method to help programmers locate bugs in a more effective
	way. An RBF neural network with a three-layer feed-forward structure
	is employed to learn the relationship between the statement coverage
	of a test case and its corresponding execution result. The trained
	network is then given as input a set of virtual test cases, each
	covering only a single statement. The output of the network for each
	test case is considered to be the suspiciousness of the corresponding
	statement; a statement with a higher suspiciousness has a higher
	likelihood of containing a bug. The set of statements ranked in descending
	order by their suspiciousness are then examined by programmers one
	by one until a bug is located. Three case studies on different programs
	(space, grep and make) were conducted with each faulty version having
	exactly one bug. An additional program gcc was also used to demonstrate
	the concept of extending the proposed method to programs with multiple
	bugs. Our experimental data suggest that an RBF neural network-based
	fault localization method is more effective in locating a program
	bug (by examining less code before the first faulty statement containing
	the bug is identified) than another popular method, Tarantula, which
	also uses the coverage and execution results to compute the suspiciousness
	of each statement.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {S},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ISSRE.2008.15},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/04700307.pdf:PDF},
  issn = {1071-9458},
  keywords = {RBF neural network;Tarantula;fault localization method;program bugs;radial
	basis function;three-layer feed-forward structure;program debugging;radial
	basis function networks;},
  nroartigo = {21},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4700307}
}

@INPROCEEDINGS{Wong2008,
  author = {Wong, W.E. and Tingting Wei and Yu Qi and Lei Zhao},
  title = {A Crosstab-based Statistical Method for Effective Fault Localization},
  booktitle = {Software Testing, Verification, and Validation, 2008 1st International
	Conference on},
  year = {2008a},
  pages = {42 -51},
  month = {april},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo \'e id\^entico um outro j\'a selecionado para esta revis\~ao
	nessa mesma biblioteca (IEEE Xplore).},
  abstract = {Fault localization is the most expensive activity in program debugging.
	Traditional ad-hoc methods can be time-consuming and ineffective
	because they rely on programmers' intuitive guesswork, which may
	neither be accurate nor reliable. A better solution is to utilize
	a systematic and statistically well-defined method to automatically
	identify suspicious code that should be examined for possible fault
	locations. We present a crosstab-based statistical method using the
	coverage information of each executable statement and the execution
	result (success or failure) with respect to each test case. A crosstab
	is constructed for each executable statement and a statistic is computed
	to determine the suspiciousness of the corresponding statement. Statements
	with a higher suspiciousness are more likely to contain bugs and
	should be examined before those with a lower suspiciousness. Three
	case studies using the Siemens suite, the Space program, and the
	Unix suite, respectively, are conducted. Our results suggest that
	the crosstab-based method is effective in fault localization and
	performs better (in terms of a smaller percentage of executable statements
	that have to be examined until the first statement containing the
	fault is reached) than other methods such as Tarantula. The difference
	in efficiency (computational time) between these two methods is very
	small.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICST.2008.65},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04539531.pdf:PDF},
  keywords = {Siemens suite;Space program;Unix suite;crosstab-based statistical
	method;fault localization;fault location;program debugging;program
	debugging;software fault tolerance;statistical analysis;},
  nroartigo = {7},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4539531}
}

@ARTICLE{Wong2011,
  author = {Wong, W. E. and Debroy, V. and Xu, D.},
  title = {Towards Better Fault Localization: A Crosstab-Based Statistical Approach},
  journal = {Systems, Man, and Cybernetics, Part C: Applications and Reviews,
	IEEE Transactions on},
  year = {2011},
  volume = {PP},
  pages = {1 -19},
  number = {99},
  month = { },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo apresenta uma t\'ecnica de localiza{\c c}\~ao de defeitos
	que utiliza uma tabela cruzada para cada comando executado por um
	caso de teste, calculando um ranking de suspei{\c c}\~ao para tais
	comandos. A t\'ecnica foi avaliada em diversos programas, incluindo
	programa grandes, como gzip e Ant. O artigo atende aos crit\'erios
	de inclus\~ao.},
  abstract = {It is becoming prohibitively expensive and time consuming, as well
	as tedious and error-prone, to perform debugging manually. Among
	the debugging activities, fault localization has been one of the
	most expensive, and therefore, a large number of fault-localization
	techniques have been proposed over the recent years. This paper presents
	a crosstab-based statistical technique that makes use of the coverage
	information of each executable statement and the execution result
	(success or failure) with respect to each test case to localize faults
	in an effective and efficient manner. A crosstab is constructed for
	each executable statement, and a statistic is computed to determine
	the suspiciousness of the corresponding statement. Statements with
	a higher suspiciousness are more likely to contain bugs and should
	be examined before those with a lower suspiciousness. Case studies
	are performed on both small- (the Siemens and Unix suites) and large-sized
	programs (space, grep, gzip, and make), and results suggest that
	the crosstab-based technique (CBT) is more effective (in terms of
	a smaller percentage of executable statements that have to be examined
	until the first statement containing the fault is reached) than other
	techniques, such as Tarantula. Further studies using the Siemens
	suite reveal that the proposed technique is also more effective at
	locating faults than other statistically oriented techniques, such
	as SOBER and Liblit05. Additional experiments evaluate the CBT from
	other perspectives, such as its efficiency in terms of time taken,
	its applicability to object-oriented languages (on a very large Java
	program: Ant), and its sensitivity to test suite size, and demonstrate
	its superior performance.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {S},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSMCC.2011.2118751},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05772029.pdf:PDF},
  issn = {1094-6977},
  nroartigo = {5},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5772029}
}

@INPROCEEDINGS{Xie2010,
  author = {Xie, Tao and Tillmann, Nikolai and de Halleux, Jonathan and Schulte,
	Wolfram},
  title = {Future of developer testing: building quality in code},
  booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering
	research},
  year = {2010},
  series = {FoSER '10},
  pages = {415--420},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma discuss\~ao sobre a realiza{\c c}\~ao de testes
	por parte do programador, o estado atual e o futuro desse tipo de
	teste. Fora do escopo desta revis\~ao.},
  abstract = {Although much progress has been made in software verification, software
	testing remains by far the most widely used technique for improving
	software reliability. Among various types of testing, developer testing
	is a type of testing where developers test their code as they write
	it, as opposed to testing done by a separate quality assurance organization.
	Developer testing has been widely recognized as an important and
	valuable means of improving software reliability, partly due to its
	capabilities of exposing faults early in the development life cycle.
	In this position paper, we present our positions on future directions
	of developer testing along four dimensions (which of course we do
	not claim to be complete): correctness confidence, specifications,(dis)integration
	testing, and human factors. Our positions are originated from two
	recent promising technologies in developer testing: parameterized
	unit testing and dynamic symbolic execution, also called concolic
	testing.},
  acmid = {1882447},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1882362.1882447},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p415-xie.pdf:PDF},
  isbn = {978-1-4503-0427-6},
  keywords = {developer testing, human factors, software testing, specifications},
  location = {Santa Fe, New Mexico, USA},
  nroartigo = {38},
  numpages = {6},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1882362.1882447}
}

@INPROCEEDINGS{Xie2010a,
  author = {Xiaoyuan Xie and Tsong Yueh Chen and Baowen Xu},
  title = {Isolating Suspiciousness from Spectrum-Based Fault Localization Techniques},
  booktitle = {Quality Software (QSIC), 2010 10th International Conference on},
  year = {2010},
  pages = {385 -392},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Este artigo prop\~oe uma t\'ecnica para refinamento dos resultados
	de execu{\c c}\~ao de teste para localiza{\c c}\~ao de defeitos,
	utilizando diferentes avalia{\c c}\~oes para comandos suspeitos de
	acordo com os resultados de sucesso ou falha na execu{\c c}\~ao dos
	testes. Pretende-se assim refinar e melhorar os resultados dos rankings
	de classifica{\c c}\~ao de comandos defeituosos. O artigo adequa-se
	aos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {Spectrum-based fault localization (SBFL) is one of the most promising
	fault localization approaches, which normally uses the failed and
	passed program spectrum to evaluate the risks for all program entities.
	However, it does not explicitly distinguish the different degree
	in definiteness between the information associated with the failed
	spectrum and the passed spectrum, which may result in an unreliable
	location of faults. Thus in this paper, we propose a refinement method
	to improve the accuracy of the predication by SBFL, through eliminating
	the indefinite information. Our method categorizes all statements
	into two groups according to their different suspiciousness, and
	then uses different evaluation schemes for these two groups. In this
	way, we can reduce the use of the unreliable information in the ranking
	list, and finally provide a more precise result. Experimental study
	shows that for some SBFL techniques, our method can significantly
	improve their performance in some situations, and in other cases,
	it can still remain the techniques' original performance.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2010.45},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/05562991.pdf:PDF},
  issn = {1550-6002},
  keywords = {program spectrum;risk evaluation;spectrum based fault localization;program
	debugging;program testing;software fault tolerance;software maintenance;},
  nroartigo = {13},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5562991}
}

@INPROCEEDINGS{Xie2011,
  author = {Xie, Xiaoyuan and Wong, W. Eric and Chen, Tsong Yueh and Xu, Baowen},
  title = {Spectrum-Based Fault Localization: Testing Oracles are No Longer
	Mandatory},
  booktitle = {Quality Software (QSIC), 2011 11th International Conference on},
  year = {2011},
  pages = {1 -10},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {Os autores prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	que n\~ao necessita de or\'aculos para obter informa{\c c}\~oes sobre
	as execu{\c c}\~oes dos casos de teste. Utilizando teste metam\'orfico,
	e utiliza caracteriza{\c c}\~oes esperadas para indicar a satisfa{\c
	c}\~ao ou insatisfa{\c c}\~ao de dado caso de teste. A t\'ecnica
	foi comparada com 3 t\'ecnicas de localiza{\c c}\~ao de defeitos
	existentes. Atende aos crit\'erios de inclus\~ao da revis\~ao.},
  abstract = {Spectrum-based Fault Localization (SBFL) is one of the most popular
	approaches for locating software faults, and has received much attention
	because of its simplicity and effectiveness. It utilizes the execution
	result of each test case (failure or pass) and the corresponding
	coverage information to evaluate the likelihood of each program entity
	(e.g., a statement or a predicate) being faulty. Different formulas
	for computing such likelihood have been proposed based on different
	intuitions. All existing SBFL techniques have assumed the existence
	of a testing oracle, that is, a mechanism which can determine whether
	the execution of a test case fails or passes. However, such an assumption
	does not always hold. Recently, metamorphic testing has been proposed
	to alleviate the oracle problem. Thus, it is a natural extension
	to investigate how it can help SBFL techniques to locate faults even
	without using a testing oracle. Based on the framework of metamorphic
	testing, we have developed a novel concept of mice as a counterpart
	of the slice used in the current SBFL techniques. More precisely,
	in the absence of a testing oracle, we can determine whether an expected
	characterization of the program is satisfied. The outcomes of dissatisfaction
	or satisfaction of an expected characterization are then regarded
	as the counterparts of failed or passed executions, respectively,
	when a testing oracle exists. Since our approach does not require
	the existence of a testing oracle, it significantly enhances the
	applicability of SBFL techniques. Case studies on three popular SBFL
	techniques (Tarantula, Ochiai and Jaccard) with 9 applications are
	reported to demonstrate the use of the proposed fault localization
	technique.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2011.20},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/06004306.pdf:PDF},
  issn = {1550-6002},
  nroartigo = {18},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6004306}
}

@INPROCEEDINGS{Xu2011,
  author = {Xu, Jian and Chan, W.K. and Zhang, Zhenyu and Tse, T.H. and Li, Shanping},
  title = {A Dynamic Fault Localization Technique with Noise Reduction for Java
	Programs},
  booktitle = {Quality Software (QSIC), 2011 11th International Conference on},
  year = {2011},
  pages = {11 -20},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {S},
  justificativa = {O artigo prop\~oe uma t\'ecnica de localiza{\c c}\~ao de defeitos
	que usa uma cadeia de blocos chave e um novo coeficiente de similaridade
	que tem o efeito de reduzir a interfer\^encia de outros comandos
	no c\'alculo de suspei{\c c}\~ao. A t\'ecnica \'e avaliada em 3 programas
	reais de tamanho m\'edio. O artigo adequa-se aos crit\'erios de inclus\~ao
	da revis\~ao.},
  abstract = {Existing fault localization techniques combine various program features
	and similarity coefficients with the aim of precisely assessing the
	similarities among the dynamic spectra of these program features
	to predict the locations of faults. Many such techniques estimate
	the probability of a particular program feature causing the observed
	failures. They ignore the noise introduced by the other features
	on the same set of executions that may lead to the observed failures.
	In this paper, we propose both the use of chains of key basic blocks
	as program features and an innovative similarity coefficient that
	has noise reduction effect. We have implemented our proposal in a
	technique known as MKBC. We have empirically evaluated MKBC using
	three real-life medium-sized programs with real faults. The results
	show that MKBC outperforms Tarantula, Jaccard, SBI, and Ochiai significantly.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {S},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2011.32},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/06004307.pdf:PDF},
  issn = {1550-6002},
  nroartigo = {10},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6004307}
}

@CONFERENCE{Xu2010,
  author = {Xu, X. and Debroy, V. and Wong, W.E. and Guo, D.},
  title = {An evaluation of tie-breaking strategies for fault localization techniques},
  year = {2010},
  pages = {123-128},
  note = {cited By (since 1996) 0},
  abstract = {Software fault localization techniques typically rank program components
	(such as statements or predicates) in descending order of their suspiciousness
	(likelihood of being faulty). During debugging, programmers may examine
	these components, starting from the top of the ranking, in order
	to locate faults. However, the assigned suspiciousness to each component
	may not always be unique, and thus, some of them may be tied for
	the same position in the ranking. In such a scenario, the total number
	of components that a programmer needs to examine in order to find
	the faults may vary considerably - as in the best case one would
	examine a faulty component before all other components that are tied
	for the same rank; and in the worst case, only after. The greater
	the variability, the harder it is for a programmer to decide which
	component to examine first, and the harder it is to accurately compute
	the expected effectiveness of a fault localization technique. Our
	first case study (based on three fault localization techniques across
	four sets of programs) reveals that the phenomenon of assigning the
	same suspiciousness to multiple components is not limited to any
	technique or program in particular. Thus, to reduce variability and
	alleviate this problem, four tie-breaking strategies are evaluated
	empirically in our second case study across the programs of the Siemens
	suite, using the Tarantula fault localization technique. Results
	indicate that some strategies can not only reduce the number of ties
	in the rankings but also improve the average effectiveness of Tarantula.},
  affiliation = {Department of Physics, Xiamen University, China; Department of Computer
	Science, University of Texas, Dallas, United States; School of Information
	Science and Technology, Xiamen University, China},
  base = {SciVerse Scopus},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {S},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  journal = {SEKE 2010 - Proceedings of the 22nd International Conference on Software
	Engineering and Knowledge Engineering},
  justificativa = {Este artigo faz uma avalia{\c c}\~ao da ocorr\^encia de comandos classificados
	com a mesma pontua{\c c}\~ao em 3 t\'ecnicas de localiza{\c c}\~ao
	de defeitos existentes, utilizando 4 conjuntos de benchmarks. Em
	seguida, prop\~oe 4 estrat\'egias para desempate de comandos com
	mesma pontua{\c c}\~ao, realizando experimentos utilizando a t\'ecnica
	Tarantula e o benchmark Siemens suite. O estudo atende aos crit\'erios
	de inclus\~ao, por\'em, o texto integral n\~ao est\'a dispon\'ivel,
	o que est\'a de acordo com os crit\'erios de exclus\~ao da revis\~ao.},
  nroartigo = {12},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79952425621\&partnerID=40\&md5=3233a04b2b6757f4aa4c56b17a9d7019}
}

@ARTICLE{Yilmaz2006,
  author = {Yilmaz, C. and Cohen, M.B. and Porter, A.A.},
  title = {Covering arrays for efficient fault characterization in complex configuration
	spaces},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2006},
  volume = {32},
  pages = { 20 - 34},
  number = {1},
  month = {jan.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo prop\~oe uma t\'ecnica que utiliza arrays de cobertura
	para identificar defeitos existentes em programas parametriz\'aveis
	e indicar parametriza{\c c}\~oes nas quais o defeito ir\'a gerar
	falhas. Fora do escopo desta revis\~ao.},
  abstract = { Many modern software systems are designed to be highly configurable
	so they can run on and be optimized for a wide variety of platforms
	and usage scenarios. Testing such systems is difficult because, in
	effect, you are testing a multitude of systems, not just one. Moreover,
	bugs can and do appear in some configurations, but not in others.
	Our research focuses on a subset of these bugs that are "option-related"-those
	that manifest with high probability only when specific configuration
	options take on specific settings. Our goal is not only to detect
	these bugs, but also to automatically characterize the configuration
	subspaces (i.e., the options and their settings) in which they manifest.
	To improve efficiency, our process tests only a sample of the configuration
	space, which we obtain from mathematical objects called covering
	arrays. This paper compares two different kinds of covering arrays
	for this purpose and assesses the effect of sampling strategy on
	fault characterization accuracy. Our results strongly suggest that
	sampling via covering arrays allows us to characterize option-related
	failures nearly as well as if we had tested exhaustively, but at
	a much lower cost. We also provide guidelines for using our approach
	in practice.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2006.8},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/01583600.pdf:PDF},
  issn = {0098-5589},
  keywords = { complex configuration spaces; covering arrays; distributed continuous
	quality assurance; fault characterization; option-related failure
	characterization; software system bug detection; software system
	testing; configuration management; program debugging; program testing;
	software fault tolerance;},
  nroartigo = {57},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1583600}
}

@ARTICLE{Yilmaz2007,
  author = {Yilmaz, C. and Porter, A. and Krishna, A.S. and Memon, A.M. and Schmidt,
	D.C. and Gokhale, A.S. and Natarajan, B.},
  title = {Reliable Effects Screening: A Distributed Continuous Quality Assurance
	Process for Monitoring Performance Degradation in Evolving Software
	Systems},
  journal = {Software Engineering, IEEE Transactions on},
  year = {2007},
  volume = {33},
  pages = {124 -141},
  number = {2},
  month = {feb. },
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma t\'ecnica para realiza{\c c}\~ao de testes
	para softwares parametriz\'aveis, aplic\'avel a programas de larga
	escala de uso. Fora do escopo desta revis\~ao.},
  abstract = {Developers of highly configurable performance-intensive software systems
	often use in-house performance-oriented "regression testing" to ensure
	that their modifications do not adversely affect their software's
	performance across its large configuration space. Unfortunately,
	time and resource constraints can limit in-house testing to a relatively
	small number of possible configurations, followed by unreliable extrapolation
	from these results to the entire configuration space. As a result,
	many performance bottlenecks escape detection until systems are fielded.
	In our earlier work, we improved the situation outlined above by
	developing an initial quality assurance process called "main effects
	screening". This process 1) executes formally designed experiments
	to identify an appropriate subset of configurations on which to base
	the performance-oriented regression testing, 2) executes benchmarks
	on this subset whenever the software changes, and 3) provides tool
	support for executing these actions on in-the-field and in-house
	computing resources. Our initial process had several limitations,
	however, since it was manually configured (which was tedious and
	error-prone) and relied on strong and untested assumptions for its
	accuracy (which made its use unacceptably risky in practice). This
	paper presents a new quality assurance process called "reliable effects
	screening" that provides three significant improvements to our earlier
	work. First, it allows developers to economically verify key assumptions
	during process execution. Second, it integrates several model-driven
	engineering tools to make process configuration and execution much
	easier and less error prone. Third, we evaluate this process via
	several feasibility studies of three large, widely used performance-intensive
	software frameworks. Our results indicate that reliable effects screening
	can detect performance degradation in large-scale systems more reliably
	and with significantly less resources than conventional t- echniques},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/TSE.2007.20},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04052587.pdf:PDF},
  issn = {0098-5589},
  keywords = {configuration subset;distributed continuous quality assurance process;evolving
	software systems;in house testing;main effects screening;performance
	bottlenecks;performance degradation monitoring;performance intensive
	software systems;process configuration;process execution;regression
	testing;reliable effects screening;software benchmarks;software performance;tool
	support;program testing;software performance evaluation;software
	quality;software reliability;},
  nroartigo = {39},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4052587}
}

@INPROCEEDINGS{Yu2011,
  author = {Yu, Kai and Lin, Mengxiang and Gao, Qing and Zhang, Hui and Zhang,
	Xiangyu},
  title = {Locating faults using multiple spectra-specific models},
  booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
  year = {2011},
  series = {SAC '11},
  pages = {1404--1410},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {S},
  justificativa = {O artigo apresenta uma t\'ecnica para combina{\c c}\~ao de m\'ultiplas
	t\'ecnicas de localiza{\c c}\~ao de defeitos baseada em espectro
	(SFL ou Spectra-based fault localization) introduzindo an\'alise
	de depend\^encia de controle e de dados na busca por defeitos. O
	trabalho atende aos crit\'erios de inclus\~ao desta revis\~ao.},
  abstract = {Spectra-based fault localization (SFL) techniques have brought encouraging
	results and a variety of program spectra have been proposed to locate
	faults. Different types of abnormal behaviors may be revealed by
	different kinds of spectra. Compared to techniques using single spectra
	type, techniques combining multiple types of spectra try to leverage
	the strengths of the constituent types. However, in the presence
	of multiple kinds of spectra, how to select adequate spectra type
	and build appropriate models need further investigation.
	
	
	In this paper, we propose an SFL technique LOUPE, which uses multiple
	spectra-specific models. Both control and data dependences are introduced
	to capture unusual behaviors of faults. In the stage of suspiciousness
	modeling, in contrast with previous studies, we build different models
	to evaluate the suspiciousness of statements for each spectra type
	respectively. Finally, since the fault type is unknown in advance,
	suspiciousness scores are calculated based on the two models. We
	evaluate LOUPE on the Siemens benchmark and experimental results
	show that our technique is promising.},
  acmid = {1982490},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1982185.1982490},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/p1404-yu.pdf:PDF},
  isbn = {978-1-4503-0113-8},
  keywords = {fault localization, multiple models, multiple spectra types, spectra
	selection, spectra-specific model},
  location = {TaiChung, Taiwan},
  nroartigo = {47},
  numpages = {7},
  owner = {higoramario},
  timestamp = {2011.09.15},
  url = {http://doi.acm.org/10.1145/1982185.1982490}
}

@INPROCEEDINGS{Zahalka2010,
  author = {Zahalka, A. and Goseva-Popstojanova, K. and Zemerick, J.},
  title = {Empirical Evaluation of Factors Affecting Distinction between Failing
	and Passing Executions},
  booktitle = {Software Reliability Engineering (ISSRE), 2010 IEEE 21st International
	Symposium on},
  year = {2010},
  pages = {259 -268},
  month = {nov.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo faz uma avalia{\c c}\~ao sobre os fatores que influenciam
	execu{\c c}\~oes de sucesso e falha utilizando alguns benchmarks
	da \'area e tamb\'em programas open-source com defeitos variados.
	Embora o tema esteja estrititamente ligado à \'area de depura{\c
	c}\~ao, est\'a fora dos crit\'erios desta revis\~ao. No entanto,
	o trabalho sera lido por tratar de tema importante para a \'area.},
  abstract = {Information captured in software execution profiles can benefit verification
	activities by supporting more cost-effective fault localization and
	execution classification. This paper proposes an experimental design
	which utilizes execution information to quantify the effect of factors
	such as different programs and fault inclusions on the distinction
	between passed and failed execution profiles. For this controlled
	experiment we use well-known, benchmark-like programs. In addition
	to experimentation, our empirical evaluation includes case studies
	of open source programs having more complex fault models. The results
	show that metrics reflecting distinction between failing and passing
	executions are affected more by program than by faults included.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ISSRE.2010.44},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05635050.pdf:PDF},
  issn = {1071-9458},
  keywords = {benchmark like program;execution information;failing execution;fault
	localization;open source program;passing execution;software execution
	profile;software metrics;benchmark testing;program testing;public
	domain software;software metrics;supervisory programs;},
  nroartigo = {28},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5635050}
}

@INPROCEEDINGS{Zeller2007,
  author = {Zeller, Andreas},
  title = {The Future of Programming Environments: Integration, Synergy, and
	Assistance},
  booktitle = {2007 Future of Software Engineering},
  year = {2007},
  series = {FOSE '07},
  pages = {316--325},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo discute poss\'iveis novas funcionalidades que os ambientes
	de desenvolvimento podem ter no futuro para permitir que processos
	e desenvolvimento possam ser feitos integrados e de forma colaborativa,
	permitindo que toda a equipe envolvida possa trabalhar em um mesmo
	ambiente. Fora do escopo desta revis\~ao.},
  abstract = {Modern programming environments foster the integration of automated,
	extensible, and reusable tools. New tools can thus leverage the available
	functionality and collect data from program and process. The synergy
	of both will allow the automation of current empirical approaches.
	This leads to automated assistance in all development decisions for
	programmers and managers alike: "For this task, you should collaborate
	with Joe, because it will likely require risky work on the Mailbox
	class."},
  acmid = {1254727},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://dx.doi.org/10.1109/FOSE.2007.31},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/28290316.pdf:PDF},
  isbn = {0-7695-2829-5},
  nroartigo = {25},
  numpages = {10},
  owner = {higor},
  timestamp = {2011.09.16},
  url = {http://dx.doi.org/10.1109/FOSE.2007.31}
}

@ARTICLE{Zhang2011,
  author = {Zhang, Wei and Lim, Junghee and Olichandran, Ramya and Scherpelz,
	Joel and Jin, Guoliang and Lu, Shan and Reps, Thomas},
  title = {ConSeq: detecting concurrency bugs through sequential errors},
  journal = {SIGPLAN Not.},
  year = {2011},
  volume = {46},
  pages = {251--264},
  month = {March},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {O artigo apresenta uma t\'ecnica para localiza{\c c}\~ao de defeitos
	para concorrentes, focando em caracter\'isticas espec\'ificas de
	compartilhamento de dados entre threads para fazer a localiza{\c
	c}\~ao. Essa especificidade foge dos prop\'ositos desta revis\~ao.},
  abstract = {Concurrency bugs are caused by non-deterministic interleavings between
	shared memory accesses. Their effects propagate through data and
	control dependences until they cause software to crash, hang, produce
	incorrect output, etc. The lifecycle of a bug thus consists of three
	phases: (1) triggering, (2) propagation, and (3) failure.
	
	
	Traditional techniques for detecting concurrency bugs mostly focus
	on phase (1)--i.e., on finding certain structural patterns of interleavings
	that are common triggers of concurrency bugs, such as data races.
	This paper explores a consequence-oriented approach to improving
	the accuracy and coverage of state-space search and bug detection.
	The proposed approach first statically identifies potential failure
	sites in a program binary (i.e., it first considers a phase (3) issue).
	It then uses static slicing to identify critical read instructions
	that are highly likely to affect potential failure sites through
	control and data dependences (phase (2)). Finally, it monitors a
	single (correct) execution of a concurrent program and identifies
	suspicious interleavings that could cause an incorrect state to arise
	at a critical read and then lead to a software failure (phase (1)).
	
	
	ConSeq's backwards approach, (3)!(2)!(1), provides advantages in bug-detection
	coverage and accuracy but is challenging to carry out. ConSeq makes
	it feasible by exploiting the empirical observationthat phases (2)
	and (3) usually are short and occur within one thread. Our evaluation
	on large, real-world C/C++ applications shows that ConSeq detects
	more bugs than traditional approaches and has a much lower false-positive
	rate.},
  acmid = {1950395},
  address = {New York, NY, USA},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1961296.1950395},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p251-zhang.pdf:PDF},
  issn = {0362-1340},
  issue = {3},
  keywords = {concurrency bugs, software testing},
  nroartigo = {49},
  numpages = {14},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.17},
  url = {http://doi.acm.org/10.1145/1961296.1950395}
}

@INPROCEEDINGS{Zhang2010,
  author = {Zhang, Xin and Gu, Qing and Chen, Xiang and Qi, Jingxian and Chen,
	Daoxu},
  title = {A study of relative redundancy in test-suite reduction while retaining
	or improving fault-localization effectiveness},
  booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
  year = {2010},
  series = {SAC '10},
  pages = {2229--2236},
  address = {New York, NY, USA},
  publisher = {ACM},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Este trabalho apresenta uma t\'ecnica que tem como objetivo reduzir
	o n\'umero de casos de testes em um conjunto de testes para diminuir
	o custo necess\'ario a etapa de testes de um projeto sem acarretar
	perda de informa{\c c}\~ao relevante para o uso em t\'ecnicas de
	localiza{\c c}\~ao de defeitos. Os efeitos da t\'ecnica proposta
	s\~ao experimentados na t\'ecnica de localiza{\c c}\~ao de defeitos
	Tarantula, sem apresentar nenhuma modifica{\c c}\~ao ou inova{\c
	c}\~ao para localiza{\c c}\~ao de defeitos.},
  abstract = {Test-suite reduction technique aims to find a subset of the test suite
	while still satisfying the original test requirements; therefore,
	it can save the cost of software testing. Because many test cases
	have been removed, the testing information is also lost. Fault localization
	is a technique using testing information to locate the fault and
	widely used by programmers to debug programs, so it suffers from
	the side effects of test-suite reduction. How to reduce the test-suite
	size in software testing with the premise of retaining or improving
	fault-localization effectiveness has become the hot spot in the area
	of software debugging recently. In this paper, we propose a new approach
	that selectively keeps the limited redundant test cases in the reduced
	set; it makes the new reduced set relatively redundant compared to
	the original one, and we expect that it retains or even improves
	fault-localization effectiveness. We also describe a framework that
	implements our approach and conduct a set of empirical studies for
	evaluation. The results show that our approach can retain or even
	improve fault-localization effectiveness as expected.},
  acmid = {1774556},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1774088.1774556},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p2229-zhang.pdf:PDF},
  isbn = {978-1-60558-639-7},
  keywords = {fault localization, test-suite reduction},
  location = {Sierre, Switzerland},
  nroartigo = {4},
  numpages = {8},
  owner = {higor},
  timestamp = {2011.09.14},
  url = {http://doi.acm.org/10.1145/1774088.1774556}
}

@ARTICLE{Zhang2009b,
  author = {Zhang, Z.a and Chan, W.K.b and Tse, T.H.a and Hu, P.c and Wang, X.d},
  title = {Is non-parametric hypothesis testing model robust for statistical
	fault localization?},
  journal = {Information and Software Technology},
  year = {2009b},
  volume = {51},
  pages = {1573-1585},
  number = {11},
  note = {cited By (since 1996) 2},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {SciVerse Scopus},
  incluido = {S},
  justificativa = {Este artigo procura investigar se as caracter\'isticas dos espectros
	de execu{\c c}\~ao utilizados pelas t\'ecnicas de localiza{\c c}\~ao
	de defeitos baseadas em SFL possuem distribui{\c c}\~oes normais
	e que, dessa forma, possam utilizar t\'ecnicas estat\'isticas param\'etricas.
	Essa quest\~ao \'e avaliada no benchmark Siemens suite. O artigo
	atende aos objetivos desta revis\~ao.},
  abstract = {Fault localization is one of the most difficult activities in software
	debugging. Many existing statistical fault-localization techniques
	estimate the fault positions of programs by comparing the program
	feature spectra between passed runs and failed runs. Some existing
	approaches develop estimation formulas based on mean values of the
	underlying program feature spectra and their distributions alike.
	Our previous work advocates the use of a non-parametric approach
	in estimation formulas to pinpoint fault-relevant positions. It is
	worthy of further study to resolve the two schools of thought by
	examining the fundamental, underlying properties of distributions
	related to fault localization. In particular, we ask: Can the feature
	spectra of program elements be safely considered as normal distributions
	so that parametric techniques can be soundly and powerfully applied?
	In this paper, we empirically investigate this question from the
	program predicate perspective. We conduct an experimental study based
	on the Siemens suite of programs. We examine the degree of normality
	on the distributions of evaluation biases of the predicates, and
	obtain three major results from the study. First, almost all examined
	distributions of evaluation biases are either normal or far from
	normal, but not in between. Second, the most fault-relevant predicates
	are less likely to exhibit normal distributions in terms of evaluation
	biases than other predicates. Our results show that normality is
	not common as far as evaluation bias can represent. Furthermore,
	the effectiveness of our non-parametric predicate-based fault-localization
	technique weakly correlates with the distributions of evaluation
	biases, making the technique robust to this type of uncertainty in
	the underlying program spectra. 2009 Elsevier B.V. All rights reserved.},
  affiliation = {Department of Computer Science, The University of Hong Kong, Pokfulam,
	Hong Kong; Department of Computer Science, City University of Hong
	Kong, Tat Chee Avenue, Hong Kong; China Merchants Bank, Central,
	Hong Kong; Department of Computer Science and Engineering, Hong Kong
	University of Science and Technology, Clear Water Bay, Hong Kong},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {S},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Zhang2009a.pdf:PDF},
  nroartigo = {11},
  owner = {higoramario},
  source = {Scopus},
  timestamp = {2011.09.20},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-69749099373\&partnerID=40\&md5=d9c4ab57d7d22d8b77e50f6413fbb47c}
}

@INPROCEEDINGS{Zhang2010a,
  author = {Zhenyu Zhang and Zhongxing Xu and Zhifang Liu and Xiaopeng Gao},
  title = {Macro-Like Instrumentation Grammar for Boolean Expressions},
  booktitle = {Computational Intelligence and Software Engineering (CiSE), 2010
	International Conference on},
  year = {2010},
  pages = {1 -4},
  month = {dec.},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Este artigo apresenta ua t\'ecnica para realizar a instrumenta{\c
	c}\~ao de express\~oes booleanas em n\'ivel de usu\'ario. Fora do
	escopo da revis\~ao.},
  abstract = {Boolean expression is a basic programming element used to evaluate
	the truth-values of conditions or their combinations. While Boolean
	expressions may have complicated logical structures, instrumenting
	them often needs heavyweight transformation to source code or work
	with low-level program implementation, which results in cumbersome
	code and great difficulties to maintenance. As a result, previous
	instrumentation is often conducted using automatic mechanism, left
	as the last integration step, and needs to be redone once the source
	code has changes. It is inflexible and not interactivable for collaborative
	work. In this paper, we compare several existing popular instrumentation
	methods and propose a friendly approach, which adds least prefix
	and postfix to Boolean expressions, simply wraps all conditions,
	and preserves all Boolean operators if any. Our method works at source-code
	level yet has a macro-like grammar. It is human maintainable so that
	programmers may manually and cooperatively modify code by instrumenting
	interested Boolean expressions like operating macros. We elaborate
	on the grammar of our method and give empirical evaluation to its
	performance. Our method has been used in some realistic industrial
	and research projects successfully.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/CISE.2010.5676786},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05676786.pdf:PDF},
  keywords = {Boolean expressions;Boolean operators;automatic mechanism;heavyweight
	transformation;logical structures;low-level program implementation;macrolike
	instrumentation grammar;programming element;source code;truth-values;Boolean
	functions;computerised instrumentation;macros;programming languages;software
	maintenance;source coding;},
  nroartigo = {59},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5676786}
}

@INCOLLECTION{Zhao2010,
  author = {Zhao, Lei and Wang, Lina and Xiong, Zuoting and Gao, Dongming},
  title = {Execution-Aware Fault Localization Based on the Control Flow Analysis},
  booktitle = {Information Computing and Applications},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Zhu, Rongbo and Zhang, Yanchun and Liu, Baoxiang and Liu, Chunfeng},
  volume = {6377},
  series = {Lecture Notes in Computer Science},
  pages = {158-165},
  note = {10.1007/978-3-642-16167-4\_21},
  abstract = {Coverage-based fault localization techniques assess the suspiciousness
	of program entities individually. However, the individual coverage
	information cannot reveal the execution paths and to some extent
	it simplifies the executions. In this paper, the control flow analysis
	is adopted to analyze the executions first. Second, the edge suspiciousness
	is used to calculate the failed executions distribution to different
	control flows. By comparing different failed executions distributions
	of blocks covered by the same failed execution path, we propose the
	bug proneness to quantify how each block contributes to the failure.
	Similarly, the bug free confidence is also proposed to represent
	the possibility of bug free for blocks covered by a passed execution
	path. At last, the weighted coverage information statistic is proceeded
	and the weighted coverage based fault localization technique is brought
	out. We conduct several experiments to compare our technique with
	an existing representative technique by using standard benchmarks
	and the results are promising.},
  affiliation = {Computer School of Wuhan University, 430072 Wuhan, Hubei P.R. China},
  base = {SpringerLink},
  ce1 = {N},
  ce2 = {N},
  ce3 = {N},
  ce4 = {N},
  ci1 = {S},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  file = {:/media/HIGOR/0/DPBTI/RS/Incluidos/Zhao\_2010.pdf:PDF},
  incluido = {S},
  isbn = {978-3-642-16166-7},
  justificativa = {O artigo traz uma nova t\'ecnica para depura{\c c}\~ao automatizada,
	utilizando an\'alise de fluxo de controle das execu{\c c}\~oes dos
	casos de teste e verificando as arestas mais suspeitas nas execu{\c
	c}\~oes que falham. S\~ao propostas duas medidas (uma baseada nas
	execu{\c c}\~oes de sucesso e outra nas execu{\c c}\~oes que falharam)
	para calcular a possibilidade dos blocos de c\'odigo conterem defeitos.
	O artugo atende aos crit\'erios de inclus\~ao da revis\~ao.},
  keyword = {Computer Science},
  nroartigo = {1},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.20},
  url = {http://dx.doi.org/10.1007/978-3-642-16167-4\_21}
}

@INPROCEEDINGS{Zoeteweij2008,
  author = {Zoeteweij, P. and Pietersma, J. and Abreu, R. and Feldman, A. and
	van Gemund, A.J.C.},
  title = {Automated Fault Diagnosis in Embedded Systems},
  booktitle = {Secure System Integration and Reliability Improvement, 2008. SSIRI
	'08. Second International Conference on},
  year = {2008},
  pages = {103 -110},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {O artigo discute o uso das abordagens Model-based Diagnosis e Spectrum-based
	Fault Localization para a depura{\c c}\~ao automatizada em sistemas
	embarcados. Est\'a fora dos crit\'erios de inclus\~ao da revis\~ao
	por n\~ao apresentar uma nova t\'ecnica para depura{\c c}\~ao.},
  abstract = {Automated fault diagnosis is emerging as an important factor in achieving
	an acceptable and competitive cost/dependability ratio for embedded
	systems. In this paper, we survey model-based diagnosis and spectrum-based
	fault localization, two state-of-the-art approaches to fault diagnosis
	that jointly cover the combination of hardware and control software
	typically found in embedded systems. We present an introduction to
	the field, discuss our recent research results, and report on the
	application on industrial test cases. In addition, we propose to
	combine the two techniques into a novel, dynamic modeling approach
	to software fault localization.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/SSIRI.2008.48},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04579801.pdf:PDF},
  keywords = {automated fault diagnosis;competitive cost-dependability ratio;dynamic
	modeling approach;embedded systems;spectrum-based fault localization;survey
	model-based diagnosis;embedded systems;fault diagnosis;software reliability;},
  nroartigo = {30},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4579801}
}

@INPROCEEDINGS{5562936,
  title = {Table of Contents},
  booktitle = {Quality Software (QSIC), 2010 10th International Conference on},
  year = {2010},
  pages = {v -x},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Conte\'udo do QSIC 2010 (10th Quality Software Internacional Conference).},
  abstract = {The paper is talking about: ubiquitous system; software architecture;
	conformance verification; UML; reachability analysis; formal specification
	language; Web services; software reusability; software reliability;
	debugging approach; OWL; and embedded systems.},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/QSIC.2010.7},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/05562936.pdf:PDF},
  issn = {1550-6002},
  keywords = {OWL;UML;conformance verification;debugging approach;embedded system;formal
	specification language;reachability analysis;software architecture;software
	reliability;software reusability;ubiquitous system;web service;Web
	services;computer debugging;conformance testing;embedded systems;formal
	specification;knowledge representation languages;reachability analysis;software
	architecture;software quality;software reliability;software reusability;specification
	languages;ubiquitous computing;},
  nroartigo = {48},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5562936}
}

@PROCEEDINGS{2009,
  title = {ISSTA '09: Proceedings of the eighteenth international symposium
	on Software testing and analysis},
  year = {2009},
  address = {New York, NY, USA},
  publisher = {ACM},
  note = {594091},
  abstract = {Welcome to ISSTA 2009: The Eighteenth International Symposium on Software
	Testing and Analysis. ISSTA 2009 brings together academics, industrial
	researchers, and practitioners to exchange ideas, solve problems,
	and share experiences related to software testing and program analysis.
	
	
	We are delighted to be holding this ISSTA in the city of Chicago,
	Illinois, USA -- a city renowned for its architecture, its music,
	its art, and its wide range of ethnic neighborhoods, cultures, and
	cuisines. We are certain that you'll find many things to occupy your
	time outside the conference.
	
	
	The ISSTA week includes four workshops:
	
	
	 Defects 2009: Defects in Large Software Systems
	
	 PADTAD 2009: Parallel and Distributed Systems: Testing and Debugging
	
	 SSEAT 2009: Workshop on State-space Exploration for Automated Testing
	
	 WODA 2009: Workshop on Dynamic Analysis
	
	
	Defects, PADTAD, and WODA precede the technical program, and SSEAT
	follows it.
	
	
	The ISSTA technical program consists of two invited talks and twenty-five
	research paper presentations. Our invited speakers, Thomas W. Reps
	and Richard A. Kemmerer, speak on issues relevant to analysis and
	validation of software. The presentations were selected from ninety-three
	research papers submitted to ISSTA. At least three members of the
	Program Committee reviewed each paper, and additional reviewers also
	reviewed some.},
  base = {ACM Digital Library},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  incluido = {N},
  isbn = {978-1-60558-338-9},
  justificativa = {Chamada do International Symposium on Software Testing and Analysis
	2009 (ISSTA 09). Fora do escopo da revis\~ao.},
  location = {Chicago, IL, USA},
  nroartigo = {48},
  owner = {higoramario},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  timestamp = {2011.09.22},
  url = {http://dl.acm.org/citation.cfm?id=1572272\&coll=DL\&dl=ACM\&CFID=46966100\&CFTOKEN=45031579}
}

@ARTICLE{2007,
  title = {Frontmatter (TOC, Letters, Calendar, Calls)},
  journal = {SIGSOFT Softw. Eng. Notes},
  year = {2007},
  volume = {32},
  pages = {0--0},
  month = {January},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {ACM Digital Library},
  incluido = {N},
  justificativa = {Trata-se de um comunicado da ACM SIGSOFT sobre os eventos previstos
	para 2007.},
  acmid = {1226817},
  address = {New York, NY, USA},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {http://doi.acm.org/10.1145/1226816.1226817},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/p0-frontmatter.pdf:PDF},
  issn = {0163-5948},
  issue = {1},
  key = {{$\!\!$}},
  nroartigo = {15},
  numpages = {1},
  owner = {higor},
  publisher = {ACM},
  timestamp = {2011.09.16},
  url = {http://doi.acm.org/10.1145/1226816.1226817}
}

@INPROCEEDINGS{4222558,
  title = {29th International Conference on Software Engineering-TOC},
  booktitle = {Software Engineering, 2007. ICSE 2007. 29th International Conference
	on},
  year = {2007},
  pages = {v -xiii},
  month = {may},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Rela{\c c}\~ao do conte\'udo da ICSE 2007 (International Conference
	on Software Engineering).},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/ICSE.2007.5},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04222558.pdf:PDF},
  issn = {0270-5257},
  nroartigo = {40},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4222558}
}

@INPROCEEDINGS{4290967,
  title = {31st Annual International Computer Software and Applications Conference
	- Table of Contents},
  booktitle = {Computer Software and Applications Conference, 2007. COMPSAC 2007.
	31st Annual International},
  year = {2007},
  volume = {1},
  pages = {v -xii},
  month = {july},
  palavra-chave = {``fault localization'' AND ``code coverage''},
  base = {IEEE Xplore Digital Library},
  incluido = {N},
  justificativa = {Lista do conte\'udo da COMPSAC 2007 (31st. Computer Software and Applications
	Conference).},
  ce1 = {N},
  ce2 = {N},
  ce3 = {S},
  ce4 = {N},
  ci1 = {N},
  ci2 = {N},
  ci3 = {N},
  ci4 = {N},
  ci5 = {N},
  doi = {10.1109/COMPSAC.2007.6},
  file = {:/media/HIGOR/0/DPBTI/RS/Excluidos/04290967.pdf:PDF},
  issn = {0730-3157},
  nroartigo = {46},
  owner = {higor},
  timestamp = {2011.09.17},
  url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4290967}
}

%FIM DA REV SISTEMATICA

@INPROCEEDINGS{boo00:ing,
  author = {B. Boothe},
  title = {Efficient Algorithms for Bidirectional Debugging},
  pages = {299-310},
  crossref = {conf/pldi/2000}
}

@ARTICLE{ada86:ing,
  author = {E. Adams and S. S. Muchnick},
  title = {Dbxtool: A Window-Based Symbolic Debugger for Sun Workstation},
  journal = {Software Practice and Experience},
  year = {1986},
  volume = {16},
  pages = {653-669},
  number = {7},
  month = {July}
}

@PHDTHESIS{agr91a:ing,
  author = {H. Agrawal},
  title = {Towards Automatic Debugging of Computer Programs},
  school = {Purdue University},
  year = {1991},
  address = {West Lafayette, Indiana, U.S.A.},
  month = {September}
}


@INPROCEEDINGS{agr91:ing,
  author = {H. Agrawal and R. A. DeMillo and E. H. Spafford},
  title = {Dynamic Slicing in the Presence of Unconstrained Pointers},
  booktitle = {Proceedings of the Symposium on Software Testing, Analysis and Verification
	-- TAV4},
  year = {1991},
  pages = {60-73}
}

@ARTICLE{agr91b:ing,
  author = {H. Agrawal and R. A. DeMillo and E. H. Spafford},
  title = {An Execution-Backtracking Approach to Debugging},
  journal = {IEEE Software},
  year = {1991},
  volume = {8},
  pages = {21-26},
  number = {3},
  month = {May}
}

@INPROCEEDINGS{agr90:ing,
  author = {H. Agrawal and J. R. Horgan},
  title = {Dynamic Program Slicing},
  booktitle = {Proceedings of the ACM SIGPLAN '90 Conference on Programming Language
	Design and Implementation},
  year = {1990},
  pages = {246-256}
}

@INPROCEEDINGS{agr95:ing,
  author = {H. Agrawal and J. R. Horgan and S. London and W. E. Wong},
  title = {Fault Localization using Execution Slices and Dataflow Tests},
  booktitle = {Proceedings 6th International Symposium on Software Reliability Engineering
	(ISSRE 1995)},
  year = {1995},
  pages = {143-151}
}

@MISC{commons-math2012,
  title = {Commons-Math},
  howpublished = {Online},
  publisher = {The Apache Software Foundation},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.05},
  url = {http://commons.apache.org/math/}
}

@ARTICLE{ArakiFurukawaCheng1991,
  author = {Keijiro Araki and Zengo Furukawa and Jingde Cheng},
  title = {A General Framework for Debbugging},
  journal = {IEEE Software},
  year = {1991},
  volume = {8},
  pages = {14--20},
  number = {3}
}

@INPROCEEDINGS{araujo2011,
  author = {Roberto A. Araujo and Antonio Accioly and Felipe A. Alencar and Marcos
	L . Chaim},
  title = {Evaluating instrumentation strategies by program simulation},
  booktitle = {Proceedings of IADIS International Conference on Applied Computing
	(2011)},
  year = {2011},
  address = {Rio de Janeiro, Brazil},
  publisher = {IADIS}
}

@INPROCEEDINGS{bal69:ing,
  author = {R. M. Balzer},
  title = {Exdams: Extensible debugging and monitoring system},
  booktitle = {Spring Joint Computer Conference},
  year = {1969},
  pages = {567-589},
  address = {Reston, VA, U.S.A.},
  publisher = {AFIPS Press}
}

@PHDTHESIS{cha01:por,
  author = {M. L. Chaim},
  title = {Depura\c c\~ao de {P}rogramas {B}aseada em {I}nforma\c c\~ao de {T}este
	{E}strutural},
  school = {DCA/FEEC/Unicamp},
  year = {2001},
  address = {Campinas, SP, Brasil},
  month = {Novembro}
}

@MISC{chaim2012,
  author = {Chaim, Marcos Lordello and Araujo, Roberto A.},
  title = {An Efficient Bit-wise Algorithm for Data-Flow Testing Coverage},
  year = {2012},
  note = {Submetido para publicação}
}

@ARTICLE{che01:ing,
  author = {S.-K. Chen and W. K. Fuchs and J. Y. Chung},
  title = {Reversible Debugging Using Program Instrumentation},
  journal = {Transaction on Software Engineering},
  year = {2001},
  volume = {27},
  number = {8},
  month = {August}
}

@ARTICLE{che97:ing,
  author = {T. Y. Chen and Y. Y. Cheung},
  title = {On Program Dicing},
  journal = {Software Maintenance: Research and Practice},
  year = {1997},
  volume = {9},
  pages = {33-46}
}

@INPROCEEDINGS{cle05:ing,
  author = {H. Cleve and A. Zeller},
  title = {Locating Causes of Program Failures},
  booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Software
	Engineering},
  pages = {342-351},
  series = {ICSE '05},
  year = {2005},
  month = {May}
}

@INPROCEEDINGS{col87:ing,
  author = {J. S. Collofello and L. Cousins},
  title = {Toward Automatic Software Fault Localization Through Decision-to-Decision
	Path Analysis},
  booktitle = {Proceedings of the AFIP 1987 National Computer Conference},
  year = {1987},
  pages = {539-544},
  address = {Chicago},
  month = {May}
}

@MISC{cloc2012,
  author = {Al Danial},
  title = {Count Lines of Code, CLOC},
  howpublished = {Online},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.07},
  url = {http://cloc.sourceforge.net/}
}

@INCOLLECTION{del2010,
  author = {Delamaro, M\'arcio Eduardo and Chaim, Marcos Lordello and Vincenzi,
	Auri Marcelo Rizzo},
  title = {T\'ecnicas e Ferramentas de Teste de Software},
  booktitle = {Atualizações em Informática 2010 (JAI 2010)},
  publisher = {Editora PUC-Rio},
  year = {2010},
  pages = {55-110},
  address = {Rio de Janeiro}
}

@BOOK{del07,
  title = {Introdu{\c c}\~ao ao {T}este de {S}oftware},
  publisher = {Elsevier},
  year = {2007},
  author = {Marcio Eduardo Delamaro and Jos\'e Carlos Maldonado and Mario Jino},
  address = {Rio de Janeiro}
}

@ARTICLE{DelamaroMaldonadoMathur2001,
  author = {M\'arcio Eduardo Delamaro and Jos\'e Carlos Maldonado and Aditya
	P. Mathur},
  title = {Interface Mutation: An Approach for Integration Testing},
  journal = {IEEE Transactions on Software Engineering},
  year = {2001},
  volume = {27},
  pages = {228--247},
  number = {3}
}

@ARTICLE{fri92:ing,
  author = {P. Fritzson and N. Shahmehri and M. Kamkar and T. Gyimothy},
  title = {Generalized Algorithmic Debugging and Testing},
  journal = {ACM Letters on Programming Languages and Systems},
  year = {1992},
  volume = {1},
  pages = {303-322},
  number = {4},
  mounth = {#December#}
}

@MISC{junit2012,
  author = {Erich Gamma and Kent Beck},
  title = {JUnit: A Cook's Tour},
  year = {1999},
  owner = {higor},
  timestamp = {2012.12.04},
  url = {http://junit.sourceforge.net/doc/cookstour/cookstour.htm}
}

@MISC{r2012,
  author = {Robert Gentleman and Ross Ihaka},
  title = {The R Project for Statistical Computing},
  howpublished = {Online},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.12},
  url = {http://www.r-project.org/}
}

@INPROCEEDINGS{HarroldMcGregorFitzpatrick1992,
  author = {Harrold, Mary Jean and McGregor, John D. and Fitzpatrick, Kevin J.},
  title = {Incremental testing of object-oriented class structures},
  booktitle = {Proceedings of the 14th international conference on Software engineering},
  year = {1992},
  series = {ICSE '92},
  pages = {68--80},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {143093},
  doi = {http://doi.acm.org/10.1145/143062.143093},
  isbn = {0-89791-504-6},
  location = {Melbourne, Australia},
  numpages = {13},
  url = {http://doi.acm.org/10.1145/143062.143093}
}

@ARTICLE{har91:ing,
  author = {M. J. Harrold and M. L. Soffa},
  title = {Selecting and using Data for Integration Testing},
  journal = {IEEE Software},
  year = {1991},
  volume = {8},
  number = {2},
  month = {March}
}

@INPROCEEDINGS{won99,
  author = {W. E. Wong S. S. Gokhale J. R. Horgan and K. S. Trivedi},
  title = {Locating Program Features using Execution Slices},
  booktitle = {ASSET --- IEEE Symposium on Application-Specific Software Engineering
	and Technology},
  year = {1999},
  pages = {194-203},
  address = {Richardson, Texas, U.S.A.},
  month = {Mar\c co de},
  publisher = {IEEE Computer Society Press}
}

@INPROCEEDINGS{hutchins1994,
  author = {Hutchins, Monica and Foster, Herb and Goradia, Tarak and Ostrand,
	Thomas},
  title = {Experiments of the effectiveness of dataflow- and controlflow-based
	test adequacy criteria},
  booktitle = {Proceedings of the 16th international conference on Software engineering},
  year = {1994},
  series = {ICSE '94},
  pages = {191--200},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society Press},
  acmid = {257766},
  isbn = {0-8186-5855-X},
  location = {Sorrento, Italy},
  numpages = {10},
  url = {http://dl.acm.org/citation.cfm?id=257734.257766}
}

@INPROCEEDINGS{HutchinsFosterGoradiaOstrand1994,
  author = {Hutchins, Monica and Foster, Herb and Goradia, Tarak and Ostrand,
	Thomas},
  title = {Experiments of the effectiveness of dataflow- and controlflow-based
	test adequacy criteria},
  booktitle = {Proceedings of the 16th international conference on Software engineering},
  year = {1994},
  series = {ICSE '94},
  pages = {191--200},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society Press},
  acmid = {257766},
  isbn = {0-8186-5855-X},
  location = {Sorrento, Italy},
  numpages = {10},
  url = {http://portal.acm.org/citation.cfm?id=257734.257766}
}

@INPROCEEDINGS{janssen2009,
  author = {Janssen, Tom and Abreu, Rui and Gemund, Arjan J. C. van},
  title = {Zoltar: A Toolset for Automatic Fault Localization},
  booktitle = {Proceedings of the 2009 IEEE/ACM International Conference on Automated
	Software Engineering},
  year = {2009},
  series = {ASE '09},
  pages = {662--664},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid = {1747577},
  doi = {http://dx.doi.org/10.1109/ASE.2009.27},
  isbn = {978-0-7695-3891-4},
  keywords = {Zoltar, Fault Localization tool, Debugging},
  numpages = {3},
  url = {http://dx.doi.org/10.1109/ASE.2009.27}
}

@ARTICLE{jin98:ing,
  author = {Z. Jin and A. J. Offutt},
  title = {Coupling-based Criteria for Integration Testing},
  journal = {Software Testing, Verification, and Reliability},
  year = {1998},
  volume = {8},
  number = {3}
}


@ARTICLE{kor88:ing,
  author = {B. Korel and J. Laski},
  title = {Dynamic Program Slicing},
  journal = {Information Processing Letters},
  year = {1988},
  volume = {29},
  pages = {155-163},
  number = {3},
  mounth = {#October#}
}

@BOOK{larson2010,
  title = {Estatística aplicada},
  publisher = {Prentice Hall},
  year = {2010},
  editor = {Pearson},
  author = {Larson, Ron and Farber, Betsy},
  pages = {638},
  address = {São Paulo},
  edition = {4},
  owner = {higor},
  timestamp = {2012.12.09}
}

@ARTICLE{LemosFranchinMasiero2009,
  author = {Ot\'avio Augusto Lazzarini Lemos and Ivan Gustavo Franchin and Paulo
	Cesar Masiero},
  title = {Integration testing of Object-Oriented and Aspect-Oriented programs:
	A structural pairwise approach for Java},
  journal = {Science of Computer Programming},
  year = {2009},
  volume = {74},
  pages = {861 - 878},
  number = {10},
  doi = {DOI: 10.1016/j.scico.2009.05.001},
  issn = {0167-6423},
  keywords = {Software testing},
  url = {http://www.sciencedirect.com/science/article/B6V17-4W91PRR-1/2/df516d55dae92c2cb67faa884d52296a}
}

@ARTICLE{lemos2007,
  author = {Lemos, Ot\'{a}vio Augusto Lazzarini and Vincenzi, Auri Marcelo Rizzo
	and Maldonado, Jos\'{e} Carlos and Masiero, Paulo Cesar},
  title = {Control and data flow structural testing criteria for aspect-oriented
	programs},
  journal = {J. Syst. Softw.},
  year = {2007},
  volume = {80},
  pages = {862--882},
  month = {June},
  acmid = {1234493},
  address = {New York, NY, USA},
  doi = {http://dx.doi.org/10.1016/j.jss.2006.08.022},
  issn = {0164-1212},
  issue = {6},
  issue_date = {June, 2007},
  keywords = {Aspect-oriented programming, Software testing, Structural testing,
	Testing aspect-oriented programs, Testing criteria},
  numpages = {21},
  publisher = {Elsevier Science Inc.},
  url = {http://dx.doi.org/10.1016/j.jss.2006.08.022}
}

@INBOOK{lie98:ing,
  chapter = {ZStep95: A Reversible, Animated Source Code Stepper},
  pages = {277-292},
  title = {Software Visualization},
  publisher = {MIT Press},
  year = {1998},
  author = {H. Lieberman and C. Fry}
}

@INPROCEEDINGS{lyl87:ing,
  author = {J. R. Lyle and M. Weiser},
  title = {Automatic program bug location by program slicing},
  booktitle = {Proceedings of the 2nd International Conference on Computers and
	Applications},
  year = {1987},
  pages = {877-883},
  address = {Beijing, China},
  month = {June}
}

@ARTICLE{masri2009a,
  author = {Wes Masri and Andy Podgurski},
  title = {Algorithms and tool support for dynamic information flow analysis},
  journal = {Information and Software Technology},
  year = {2009},
  volume = {51},
  pages = {385 - 404},
  number = {2},
  doi = {10.1016/j.infsof.2008.05.008},
  issn = {0950-5849},
  keywords = {Dynamic information flow analysis},
  url = {http://www.sciencedirect.com/science/article/pii/S0950584908000815}
}

@INPROCEEDINGS{misurda2005,
  author = {Misurda, Jonathan and Clause, James A. and Reed, Juliya L. and Childers,
	Bruce R. and Soffa, Mary Lou},
  title = {Demand-Driven Structural Testing with Dynamic Instrumentation},
  booktitle = {Proceedings of the twenty-seventh International Conference on Software
	Engineering, 2005.},
  year = {2005},
  series = {ICSE 2005},
  pages = {156--165},
  publisher = {IEEE},
  doi = {http://dx.doi.org/10.1109/ICSE.2005.1553558},
  isbn = {978-1-59593-963-2},
  numpages = {10},
  url = {http://dx.doi.org/10.1109/ICSE.2005.1553558}
}

@UNPUBLISHED{mutti2012,
  author = {Danilo Mutti and Higor Amario de Souza and Roberto Andrioli de Araujo 
	and Eduardo Cerejo and Marcos Lordello Chaim},
  title = {CodeForest -- In Search of Bugs in the Forest of Code},
  note = {Em preparação},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.13}
}

@BOOK{mye79:ing,
  title = {The Art of Software Testing},
  publisher = {Wiley-Inter-Science},
  year = {1979},
  author = {G. J. Myers},
  address = {New York}
}

@MISC{napsol2012,
  title = {NAPSoL},
  publisher = {Núcleo de Apoio à Pesquisa em Software Livre (NAPSoL)},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.07},
  url = {http://www.usp.br/prp/subpagina.php?menu=6&pagina=23&subpagina=67}
}

@MASTERSTHESIS{neves2009,
  author = {Neves, V\^ania de Oliveira},
  title = {Teste de Integra{\c c}\~ao Contextual de Programas Orientados a Objetos
	e a Aspectos: crit\'erios e automa{\c c}\~ao},
  school = {Instituto de Ci\^encias Matem\'aticas e de Computa{\c c}\~ao, Universidade
	de S\~ao Paulo},
  year = {2010},
  url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-08042010-163127}
}

@BOOK{nguyen2001,
  title = {Testing applications on the Web: test planning for Internet-based
	systems},
  publisher = {Wiley},
  year = {2001},
  author = {Nguyen, Hung Q.},
  series = {Wiley computer publishing},
  isbn = {9780471394709},
  lccn = {00050982}
}

@INPROCEEDINGS{nis99:ing,
  author = {A. Nishimatsu and M. Jihira and S. Kusumoto and K. Inoue},
  title = {Call-{M}ark {S}licing: {A} Efficient and Economical Way of Reducing
	Slice},
  booktitle = {Proceedings of the 21st International Conference on Software Engineering},
  year = {1999},
  pages = {422-431},
  address = {Los Angeles, CA, U.S.A.},
  month = {May},
  publisher = {IEEE Computer Society Press}
}

@MISC{esh2012,
  title = {Engineering Statistics Handbook},
  publisher = {NIST, National Institute of Standards \& Technology},
  howpublished = {Online},
  year = {2012},
  owner = {higor},
  timestamp = {2012.12.08},
  url = {http://www.itl.nist.gov/div898/handbook/}
}

@PHDTHESIS{pan93:ing,
  author = {H. Pan},
  title = {Software Debugging with Dynamic Instrumentation and Test-Based Knowledge},
  school = {Purdue University},
  year = {1993},
  address = {West Lafayette, Indiana, U.S.A.},
  month = {August}
}

@INPROCEEDINGS{pan92:ing,
  author = {H. Pan and Eugene H. Spafford},
  title = {Toward Automatic Localization of Software Faults},
  booktitle = {10th Pacific Northwest Software Quality Conference},
  year = {1992},
  pages = {192-209},
  address = {Portland, Oregon},
  month = {October}
}

@BOOK{Pre06,
  title = {Engenharia de Software},
  publisher = {Mc-Graw-Hill},
  year = {2006},
  author = {R. S. Pressman},
  pages = {752},
  address = {S\~ao Paulo},
  edition = {6}
}

@ARTICLE{renieris2003,
  author = {Renieris, Manos and Reiss, Steven P},
  title = {Fault localization with nearest neighbor queries},
  journal = {18th IEEE International Conference on Automated Software Engineering
	2003 Proceedings},
  year = {2003},
  volume = {0},
  pages = {30--39},
  publisher = {IEEE Comput. Soc},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1240292}
}

@ARTICLE{rap85:ing,
  author = {S.Rapps and E. J. Weyuker},
  title = {Selecting software test data using data flow information},
  journal = {IEEE Transactions on Software Engineering},
  year = {1985},
  volume = {SE-11},
  pages = {367-375},
  number = {4},
  mounth = {#April#}
}

@BOOK{marquesdesa2007,
  title = {Applied Statistics Using SPSS, STATISTICA, MATLAB and R},
  publisher = {Springer Berlin Heidelberg},
  year = {2007},
  editor = {Joaquim P. Marques de Sá},
  author = {Joaquim P. Marques de S\'a},
  pages = {506},
  address = {Berlin, Heidelberg},
  edition = {2},
  owner = {higor},
  timestamp = {2012.12.09}
}

@MASTERSTHESIS{gonzalezsanchez2007,
  author = {Alberto Gonz\'alez S\'anchez},
  title = {Automatic Error Detection Techniques based on Dynamic Invariants},
  school = {Delft University of Technology},
  year = {2007},
  url = {www.st.ewi.tudelft.nl/~albgonz/pub/mscthesis.pdf}
}

@INPROCEEDINGS{saff2004,
  author = {Saff, David and Ernst, Michael D.},
  title = {Mock object creation for test factoring},
  booktitle = {Proceedings of the 5th ACM SIGPLAN-SIGSOFT workshop on Program analysis
	for software tools and engineering},
  year = {2004},
  series = {PASTE '04},
  pages = {49--51},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {996838},
  doi = {http://doi.acm.org/10.1145/996821.996838},
  isbn = {1-58113-910-1},
  keywords = {mock objects, test factoring, unit testing},
  location = {Washington DC, USA},
  numpages = {3},
  url = {http://doi.acm.org/10.1145/996821.996838}
}

@INPROCEEDINGS{santelices2007,
  author = {Santelices, Raul and Harrold, Mary Jean},
  title = {Efficiently monitoring data-flow test coverage},
  booktitle = {Proceedings of the twenty-second IEEE/ACM international conference
	on Automated software engineering},
  year = {2007},
  series = {ASE '07},
  pages = {343--352},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1321682},
  doi = {http://doi.acm.org/10.1145/1321631.1321682},
  isbn = {978-1-59593-882-4},
  keywords = {data-flow testing, definition-use association, inference, instrumentation,
	test coverage},
  location = {Atlanta, Georgia, USA},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1321631.1321682}
}


@BOOK{sha83:ing,
  title = {Algorithmic Program Debugging},
  publisher = {MIT Press},
  year = {1983},
  author = {E. Y. Shapiro},
  address = {Cambridge, Massachussetts}
}

@INPROCEEDINGS{silva06,
  author = {Silva, Josep and Chitil, Olaf},
  title = {Combining algorithmic debugging and program slicing},
  booktitle = {PPDP '06: Proceedings of the 8th ACM SIGPLAN international conference
	on Principles and practice of declarative programming},
  year = {2006},
  pages = {157--166},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1140335.1140355},
  isbn = {1-59593-388-3},
  location = {Venice, Italy}
}

@BOOK{sta99:ing,
  title = {Debugging with {GDB}: {T}he {GNU} Source-Level Debugger},
  publisher = {Free Software Foundation},
  year = {1999},
  author = {R. M. Stallman and R. H. Pesch},
  address = {Cambridge, MA},
  edition = {{S}eventh},
  month = {February}
}

@ARTICLE{tol95:ing,
  author = {A. Tolmach and A. W. Appel},
  title = {A Debugger for Standard {ML}},
  journal = {Journal of Functional Programming},
  year = {1995},
  volume = {5},
  pages = {155-200},
  number = {2},
  month = {April}
}

@TECHREPORT{vallee-rai98,
  author = {Raja Vallee-Rai and Laurie J. Hendren},
  title = {Jimple: Simplifying Java Bytecode for Analyses and Transformations},
  institution = {Sable Research Group, McGill University},
  year = {1998},
  type = {Technical Report},
  number = {Technical Report 1998-4},
  address = {Montreal, Quebec, Canada}
}

@MASTERSTHESIS{vayani2007,
  author = {Rafi Vayani},
  title = {Improving Automatic Software Fault Localization},
  school = {Delft University of Technology},
  year = {2007},
  url = {swerl.tudelft.nl/twiki/pub/Main/RafiVayani/thesisvayani.pdf}
}

@PHDTHESIS{vil98:ing,
  author = {P. Vilela},
  title = {Crit\'erios Potenciais Usos de Integra\c c\~ao: Defini\c c\~ao e
	An\'alise},
  school = {Tese de Doutorado, DCA/FEEC/Unicamp},
  year = {1998},
  address = {Campinas, SP,Brasil},
  month = {Abril}
}

@ARTICLE{VincenziMaldonadoWongDelamaro2005,
  author = {Auri M.R. Vincenzi and Jos\'e Carlos Maldonado and W.Eric Wong and
	M\'arcio Eduardo Delamaro},
  title = {Coverage testing of Java programs and components},
  journal = {Science of Computer Programming},
  year = {2005},
  volume = {56},
  pages = {211--230},
  number = {1-2},
  note = {New Software Composition Concepts},
  doi = {DOI: 10.1016/j.scico.2004.11.013},
  issn = {0167-6423},
  keywords = {Java program testing},
  url = {http://www.sciencedirect.com/science/article/B6V17-4F15003-5/2/e45168e915c6ede8de1d4a04c29975ba}
}

@ARTICLE{wei84:ing,
  author = {M. Weiser},
  title = {Program Slicing},
  journal = {IEEE Transactions on Software Engineering},
  year = {1984},
  volume = {SE-10},
  pages = {352-357},
  number = {4},
  mounth = {#October#}
}

@ARTICLE{wei84:por,
  author = {M. Weiser},
  title = {Program Slicing},
  journal = {IEEE Transactions on Software Engineering},
  year = {1984},
  volume = {SE-10},
  pages = {352-357},
  number = {4},
  mounth = {#October#}
}

@ARTICLE{WongDebroyChoi2010,
  author = {W. Eric Wong and Vidroha Debroy and Byoungju Choi},
  title = {A family of code coverage-based heuristics for effective fault localization},
  journal = {Journal of Systems and Software},
  year = {2010},
  volume = {83},
  pages = {188 - 208},
  number = {2},
  note = {Computer Software and Applications},
  doi = {DOI: 10.1016/j.jss.2009.09.037},
  issn = {0164-1212},
  keywords = {Fault localization},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4XBG177-1/2/972fddb82f8035a6aae52ca14667a9a0}
}

@INPROCEEDINGS{WongWeiQiZhao2008,
  author = {W. Eric Wong and Tingting Wei and Yu Qi and Lei Zhao},
  title = {A Crosstab-based Statistical Method for Effective Fault Localization},
  booktitle = {Proceedings of the 1st International Conference on Software Testing,
	Verification and Validation},
  year = {2008},
  series = {ICST '09},
  pages = {42--51},
  publisher = {IEEE},
  isbn = {978-0-7695-3127-4},
  location = {Lillehammer, Norway},
  numpages = {10}
}

@BOOK{zeller2009,
  title = {Why programs fail: a guide to systematic debugging},
  publisher = {Morgan Kaufmann Publishers},
  year = {2009},
  author = {Zeller, Andreas},
  pages = {424},
  address = {Burlington, MA},
  edition = {2},
  isbn = {978-0-12-374515-6}
}

@INPROCEEDINGS{zel02:ing,
  author = {Andreas Zeller},
  title = {Isolating cause-effect chains from computer programs.},
  booktitle = {Proceedings of the Tenth ACM SIGSOFT Symposium on Foundations of
	Software Engineering (FSE)},
  year = {2002},
  pages = {1-10}
}

@INPROCEEDINGS{zel02b:ing,
  author = {A. Zeller},
  title = {Isolating cause-effect chains from computer programs},
  booktitle = {SIGSOFT '02/FSE-10: Proceedings of the 10th ACM SIGSOFT symposium
	on Foundations of software engineering},
  year = {2002},
  pages = {1--10},
  address = {New York, NY, USA},
  publisher = {ACM Press},
  doi = {http://doi.acm.org/10.1145/587051.587053},
  isbn = {1-58113-514-9},
  location = {Charleston, South Carolina, USA}
}

@INPROCEEDINGS{zha04:ing,
  author = {X. Zhang and R. Gupta},
  title = {Cost effective dynamic program slicing},
  booktitle = {PLDI '04: Proceedings of the ACM SIGPLAN 2004 conference on Programming
	language design and implementation},
  year = {2004},
  pages = {94--106},
  address = {New York, NY, USA},
  publisher = {ACM Press},
  doi = {http://doi.acm.org/10.1145/996841.996855},
  isbn = {1-58113-807-5},
  location = {Washington DC, USA}
}

@INPROCEEDINGS{zha03:ing,
  author = {X. Zhang and R. Gupta and Y. Zhang},
  title = {Precise Dynamic Slicing Algorithms},
  booktitle = {Proceedings of the ACM/IEEE International Conference on Software
	Engineering},
  year = {2003},
  month = {May}
}

@MISC{clover2012,
  title = {Clover},
  howpublished = {Online},
  year = {2012},
  publisher = {Atlassian},
  url = {http://www.atlassian.com/software/clover/},
  urlaccessdate = {05 jan. 2012}
}

@MISC{sloccount2012,
  title = {SLOCCount},
  howpublished = {Online},
  year = {2011},
  publisher = {Wheeler, David A.},
  url = {http://www.dwheeler.com/sloccount/},
  urlaccessdate = {11 nov. 2011}
}

@MISC{aristotle2007,
  title = {ARISTOTLE analysis system},
  howpublished = {Online},
  year = {2007},
  publisher = {Aristotle Research Group},
  url = {http://www.cc.gatech.edu/aristotle/},
  urlaccessdate = {06 jan. 2012}
}

@MISC{bcel2003,
  title = {BCEL (The Byte Code Engineering Library)},
  howpublished = {Online},
  year = {2003},
  publisher = {The Apache Jakarta Project, Apache Software Foundation},
  url = {http://jakarta.apache.org/bcel},
  urlaccessdate = {05 jan. 2012}
}

@PROCEEDINGS{conf/pldi/2000,
  year = {2000},
  address = {Vancouver, Britith Columbia, Canada. New York, NY},
  publisher = {ACM},
  note = { SIGPLAN Notices 35(5) (May 2000)},
  month = {June},
  booktitle = {Proceedings 2000 ACM SIGPLAN Conference on Programming Language Design
	and Implementation (PLDI)}
}

@MISC{gcov1999,
  title = {Gcov. The GNU Compiler Collection (GCC)},
  howpublished = {Online},
  year = {1999},
  publisher = {Free Software Foundation},
  url = {http://gcc.gnu.org/onlinedocs/gcc/Gcov.html},
  urlaccessdate = {15 dez. 2011}
}

@MISC{xSuds1998,
  title = {xSuds User's manual},
  howpublished = {Online},
  year = {1998},
  publisher = {Telcordia Technologies},
  url = {http://xsuds.argreenhouse.com/},
  urlaccessdate = {05 jan. 2012}
}

@PROCEEDINGS{conf_issre_1995,
  year = {1995},
  address = {Toulouse, France. Los Alamitos, CA},
  publisher = {IEEE Computer Society},
  month = {October},
  booktitle = {Proceedings 6th International Symposium on Software Reliability Engineering
	(ISSRE 1995)}
}

%NOVOS + Arrumados

@article{collofello1989,
author = {James S. Collofello and Scott N. Woodfield},
title = {Evaluating the effectiveness of reliability-assurance techniques},
journal = {Journal of Systems and Software},
volume = {9},
number = {3},
pages = {191 - 195},
year = {1989},
month = {March},
url = {http://www.sciencedirect.com/science/article/pii/0164121289900393}
}

@INPROCEEDINGS{digiuseppe2011, 
author={DiGiuseppe, N. and Jones, J.A.}, 
booktitle={Proceedings of the 27th IEEE International Conference on Software Maintenance}, 
title={Fault interaction and its repercussions}, 
year={2011}, 
series={ICSM '11},
pages={3-12},
address = {Williamsburg, VI}
}

@INPROCEEDINGS{parnin2011,
  author = {Parnin, Chris and Orso, Alessandro},
  title = {Are automated debugging techniques actually helping programmers?},
  booktitle = {Proceedings of the 2011 International Symposium on Software Testing
	and Analysis},
  year = {2011},
  series = {ISSTA '11},
  pages = {199-209},
  address = {New York, NY, USA},
  publisher = {ACM},
  location = {Toronto, Ontario, Canada}
}

@ARTICLE{mariani2011,
  author = {Mariani, L. and Pastore, F. and Pezze, M.},
  title = {Dynamic Analysis for Diagnosing Integration Faults},
  journal = {IEEE Transactions on Software Engineering},
  year = {2011},
  volume = {37},
  pages = {486-508},
  number = {4},
  month = {jul-aug}
}

@ARTICLE{agrawal1998,
  author = {H. Agrawal and J. L. Alberi and J. R. Horgan and J. J. Li and S.
	London and W. E. Wong and S. Gosh and N. Wilde},
  title = {Mining System Tests to Aid Software Maintenance},
  journal = {IEEE Computer},
  year = {1998},
  volume = {31},
  pages = {64-73},
  number = {7},
  month = {July}
}

@INPROCEEDINGS{jones2007,
  author = {Jones, James A. and Bowring, James F. and Harrold, Mary Jean},
  title = {Debugging in Parallel},
  booktitle = {Proceedings of the 2007 International Symposium on Software Testing
	and Analysis},
  year = {2007},
  series = {ISSTA '07},
  pages = {16-26},
  address = {New York, NY, USA},
  location = {London, United Kingdom}
}

@INPROCEEDINGS{jones2002,
  author = {J. A. Jones and M. J. Harrold and J. Stasko},
  title = {Visualization of Test Information to Assist Fault Localization},
  booktitle = {Proceedings of the 24th ACM/IEEE International Conference on Software
	Engineering},
  year = {2002},
  series = {ICSE '02},
  pages={467-477},
  address = {Orlando, FL, USA},
  month = {May}
}

@ARTICLE{wong2010,
  author = {Wong, W. E. and Debroy, V. and Choi, B.},
  title = {A family of code coverage-based heuristics for effective fault localization},
  journal = {Journal of Systems and Software},
  year = {2010},
  volume = {83},
  pages = {188-208},
  number = {2},
  month = {February}
}

@MASTERSTHESIS{souza2012b,
  author = {Higor Amario de Souza},
  title = {Program Debugging based on Integration Coverage },
  school = {School of Arts, Sciences, and Humanities, University
	of S\~ao Paulo},
  year = {2012},
  note = {In Portuguese}
}

@INPROCEEDINGS{souza2012a,
  author = {Higor Amario de Souza and Marcos Lordello Chaim},
  title = {Depura{\c c}\~ao de Programas Baseada em Cobertura de Integra{\c c}\~ao},
  booktitle = {Anais do II Workshop de Teses e Disserta{\c c}\~oes do CBSoft},
  series = {WTDSoft '12},
  year = {2012},
  pages = {17-21},
  month = {Setembro},
  address = {Natal, RN, Brasil},
  publisher = {Sociedade Brasileira da Computação},
  volume = {6},
  location = {Porto Alegre, RS, Brasil}
}

@INPROCEEDINGS{oliveira2013,
  author = {Lucas Santos de Oliveira and Higor Amario de Souza and Danilo Mutti and Marcos Lordello Chaim},
  title = {Avalia{\c c}\~ao de Heur\'isticas para Localiza{\c c}\~ao de Defeitos},
  booktitle = {Proceedings of 7th Brazilian Workshop Systematic and Automated Software Testing},
  series = {SAST '13},
  year = {2013},
  pages = {},
  month = {September},
  pages = {165-174},
  address = {Bras\'ilia, DF, Brasil},
  publisher = {Sociedade Brasileira da Computação},
  location = {Porto Alegre, RS, Brazil}
}

@INPROCEEDINGS{souza2013,
  author = {Higor Amario de Souza and Marcos Lordello Chaim},
  title = {Adding Context to Fault Localization with Integration Coverage},
  booktitle = {Proceedings of the 28th International Conference on Automated Software Engineering},
  series = {ASE '13},
  year = {2013},
  pages = {628-633},
  month = {November},
  publisher = {ACM Press},
  location = {Palo Alto, CA, USA}
}

@INPROCEEDINGS{abreu2007,
  author = {Abreu, R. and Zoeteweij, P. and van Gemund, Arjan J. C.},
  title = {On the Accuracy of Spectrum-based Fault Localization},
  booktitle = {Testing: Academic and Industrial Conference Practice and Research
	Techniques - MUTATION},
  series = {TAICPART-MUTATION 2007},
  year = {2007},
  pages = {89-98},
  month = {sept.}
}

@INPROCEEDINGS{debroy2009,
  author = {Debroy, Vidroha and Wong, W. Eric},
  title = {Insights on fault interference for programs with multiple bugs},
  booktitle = {Proceedings of the 20th IEEE International Conference on Software
	Reliability Engineering},
  year = {2009},
  series = {ISSRE '09},
  pages = {165-174},
  address = {Piscataway, NJ, USA},
  publisher = {IEEE Press},
  location = {Bengaluru-Mysuru, India},
  url = {http://dl.acm.org/citation.cfm?id=1802408.1802433}
}

@INPROCEEDINGS{debroy2011b,
  author = {Debroy, Vidroha and Wong, W. Eric},
  title = {On the equivalence of certain fault localization techniques},
  booktitle = {Proceedings of the 2011 ACM Symposium on Applied Computing},
  year = {2011},
  series = {SAC '11},
  pages = {1457-1463},
  address = {New York, NY, USA},
  publisher = {ACM},
  location = {TaiChung, Taiwan},
  url = {http://doi.acm.org/10.1145/1982185.1982498}
}

@INCOLLECTION{wainer2006,
  title={Experiment in Collaborative Systems},
  booktitle={Collaborative systems},
  author={Jacques Wainer},
  editor={Mariano Pimentel and Hugo Fuks},
  publisher={Elsevier-Campus-SBC},
  pages={405-432},
  address={Rio de Janeiro, RJ},
  year={2011},
  note={In Portuguese}
}

@INPROCEEDINGS{naish2010,
  author = {Naish, L. and Hua Jie Lee and Ramamohanarao, K.},
  title = {Statements versus Predicates in Spectral Bug Localization},
  booktitle = {Proceedings of the 17th Asia Pacific Software Engineering Conference},
  year = {2010},
  series = {APSEC '10},
  pages = {375-384},
  month = {December},
  address = {Sydney, Australia}
}

@INPROCEEDINGS{santelices2009,
  author = {Raul Santelices and James A. Jones and Yanbing Yu and Mary Jean Harrold},
  title = {Lightweight Fault-Localization Using Multiple Coverage Types},
  booktitle = {Proceedings of the ACM/IEEE 31st International Conference on Software Engineering},
  year = {2009},
  series = {ICSE '09},
  pages = {56-66},
  publisher = {IEEE},
  address = {Washington, DC, USA}
}

@MastersThesis{mutti2013,
 author = {Danilo Mutti},
 title = {Coverage-based Debugging Visualization},
 school = {Escola de Artes, Ci\^encias e Humanidades, Universidade de S\~ao Paulo},
 month = {Agosto},
 year = {2013},
 address = {S\~ao Paulo},
 type = {Proposta de disserta{\c c}\~ao}
}


@INPROCEEDINGS{lee2009,
  author = {Hua Jie Lee and Lee Naish and Ramamohanarao, K.},
  title = {Study of the relationship of bug consistency with respect to performance of spectra metrics},
  booktitle = {Proceedings of the 2nd IEEE International Conference on Computer Science and Information Technology},
  year = {2009},
  series = {ICCSIT '09},
  pages = {501-508},
  month = {August},
  url = {http://ieeexplore.ieee.org/xpl/freeabs-all.jsp?arnumber=5234512}
}

@ARTICLE{zhang2011a,
  author = {Zhang, Z.a and Chan, W.K.b and Tse, T.H.c and Yu, Y.T.b and Hu, P.d},
  title = {Non-parametric statistical fault localization},
  journal = {Journal of Systems and Software},
  year = {2011},
  volume = {84},
  pages = {885-905},
  number = {6},
  month = {June},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79953688693\&partnerID=40\&md5=3ae90bf5e239c05034f76100eaeaa20c}
}

@ARTICLE{masri2010,
  author = {Masri, Wes},
  title = {Fault localization based on information flow coverage},
  journal = {Software Testing, Verification and Reliability},
  year = {2010},
  volume = {20},
  pages = {121-147},
  month = {June},
  address = {Chichester, UK}
}

@ARTICLE{do2005,
  author = {Do, Hyunsook and Elbaum, Sebastian and Rothermel, Gregg},
  title = {Supporting Controlled Experimentation with Testing Techniques: An
	Infrastructure and its Potential Impact},
  journal = {Empirical Software Engineering},
  year = {2005},
  volume = {10},
  pages = {405-435},
  number = {4},
  month = {October},
  url = {http://dx.doi.org/10.1007/s10664-005-3861-2}
}

@INPROCEEDINGS{burger2008,
  author = {Burger, Martin and Zeller, Andreas},
  title = {Replaying and isolating failing multi-object interactions},
  booktitle = {Proceedings of the 2008 International Workshop on Dynamic Analysis:
	Held in conjunction with the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA '08)},
  year = {2008},
  series = {WODA '08},
  pages = {71-77},
  address = {New York, NY, USA},
  month = {July}
}

@INPROCEEDINGS{naish2009,
  author = {Naish, L. and Hua Jie Lee and Ramamohanarao, K.},
  title = {Spectral Debugging with Weights and Incremental Ranking},
  booktitle = {Proceedings of the 16th Asia-Pacific Software Engineering Conference},
  year = {2009},
  series = {APSEC '09},
  pages = {168-175},
  address = {Penang, Malaysia},
  month = {December},
  url = {http://ieeexplore.ieee.org/xpl/freeabs-all.jsp?arnumber=5358598}
}

@ARTICLE{abreu2011,
  author = {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan J. C.},
  title = {Simultaneous debugging of software faults},
  journal = {Journal of Systems and Software},
  year = {2011},
  volume = {84},
  pages = {573-586},
  month = {April},
  number = {4},
  url = {http://dx.doi.org/10.1016/j.jss.2010.11.915}
}

@INPROCEEDINGS{zhang2009,
  author = {Zhang, Zhenyu and Chan, W. K. and Tse, T. H. and Jiang, Bo and Wang, Xinming},
  title = {Capturing propagation of infected program states},
  booktitle = {Proceedings of the 7th joint meeting of the European Software
	Engineering Conference and the ACM SIGSOFT Symposium on The Foundations
	of Software Engineering},
  year = {2009},
  series = {ESEC/FSE '09},
  pages = {43-52},
  address = {Amsterdam, Netherlands},
  month = {August},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/1595696.1595705}
}

@INPROCEEDINGS{chaim2003,
  author = {Chaim, Marcos L. and Maldonado, Jos\'{e} C. and Jino, Mario},
  title = {A Debugging Strategy Based on Requirements of Testing},
  booktitle = {Proceedings of the 7th European Conference on Software Maintenance
	and Reengineering},
  year = {2003},
  series = {CSMR '03},
  pages = {160-169},
  address = {Benevento, Italy},
  month = {March},
  publisher = {IEEE Computer Society},
  url = {http://dl.acm.org/citation.cfm?id=872754.873600}
}

@ARTICLE{hailpern2002, 
  author={Hailpern, B. and Santhanam, P.}, 
  journal={IBM Systems Journal}, 
  title={Software debugging, testing, and verification}, 
  year={2002}, 
  volume={41}, 
  number={1}, 
  pages={4-12}, 
  month={April}
}

@ARTICLE{tassey2002,
  title={The economic impacts of inadequate infrastructure for software testing},
  author={Tassey, Gregory},
  journal={National Institute of Standards and Technology, RTI Project},
  volume={7007},
  number={011},
  year={2002}
}

@INPROCEEDINGS{mega2007,
  author={Mega, Giuliano and Kon, Fabio},
  title={An Eclipse-Based Tool for Symbolic Debugging of Distributed Object Systems},
  booktitle={Proceedings of the 9th International Symposium on Distributed Objects, Middleware and Applications},
  year={2007},
  volume={4803},
  series={DOA '07},
  pages={648-666},
  address = {Algarve, Portugal},
  month = {November},
  publisher={Springer Berlin Heidelberg},
  url={http://dx.doi.org/10.1007/978-3-540-76848-7-44}
}
